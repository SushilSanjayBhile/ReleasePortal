Diamanti test package path : /home/diamanti/vishal/BOS2/diamanti-test-pkg
Default log file location : /home/diamanti/vishal/BOS2/diamanti-test-pkg/logs/e2e_log2018-09-27_02-33-07.log
    DEBUG: 2018/09/27 02:33:07 Removing leading and trailing spaces from Ipmi IP of all nodes.
    DEBUG: 2018/09/27 02:33:07 Check all nodes are ready to run test(s):
    DEBUG: 2018/09/27 02:33:07 172.16.230.8 is ready to run test
    DEBUG: 2018/09/27 02:33:07 172.16.230.10 is ready to run test
    DEBUG: 2018/09/27 02:33:07 172.16.230.12 is ready to run test
Running Suite: DWS e2e Suite run 1 of 1
=======================================
Random Seed: [1m1538040787[0m - Will randomize all specs
Will run [1m24[0m of [1m262[0m specs

    DEBUG: 2018/09/27 02:33:13 Planning to run tests on following nodes :
    DEBUG: 2018/09/27 02:33:13 172.16.230.8
    DEBUG: 2018/09/27 02:33:13 172.16.230.10
    DEBUG: 2018/09/27 02:33:13 172.16.230.12
    DEBUG: 2018/09/27 02:33:13 Checking existance of loopback device(s) on all cluster nodes
    DEBUG: 2018/09/27 02:33:24 Checking if cluster already exists 
    DEBUG: 2018/09/27 02:33:24 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:25 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:26 Login to cluster
    DEBUG: 2018/09/27 02:33:26 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:26 Destroying the cluster: 42cf852b-c21d-11e8-af97-54ab3a2919da, Master node is bosserv4
    DEBUG: 2018/09/27 02:33:26 Checking in a loop for cluster status
    DEBUG: 2018/09/27 02:33:27 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:28 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:30 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:32 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:33 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:35 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:37 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:39 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:40 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:42 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:44 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:46 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:48 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:49 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:51 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:53 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:55 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:56 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:33:58 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:00 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:02 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:03 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:05 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:07 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:09 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:11 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:12 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:17 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:20 Login command is login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:34:20 Error while saving cluster info%!(EXTRA string=failed to run commmand 'dctl -s 172.16.230.102  -o json login -u admin -p Diamanti@111 --proxy --insecure', output:, error:Get https://172.16.230.102:443/api/v1/clusterdiscover: dial tcp 172.16.230.102:443: connect: no route to host
Cannot reach cluster, please check if vip / fqdn is reachable

)
    DEBUG: 2018/09/27 02:34:29 Doing sync all nodes.
    DEBUG: 2018/09/27 02:34:29 Doing sync all nodes.
    DEBUG: 2018/09/27 02:34:30 Doing sync all nodes.
    DEBUG: 2018/09/27 02:34:32 Checking for cluster-info.json on node :172.16.230.8
    DEBUG: 2018/09/27 02:34:32 Checking for cluster-info.json on node :172.16.230.10
    DEBUG: 2018/09/27 02:34:33 Checking for cluster-info.json on node :172.16.230.12
    DEBUG: 2018/09/27 02:34:33 Rebooting all nodes.
    DEBUG: 2018/09/27 02:34:33 Doing sync on 172.16.230.8
    DEBUG: 2018/09/27 02:34:34 Doing sync on 172.16.230.10
PolicyKit daemon disconnected from the bus.
We are no longer a registered authentication agent.
    DEBUG: 2018/09/27 02:34:35 Doing sync on 172.16.230.12
    DEBUG: 2018/09/27 02:34:36 Waiting for nodes to come up, will wait upto 800 seconds
................    DEBUG: 2018/09/27 02:37:29 Nodes are up, waiting for armada to start
......    DEBUG: 2018/09/27 02:38:29 rpm not specified, assuming rpm to be tested is already installed on all nodes
    DEBUG: 2018/09/27 02:38:29 Starting tests

    DEBUG: 2018/09/27 02:38:29 Getting dns domain name
    DEBUG: 2018/09/27 02:38:29 FQDN : bostontb2.bos.diamanti.com
    DEBUG: 2018/09/27 02:38:29 Generating certificates for the cluster: (Name: bostontb2, VIP: 172.16.230.102, FQDN: bostontb2.bos.diamanti.com)
    DEBUG: 2018/09/27 02:38:29 Clean up existing certs if any:
    DEBUG: 2018/09/27 02:38:29 Generate unique CA name with current date
    DEBUG: 2018/09/27 02:38:29 Integrate CA name in file
    DEBUG: 2018/09/27 02:38:29 Generate CA certs
    DEBUG: 2018/09/27 02:38:30 Create a CSR to generate a certificate using FQDN, VIP, Cluster Name for a server certs
    DEBUG: 2018/09/27 02:38:30 Generate server certificate:
    DEBUG: 2018/09/27 02:38:30 Getting CertificateAuthority from /home/diamanti/vishal/BOS2/diamanti-test-pkg/server_certs/ca.pem file
    DEBUG: 2018/09/27 02:38:30 Getting ServerCertificate from /home/diamanti/vishal/BOS2/diamanti-test-pkg/server_certs/server.pem file
    DEBUG: 2018/09/27 02:38:30 Getting ServerPrivateKey from /home/diamanti/vishal/BOS2/diamanti-test-pkg/server_certs/server-key.pem file
    DEBUG: 2018/09/27 02:38:30 Creating the cluster
    DEBUG: 2018/09/27 02:38:44 Please import "/home/diamanti/vishal/BOS2/diamanti-test-pkg/server_certs/ca.pem" certificate to your client machine
    DEBUG: 2018/09/27 02:38:44 Sleeping for 60 sec
    DEBUG: 2018/09/27 02:39:44 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:39:45 Login to cluster
    DEBUG: 2018/09/27 02:39:45 Polling for cluster login for 300 seconds.
    DEBUG: 2018/09/27 02:39:45 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:39:46 Checking in a loop for cluster status
    DEBUG: 2018/09/27 02:39:46 Found '3' nodes
    DEBUG: 2018/09/27 02:39:46 All nodes are in ready state
    DEBUG: 2018/09/27 02:39:46 Creating network default

    DEBUG: 2018/09/27 02:39:46 Creating network blue

    DEBUG: 2018/09/27 02:39:46 Add default tag to default network
    DEBUG: 2018/09/27 02:39:56 Labeled all nodes with node=node$

    DEBUG: 2018/09/27 02:39:56 Getting cluster ID
    DEBUG: 2018/09/27 02:39:56 Created test cluster: 1791e929-c239-11e8-be5a-54ab3a2919da
    DEBUG: 2018/09/27 02:39:56 Recording timestamp of all services on all nodes
    DEBUG: 2018/09/27 02:40:03 Updating inventory struct
    DEBUG: 2018/09/27 02:40:04 rpm=diamanti-cx-2.1.0-165.x86_64
    DEBUG: 2018/09/27 02:40:04 Deleting all LCVs, volumes, snapshots from previous cluster if any.
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.CheckIODistributionOnSV Weekly RS_Verify-1.5[0m [90mcreate remote volume of large size such that it uses multiple SVs and check IO distribution on those SVs[0m 
  [1mcreates remote volume of large size such that it uses multiple SVs and check IO distribution on those SVs[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3588[0m
[BeforeEach] create remote volume of large size such that it uses multiple SVs and check IO distribution on those SVs
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3573
    DEBUG: 2018/09/27 02:40:04 START_TEST RemoteStorage.CheckIODistributionOnSV
    DEBUG: 2018/09/27 02:40:04 Login to cluster
    DEBUG: 2018/09/27 02:40:04 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:40:05 Checking basic Vnic usage
    DEBUG: 2018/09/27 02:40:05 Updating inventory struct
[It] creates remote volume of large size such that it uses multiple SVs and check IO distribution on those SVs
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3588
    DEBUG: 2018/09/27 02:40:11 Computing total available storage space on node bosserv5
    DEBUG: 2018/09/27 02:40:11 Available space on the node is less than the maximum size of volume. Hence, creating a volume of size equal to maximum available space on node
Max Volume size allowed : 8796093022208
Available space on node : 3016677654528

    DEBUG: 2018/09/27 02:40:11 Volume size is less than maximum SV size. Can't create multiple SVs.
[AfterEach] create remote volume of large size such that it uses multiple SVs and check IO distribution on those SVs
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3583
    DEBUG: 2018/09/27 02:40:11 END_TEST RemoteStorage.CheckIODistributionOnSV Time-taken : 7.211818536

[36m[1mS [SKIPPING] [7.212 seconds][0m
RemoteStorage.CheckIODistributionOnSV Weekly RS_Verify-1.5
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3563[0m
  create remote volume of large size such that it uses multiple SVs and check IO distribution on those SVs
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3568[0m
    [36m[1mcreates remote volume of large size such that it uses multiple SVs and check IO distribution on those SVs [It][0m
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3588[0m

    [36mSkipping since Volume size is less than maximum SV size[0m

    /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3649
[90m------------------------------[0m
[0mRemoteStorage.IPMIBasedInitiatorReboot Weekly AT_Other-3.3 Qos[0m [90mIPMI power cycle the node having fio pods.[0m 
  [1mthe node having fio pods.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:378[0m
[BeforeEach] IPMI power cycle the node having fio pods.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:365
    DEBUG: 2018/09/27 02:40:11 START_TEST RemoteStorage.IPMIBasedInitiatorReboot
    DEBUG: 2018/09/27 02:40:11 Login to cluster
    DEBUG: 2018/09/27 02:40:11 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:40:12 Checking basic Vnic usage
    DEBUG: 2018/09/27 02:40:12 Updating inventory struct
[It] the node having fio pods.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:378
    DEBUG: 2018/09/27 02:40:18 Creating 8 volumes. Mirror count: 1.
    DEBUG: 2018/09/27 02:40:28 Creating 8 fio pods: 
    DEBUG: 2018/09/27 02:40:30 Checking if given pods are in Running state
    DEBUG: 2018/09/27 02:40:45 Wait for volumes to move into attached state: 
    DEBUG: 2018/09/27 02:40:45 Waiting for 180 sec., so that prometheus database will have some stats...
    DEBUG: 2018/09/27 02:43:45 Validate qos for every volume: 
    DEBUG: 2018/09/27 02:43:46 Rebooting cluster node "bosserv4". Reboot Type: IPMI_BASED.
    DEBUG: 2018/09/27 02:43:46 Waiting till node goes down: 
    DEBUG: 2018/09/27 02:43:46 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:43:50 bosserv4 is pingable from local machine
    DEBUG: 2018/09/27 02:43:55 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:44:04 Cluster node "bosserv4" become unreachable.
    DEBUG: 2018/09/27 02:44:04 Checking reachability of rebooted node: bosserv4
    DEBUG: 2018/09/27 02:44:04 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:44:21 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:44:38 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:44:55 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:45:12 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:45:29 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:45:46 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:46:03 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:46:20 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 02:46:25 bosserv4 is pingable from local machine
    DEBUG: 2018/09/27 02:46:25 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2018/09/27 02:46:36 Nodes are up, waiting for armada to start
......
    DEBUG: 2018/09/27 02:47:36 Waiting for all the nodes to go into Ready state
    DEBUG: 2018/09/27 02:47:36 Found '3' nodes
    DEBUG: 2018/09/27 02:47:40 All nodes are in ready state
    DEBUG: 2018/09/27 02:47:40 After power cycle/reboot, updating timestamp of node : bosserv4
    DEBUG: 2018/09/27 02:47:43 Volume "test-vol1" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 02:47:59 Volume "test-vol2" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 02:48:05 Volume "test-vol3" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 02:48:05 Volume "test-vol4" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 02:48:05 Volume "test-vol5" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 02:48:06 Volume "test-vol6" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 02:48:06 Volume "test-vol7" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 02:48:06 Volume "test-vol8" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 02:48:06 Wait till all pods go into running state: 
    DEBUG: 2018/09/27 02:48:06 Checking if given pods are in Running state
    DEBUG: 2018/09/27 02:48:36 Waiting for 180 sec., so that prometheus database will have some stats...
    DEBUG: 2018/09/27 02:51:36 Validate qos for every volume: 
    DEBUG: 2018/09/27 02:51:37 Delete Pods: 
    DEBUG: 2018/09/27 02:51:37 Deleting pods : 
    DEBUG: 2018/09/27 02:51:47 Wait for volumes to come in Available state: 
    DEBUG: 2018/09/27 02:51:48 Delete volumes: 
[AfterEach] IPMI power cycle the node having fio pods.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:374
    DEBUG: 2018/09/27 02:53:21 END_TEST RemoteStorage.IPMIBasedInitiatorReboot Time-taken : 789.240242534

[32m• [SLOW TEST:789.240 seconds][0m
RemoteStorage.IPMIBasedInitiatorReboot Weekly AT_Other-3.3 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:354[0m
  IPMI power cycle the node having fio pods.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:355[0m
    the node having fio pods.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:378[0m
[90m------------------------------[0m
[0mRemoteStorage.ConfigStress Weekly RS_Stress-1.0[0m [90mCreate - Attach - Detach - Delete remote volumes in loop.[0m 
  [1mCreate - Attach - Detach - Delete remote volumes in loop.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4359[0m
[BeforeEach] Create - Attach - Detach - Delete remote volumes in loop.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4344
    DEBUG: 2018/09/27 02:53:21 START_TEST RemoteStorage.ConfigStress
    DEBUG: 2018/09/27 02:53:21 Login to cluster
    DEBUG: 2018/09/27 02:53:21 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 02:53:21 Checking basic Vnic usage
    DEBUG: 2018/09/27 02:53:21 Updating inventory struct
[It] Create - Attach - Detach - Delete remote volumes in loop.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4359
    DEBUG: 2018/09/27 02:53:28 /****************************** Started Iteration: 1 ***********************/
    DEBUG: 2018/09/27 02:53:28 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 02:53:28 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 02:53:28 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 02:53:28 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 02:54:05 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 02:56:44 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 02:59:19 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 03:01:53 Detach volumes:
    DEBUG: 2018/09/27 03:01:53 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:01:53 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:01:53 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:02:21 Delete volumes: 
    DEBUG: 2018/09/27 03:03:27 /****************************** Started Iteration: 2 ***********************/
    DEBUG: 2018/09/27 03:03:27 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 03:03:27 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:03:27 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:03:27 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:04:04 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 03:06:40 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 03:09:13 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 03:11:50 Detach volumes:
    DEBUG: 2018/09/27 03:11:50 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:11:50 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:11:50 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:12:21 Delete volumes: 
    DEBUG: 2018/09/27 03:13:29 /****************************** Started Iteration: 3 ***********************/
    DEBUG: 2018/09/27 03:13:29 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 03:13:29 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:13:29 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:13:29 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:14:06 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 03:16:40 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 03:19:06 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 03:21:39 Detach volumes:
    DEBUG: 2018/09/27 03:21:39 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:21:39 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:21:39 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:21:51 Delete volumes: 
    DEBUG: 2018/09/27 03:22:35 /****************************** Started Iteration: 4 ***********************/
    DEBUG: 2018/09/27 03:22:35 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 03:22:35 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:22:35 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:22:35 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:23:11 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 03:25:41 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 03:28:14 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 03:30:45 Detach volumes:
    DEBUG: 2018/09/27 03:30:45 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:30:45 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:30:45 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:30:54 Delete volumes: 
    DEBUG: 2018/09/27 03:31:36 /****************************** Started Iteration: 5 ***********************/
    DEBUG: 2018/09/27 03:31:37 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 03:31:37 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:31:37 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:31:37 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:32:14 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 03:34:49 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 03:37:23 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 03:39:59 Detach volumes:
    DEBUG: 2018/09/27 03:39:59 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:39:59 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:39:59 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:40:22 Delete volumes: 
    DEBUG: 2018/09/27 03:41:09 /****************************** Started Iteration: 6 ***********************/
    DEBUG: 2018/09/27 03:41:10 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 03:41:10 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:41:10 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:41:10 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:41:46 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 03:44:20 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 03:46:54 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 03:49:31 Detach volumes:
    DEBUG: 2018/09/27 03:49:31 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:49:31 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:49:31 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:49:52 Delete volumes: 
    DEBUG: 2018/09/27 03:50:43 /****************************** Started Iteration: 7 ***********************/
    DEBUG: 2018/09/27 03:50:43 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 03:50:43 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:50:43 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:50:43 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:51:20 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 03:53:56 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 03:56:32 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 03:59:09 Detach volumes:
    DEBUG: 2018/09/27 03:59:09 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 03:59:09 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 03:59:09 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 03:59:21 Delete volumes: 
    DEBUG: 2018/09/27 04:00:16 /****************************** Started Iteration: 8 ***********************/
    DEBUG: 2018/09/27 04:00:17 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 04:00:17 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 04:00:17 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 04:00:17 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 04:00:54 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 04:03:30 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 04:06:00 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 04:08:36 Detach volumes:
    DEBUG: 2018/09/27 04:08:36 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 04:08:36 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 04:08:36 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 04:08:46 Delete volumes: 
    DEBUG: 2018/09/27 04:09:47 /****************************** Started Iteration: 9 ***********************/
    DEBUG: 2018/09/27 04:09:48 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 04:09:48 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 04:09:48 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 04:09:48 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 04:10:24 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 04:12:59 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 04:15:29 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 04:18:01 Detach volumes:
    DEBUG: 2018/09/27 04:18:02 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 04:18:02 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 04:18:02 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 04:18:22 Delete volumes: 
    DEBUG: 2018/09/27 04:19:23 /****************************** Started Iteration: 10 ***********************/
    DEBUG: 2018/09/27 04:19:23 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 04:19:23 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 04:19:23 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 04:19:23 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 04:20:00 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 04:22:37 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 04:25:11 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 04:27:44 Detach volumes:
    DEBUG: 2018/09/27 04:27:44 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 04:27:44 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 04:27:44 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 04:27:53 Delete volumes: 
[AfterEach] Create - Attach - Detach - Delete remote volumes in loop.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4354
    DEBUG: 2018/09/27 04:28:54 END_TEST RemoteStorage.ConfigStress Time-taken : 5733.928073378

[32m• [SLOW TEST:5733.928 seconds][0m
RemoteStorage.ConfigStress Weekly RS_Stress-1.0
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4337[0m
  Create - Attach - Detach - Delete remote volumes in loop.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4338[0m
    Create - Attach - Detach - Delete remote volumes in loop.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4359[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorageStaticProvisioning.OnePodMultiplePvcs Weekly PVC_Remote-1.3 Qos[0m [90mRemote storage, static provisioning, one pod multiple PVCs.[0m 
  [1mRemote storage, static provisioning, one pod multiple PVCs.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:216[0m
[BeforeEach] Remote storage, static provisioning, one pod multiple PVCs.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:199
    DEBUG: 2018/09/27 04:28:54 START_TEST RemoteStorageStaticProvisioning.OnePodMultiplePvcs
    DEBUG: 2018/09/27 04:28:54 Login to cluster
    DEBUG: 2018/09/27 04:28:54 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 04:28:55 Checking basic Vnic usage
    DEBUG: 2018/09/27 04:28:55 Updating inventory struct
[It] Remote storage, static provisioning, one pod multiple PVCs.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:216
    DEBUG: 2018/09/27 04:29:02 Creating 4 volumes. Mirror count: 1.
    DEBUG: 2018/09/27 04:29:06 Creating 4 Persistent Volume Claims (PVCs).
    DEBUG: 2018/09/27 04:29:07 Created PVC successfully.
    DEBUG: 2018/09/27 04:29:07 Created PVC successfully.
    DEBUG: 2018/09/27 04:29:07 Created PVC successfully.
    DEBUG: 2018/09/27 04:29:07 Created PVC successfully.
    DEBUG: 2018/09/27 04:29:07 Creating 1 fio pods: 
    DEBUG: 2018/09/27 04:29:08 Checking if given pods are in Running state
    DEBUG: 2018/09/27 04:29:25 Wait for volumes to move into attached state: 
    DEBUG: 2018/09/27 04:32:25 Validating qos associated with each volume: 
    DEBUG: 2018/09/27 04:32:26 Deleting pods : 
    DEBUG: 2018/09/27 04:33:28 Wait for volumes to come in Available state: 
    DEBUG: 2018/09/27 04:33:29 Deleted pvc : test-vol-claim1 successfully.
    DEBUG: 2018/09/27 04:33:29 Deleted pvc : test-vol-claim2 successfully.
    DEBUG: 2018/09/27 04:33:29 Deleted pvc : test-vol-claim3 successfully.
    DEBUG: 2018/09/27 04:33:29 Deleted pvc : test-vol-claim4 successfully.
    DEBUG: 2018/09/27 04:33:29 Delete volumes: 
[AfterEach] Remote storage, static provisioning, one pod multiple PVCs.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:211
    DEBUG: 2018/09/27 04:35:22 END_TEST RemoteStorageStaticProvisioning.OnePodMultiplePvcs Time-taken : 387.729601313

[32m• [SLOW TEST:387.730 seconds][0m
RemoteStorageStaticProvisioning.OnePodMultiplePvcs Weekly PVC_Remote-1.3 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:191[0m
  Remote storage, static provisioning, one pod multiple PVCs.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:192[0m
    Remote storage, static provisioning, one pod multiple PVCs.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:216[0m
[90m------------------------------[0m
[0mRemoteStorage.RebootInitiator Weekly RS_Reboot-1.2[0m [90mreboot initiator node after running IO and verify data before and after reboot[0m 
  [1mreboot initiator node after running IO and verify data before and after reboot[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2491[0m
[BeforeEach] reboot initiator node after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2473
    DEBUG: 2018/09/27 04:35:22 START_TEST RemoteStorage.RebootInitiator
    DEBUG: 2018/09/27 04:35:22 Login to cluster
    DEBUG: 2018/09/27 04:35:22 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 04:35:23 Checking basic Vnic usage
    DEBUG: 2018/09/27 04:35:23 Updating inventory struct
[It] reboot initiator node after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2491
    DEBUG: 2018/09/27 04:35:29 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2018/09/27 04:35:44 FBM and L1 usage is Zero across all nodes

    DEBUG: 2018/09/27 04:35:44 Creating 8 volumes of random sizes
    DEBUG: 2018/09/27 04:35:44 Mirror Count: 1
    DEBUG: 2018/09/27 04:35:53 Attaching all 8 volumes
    DEBUG: 2018/09/27 04:36:31 Initiator node : bosserv4
    DEBUG: 2018/09/27 04:36:31 Nodes to reboot : bosserv4
    DEBUG: 2018/09/27 04:36:34 List of devices :  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1

    DEBUG: 2018/09/27 04:36:34 Running WRITE fio job on node : bosserv4
    DEBUG: 2018/09/27 04:36:34 FIO Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-12 --verify_interval=4096 --runtime=300 --blocksize=4K --iodepth=32  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1

    DEBUG: 2018/09/27 04:41:36 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2018/09/27 04:41:36 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2018/09/27 04:41:36 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2018/09/27 04:41:36 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2018/09/27 04:41:36 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2018/09/27 04:41:36 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2018/09/27 04:41:36 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2018/09/27 04:41:36 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2018/09/27 04:51:44 Getting cluster quorum nodes
    DEBUG: 2018/09/27 04:51:44 Powering OFF the node bosserv4
    DEBUG: 2018/09/27 04:51:49 Node 172.16.230.8 took 5 seconds to power off
    DEBUG: 2018/09/27 04:51:49 Ensuring that bosserv4 node is unreachable: 
    DEBUG: 2018/09/27 04:51:49 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:51:58 Polling to check until node: bosserv4 goes down
    DEBUG: 2018/09/27 04:53:38 Powering ON the node bosserv4
    DEBUG: 2018/09/27 04:53:39 Node 172.16.230.8 took 1 seconds to power on
    DEBUG: 2018/09/27 04:53:39 Checking if node bosserv4 is reachable or not: 
    DEBUG: 2018/09/27 04:53:39 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:53:58 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:54:15 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:54:32 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:54:49 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:55:06 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:55:23 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:55:40 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:55:57 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:56:14 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 04:56:18 bosserv4 is pingable from local machine
    DEBUG: 2018/09/27 04:56:18 Checking ssh port is up or not on node: bosserv4
    DEBUG: 2018/09/27 04:56:48 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2018/09/27 04:56:48 Found '3' nodes
    DEBUG: 2018/09/27 04:57:47 All nodes are in ready state
    DEBUG: 2018/09/27 04:57:57 After power cycle/reboot, updating timestamp of node : bosserv4
    DEBUG: 2018/09/27 04:57:59 Getting cluster quorum nodes
    DEBUG: 2018/09/27 04:58:59 Updating inventory struct
    DEBUG: 2018/09/27 04:58:59 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2018/09/27 04:59:10 Nodes are up, waiting for armada to start
.
    DEBUG: 2018/09/27 05:00:20 Waiting for the nodes to go into Ready state
    DEBUG: 2018/09/27 05:00:21 Found '3' nodes
    DEBUG: 2018/09/27 05:00:21 All nodes are in ready state
    DEBUG: 2018/09/27 05:00:21 Waiting for volumes to come into Attached state after rebooting cluster nodes.
    DEBUG: 2018/09/27 05:00:21 Detaching all 8 volumes
    DEBUG: 2018/09/27 05:00:24 Re-attaching all 8 volumes
    DEBUG: 2018/09/27 05:01:05 Comparing Volume's UUID with nvme id-ns for all volumes
    DEBUG: 2018/09/27 05:01:09 Comparing the device path & uuid on initiator before and after reboot
    DEBUG: 2018/09/27 05:01:43 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2018/09/27 05:01:43 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2018/09/27 05:01:43 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2018/09/27 05:01:43 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2018/09/27 05:01:43 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2018/09/27 05:01:43 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2018/09/27 05:01:43 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2018/09/27 05:01:43 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2018/09/27 05:12:22 Successfully completed Verification on all the volumes
    DEBUG: 2018/09/27 05:12:22 Detach & Delete all volumes
[AfterEach] reboot initiator node after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2486
    DEBUG: 2018/09/27 05:33:23 END_TEST RemoteStorage.RebootInitiator Time-taken : 3481.232993159

[32m• [SLOW TEST:3481.233 seconds][0m
RemoteStorage.RebootInitiator Weekly RS_Reboot-1.2
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2466[0m
  reboot initiator node after running IO and verify data before and after reboot
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2468[0m
    reboot initiator node after running IO and verify data before and after reboot
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2491[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.PodWithMultipleVolsDo4KAndNon4KIOs Weekly RS_Verify-1.2[0m [90mFor same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously[0m 
  [1mFor same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4437[0m
[BeforeEach] For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4422
    DEBUG: 2018/09/27 05:33:23 START_TEST RemoteStorage.PodWithMultipleVolsDo4KAndNon4KIOs
    DEBUG: 2018/09/27 05:33:23 Login to cluster
    DEBUG: 2018/09/27 05:33:23 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 05:33:24 Checking basic Vnic usage
    DEBUG: 2018/09/27 05:33:24 Updating inventory struct
[It] For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4437
    DEBUG: 2018/09/27 05:33:31 Create 2 volumes on node: bosserv5.
    DEBUG: 2018/09/27 05:33:31 Mirror Count: 1
    DEBUG: 2018/09/27 05:33:33 Create container specs for fio pod: 
    DEBUG: 2018/09/27 05:33:33 Fio pod with two remote volumes: 
    DEBUG: 2018/09/27 05:36:43 Checking if IOs are happening: 
    DEBUG: 2018/09/27 05:36:43 Before deleting pod, check if it is in running state: 
    DEBUG: 2018/09/27 05:36:43 Delete pod: 
    DEBUG: 2018/09/27 05:36:52 Wait for volumes to come in "Available" state: 
    DEBUG: 2018/09/27 05:36:52 Delete volumes: 
[AfterEach] For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4432
    DEBUG: 2018/09/27 05:38:25 END_TEST RemoteStorage.PodWithMultipleVolsDo4KAndNon4KIOs Time-taken : 301.066462095

[32m• [SLOW TEST:301.067 seconds][0m
RemoteStorage.PodWithMultipleVolsDo4KAndNon4KIOs Weekly RS_Verify-1.2
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4411[0m
  For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4412[0m
    For same pod, attach multiple volumes. Run jobs with 4k and non4k multiple block-size simultaneously
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4437[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.RebootTarget Daily RS_Reboot-1.3[0m [90mreboot target node after running IO and verify data before and after reboot[0m 
  [1mreboot target node after running IO and verify data before and after reboot[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2541[0m
[BeforeEach] reboot target node after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2523
    DEBUG: 2018/09/27 05:38:25 START_TEST RemoteStorage.RebootTarget
    DEBUG: 2018/09/27 05:38:25 Login to cluster
    DEBUG: 2018/09/27 05:38:25 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 05:38:25 Checking basic Vnic usage
    DEBUG: 2018/09/27 05:38:25 Updating inventory struct
[It] reboot target node after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2541
    DEBUG: 2018/09/27 05:38:32 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2018/09/27 05:38:46 FBM and L1 usage is Zero across all nodes

    DEBUG: 2018/09/27 05:38:46 Creating 4 volumes of random sizes
    DEBUG: 2018/09/27 05:38:46 Mirror Count: 1
    DEBUG: 2018/09/27 05:38:51 Attaching all 4 volumes
    DEBUG: 2018/09/27 05:39:09 Initiator node : bosserv5
    DEBUG: 2018/09/27 05:39:09 Nodes to reboot : bosserv4
    DEBUG: 2018/09/27 05:39:11 List of devices :  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1

    DEBUG: 2018/09/27 05:39:11 Running WRITE fio job on node : bosserv5
    DEBUG: 2018/09/27 05:39:11 FIO Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"akpz\"-12 --verify_interval=4096 --runtime=120 --blocksize=64K --iodepth=16  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1

    DEBUG: 2018/09/27 05:41:12 Running VERIFY IOs on all plexes
    DEBUG: 2018/09/27 05:41:12 Running Verify IOs on node : bosserv5 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"akpz\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=64K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1
    DEBUG: 2018/09/27 05:41:39 Getting cluster quorum nodes
    DEBUG: 2018/09/27 05:41:39 Powering OFF the node bosserv4
    DEBUG: 2018/09/27 05:41:43 Node 172.16.230.8 took 4 seconds to power off
    DEBUG: 2018/09/27 05:41:43 Ensuring that bosserv4 node is unreachable: 
    DEBUG: 2018/09/27 05:41:43 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:41:52 Polling to check until node: bosserv4 goes down
    DEBUG: 2018/09/27 05:43:40 Powering ON the node bosserv4
    DEBUG: 2018/09/27 05:43:42 Node 172.16.230.8 took 1 seconds to power on
    DEBUG: 2018/09/27 05:43:42 Checking if node bosserv4 is reachable or not: 
    DEBUG: 2018/09/27 05:43:42 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:44:01 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:44:18 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:44:35 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:44:52 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:45:09 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:45:26 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:45:43 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:46:00 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:46:17 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 05:46:21 bosserv4 is pingable from local machine
    DEBUG: 2018/09/27 05:46:21 Checking ssh port is up or not on node: bosserv4
    DEBUG: 2018/09/27 05:46:51 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2018/09/27 05:46:51 Found '3' nodes
    DEBUG: 2018/09/27 05:47:49 All nodes are in ready state
    DEBUG: 2018/09/27 05:47:59 After power cycle/reboot, updating timestamp of node : bosserv4
    DEBUG: 2018/09/27 05:48:01 Getting cluster quorum nodes
    DEBUG: 2018/09/27 05:49:01 Updating inventory struct
    DEBUG: 2018/09/27 05:49:01 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2018/09/27 05:49:13 Nodes are up, waiting for armada to start
.
    DEBUG: 2018/09/27 05:50:23 Waiting for the nodes to go into Ready state
    DEBUG: 2018/09/27 05:50:23 Found '3' nodes
    DEBUG: 2018/09/27 05:50:23 All nodes are in ready state
    DEBUG: 2018/09/27 05:50:23 Waiting for volumes to come into Attached state after rebooting cluster nodes.
    DEBUG: 2018/09/27 05:50:23 Detaching all 4 volumes
    DEBUG: 2018/09/27 05:50:24 Re-attaching all 4 volumes
    DEBUG: 2018/09/27 05:50:45 Comparing Volume's UUID with nvme id-ns for all volumes
    DEBUG: 2018/09/27 05:50:47 Comparing the device path & uuid on initiator before and after reboot
    DEBUG: 2018/09/27 05:51:09 Running VERIFY IOs on all plexes
    DEBUG: 2018/09/27 05:51:09 Running Verify IOs on node : bosserv5 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"akpz\"-12 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=64K --iodepth=16  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1
    DEBUG: 2018/09/27 05:51:21 Successfully completed Verification on all the volumes
    DEBUG: 2018/09/27 05:51:21 Detach & Delete all volumes
[AfterEach] reboot target node after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2536
    DEBUG: 2018/09/27 05:53:23 END_TEST RemoteStorage.RebootTarget Time-taken : 898.482925393

[32m• [SLOW TEST:898.483 seconds][0m
RemoteStorage.RebootTarget Daily RS_Reboot-1.3
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2516[0m
  reboot target node after running IO and verify data before and after reboot
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2518[0m
    reboot target node after running IO and verify data before and after reboot
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2541[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.IPMIBasedTargetReboot Weekly AT_Other-3.2 Qos[0m [90mIpmi power cycle the node having volume.[0m 
  [1mIpmi power cycle the node having volume.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:339[0m
[BeforeEach] Ipmi power cycle the node having volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:325
    DEBUG: 2018/09/27 05:53:23 START_TEST RemoteStorage.IPMIBasedTargetReboot
    DEBUG: 2018/09/27 05:53:23 Login to cluster
    DEBUG: 2018/09/27 05:53:23 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 05:53:24 Checking basic Vnic usage
    DEBUG: 2018/09/27 05:53:24 Updating inventory struct
[It] Ipmi power cycle the node having volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:339
    DEBUG: 2018/09/27 05:53:30 Creating 8 volumes. Mirror count: 1.
    DEBUG: 2018/09/27 05:53:39 Creating 8 fio pods: 
    DEBUG: 2018/09/27 05:53:42 Checking if given pods are in Running state
    DEBUG: 2018/09/27 05:53:56 Wait for volumes to move into attached state: 
    DEBUG: 2018/09/27 05:53:57 Waiting for 180 sec., so that prometheus database will have some stats...
    DEBUG: 2018/09/27 05:56:57 Validate qos for every volume: 
    DEBUG: 2018/09/27 05:56:57 Rebooting cluster node "bosserv5". Reboot Type: IPMI_BASED.
    DEBUG: 2018/09/27 05:56:57 Waiting till node goes down: 
    DEBUG: 2018/09/27 05:56:57 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:57:01 bosserv5 is pingable from local machine
    DEBUG: 2018/09/27 05:57:06 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:57:15 Cluster node "bosserv5" become unreachable.
    DEBUG: 2018/09/27 05:57:15 Checking reachability of rebooted node: bosserv5
    DEBUG: 2018/09/27 05:57:15 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:57:34 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:57:51 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:58:08 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:58:25 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:58:42 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:58:59 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:59:16 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:59:33 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 05:59:37 bosserv5 is pingable from local machine
    DEBUG: 2018/09/27 05:59:37 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2018/09/27 05:59:48 Nodes are up, waiting for armada to start
......    DEBUG: 2018/09/27 06:00:48 Waiting for all the nodes to go into Ready state

    DEBUG: 2018/09/27 06:00:48 Found '3' nodes
    DEBUG: 2018/09/27 06:01:01 All nodes are in ready state
    DEBUG: 2018/09/27 06:01:01 After power cycle/reboot, updating timestamp of node : bosserv5
    DEBUG: 2018/09/27 06:01:03 Deleting fio pods, after rebooting target node:
    DEBUG: 2018/09/27 06:01:03 Deleting pods : 
    DEBUG: 2018/09/27 06:02:07 After target node reboot & fio pod deletion, waiting for all volumes to come in "Available" state.
    DEBUG: 2018/09/27 06:02:07 After target node reboot & fio pod deletion, recreating pods: 
    DEBUG: 2018/09/27 06:02:47 Waiting for 180 sec., so that prometheus database will have some stats...
    DEBUG: 2018/09/27 06:05:47 Validate qos for every volume: 
    DEBUG: 2018/09/27 06:05:48 Delete Pods: 
    DEBUG: 2018/09/27 06:05:48 Deleting pods : 
    DEBUG: 2018/09/27 06:05:58 Wait for volumes to come in Available state: 
    DEBUG: 2018/09/27 06:05:58 Delete volumes: 
[AfterEach] Ipmi power cycle the node having volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:334
    DEBUG: 2018/09/27 06:07:40 END_TEST RemoteStorage.IPMIBasedTargetReboot Time-taken : 856.730680666

[32m• [SLOW TEST:856.731 seconds][0m
RemoteStorage.IPMIBasedTargetReboot Weekly AT_Other-3.2 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:314[0m
  Ipmi power cycle the node having volume.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:315[0m
    Ipmi power cycle the node having volume.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:339[0m
[90m------------------------------[0m
[0mRemoteStorage.OSBasedInitiatorReboot Weekly AT_Other-3.1 Qos[0m [90mReboot the node having fio pods.[0m 
  [1mReboot the node having fio pods.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:299[0m
[BeforeEach] Reboot the node having fio pods.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:285
    DEBUG: 2018/09/27 06:07:40 START_TEST RemoteStorage.OSBasedInitiatorReboot
    DEBUG: 2018/09/27 06:07:40 Login to cluster
    DEBUG: 2018/09/27 06:07:40 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 06:07:40 Checking basic Vnic usage
    DEBUG: 2018/09/27 06:07:40 Updating inventory struct
[It] Reboot the node having fio pods.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:299
    DEBUG: 2018/09/27 06:07:47 Creating 8 volumes. Mirror count: 1.
    DEBUG: 2018/09/27 06:07:56 Creating 8 fio pods: 
    DEBUG: 2018/09/27 06:07:58 Checking if given pods are in Running state
    DEBUG: 2018/09/27 06:08:13 Wait for volumes to move into attached state: 
    DEBUG: 2018/09/27 06:08:13 Waiting for 180 sec., so that prometheus database will have some stats...
    DEBUG: 2018/09/27 06:11:13 Validate qos for every volume: 
    DEBUG: 2018/09/27 06:11:14 Rebooting cluster node "bosserv4". Reboot Type: OS_BASED.
    DEBUG: 2018/09/27 06:11:14 Doing sync on 172.16.230.8
PolicyKit daemon disconnected from the bus.
We are no longer a registered authentication agent.
    DEBUG: 2018/09/27 06:11:15 Waiting till node goes down: 
    DEBUG: 2018/09/27 06:11:15 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:11:19 bosserv4 is pingable from local machine
    DEBUG: 2018/09/27 06:11:24 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:11:28 bosserv4 is pingable from local machine
    DEBUG: 2018/09/27 06:11:33 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:11:42 Cluster node "bosserv4" become unreachable.
    DEBUG: 2018/09/27 06:11:42 Checking reachability of rebooted node: bosserv4
    DEBUG: 2018/09/27 06:11:42 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:12:01 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:12:20 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:12:37 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:12:54 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:13:11 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:13:28 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:13:45 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:14:02 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 06:14:06 bosserv4 is pingable from local machine
    DEBUG: 2018/09/27 06:14:06 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2018/09/27 06:14:17 Nodes are up, waiting for armada to start
.....    DEBUG: 2018/09/27 06:15:07 Waiting for all the nodes to go into Ready state

    DEBUG: 2018/09/27 06:15:08 Found '3' nodes
    DEBUG: 2018/09/27 06:15:33 All nodes are in ready state
    DEBUG: 2018/09/27 06:15:33 After power cycle/reboot, updating timestamp of node : bosserv4
    DEBUG: 2018/09/27 06:15:34 Volume "test-vol1" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 06:16:03 Volume "test-vol2" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 06:16:03 Volume "test-vol3" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 06:16:06 Volume "test-vol4" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 06:16:07 Volume "test-vol5" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 06:16:11 Volume "test-vol6" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 06:16:11 Volume "test-vol7" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 06:16:11 Volume "test-vol8" is in "Down" state. Waiting for it to come in "Attached" state.
    DEBUG: 2018/09/27 06:16:12 Wait till all pods go into running state: 
    DEBUG: 2018/09/27 06:16:12 Checking if given pods are in Running state
    DEBUG: 2018/09/27 06:17:13 Waiting for 180 sec., so that prometheus database will have some stats...
    DEBUG: 2018/09/27 06:20:13 Validate qos for every volume: 
    DEBUG: 2018/09/27 06:20:14 Delete Pods: 
    DEBUG: 2018/09/27 06:20:14 Deleting pods : 
    DEBUG: 2018/09/27 06:20:24 Wait for volumes to come in Available state: 
    DEBUG: 2018/09/27 06:20:24 Delete volumes: 
[AfterEach] Reboot the node having fio pods.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:294
    DEBUG: 2018/09/27 06:22:11 END_TEST RemoteStorage.OSBasedInitiatorReboot Time-taken : 871.592345639

[32m• [SLOW TEST:871.592 seconds][0m
RemoteStorage.OSBasedInitiatorReboot Weekly AT_Other-3.1 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:274[0m
  Reboot the node having fio pods.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:275[0m
    Reboot the node having fio pods.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:299[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorageStaticProvisioning.MultiplePodsMultiplePvcs Weekly PVC_Remote-1.4 Qos[0m [90mRemote storage, static provisioning, Multiple pods multiple PVCs.[0m 
  [1mRemote storage, static provisioning, multiple pods, multiple PVCs.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:251[0m
[BeforeEach] Remote storage, static provisioning, Multiple pods multiple PVCs.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:234
    DEBUG: 2018/09/27 06:22:11 START_TEST RemoteStorageStaticProvisioning.MultiplePodsMultiplePvcs
    DEBUG: 2018/09/27 06:22:11 Login to cluster
    DEBUG: 2018/09/27 06:22:11 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 06:22:12 Checking basic Vnic usage
    DEBUG: 2018/09/27 06:22:12 Updating inventory struct
[It] Remote storage, static provisioning, multiple pods, multiple PVCs.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:251
    DEBUG: 2018/09/27 06:22:19 Creating 16 volumes. Mirror count: 1.
    DEBUG: 2018/09/27 06:22:37 Creating 16 Persistent Volume Claims (PVCs).
    DEBUG: 2018/09/27 06:22:37 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:37 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:37 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:38 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:38 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:38 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:38 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:39 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:39 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:39 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:39 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:40 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:40 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:40 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:40 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:41 Created PVC successfully.
    DEBUG: 2018/09/27 06:22:41 Creating 4 fio pods: 
    DEBUG: 2018/09/27 06:22:42 Checking if given pods are in Running state
    DEBUG: 2018/09/27 06:23:29 Wait for volumes to move into attached state: 
    DEBUG: 2018/09/27 06:26:30 Validating qos associated with each volume: 
    DEBUG: 2018/09/27 06:26:31 Deleting pods : 
    DEBUG: 2018/09/27 06:26:36 Wait for volumes to come in Available state: 
    DEBUG: 2018/09/27 06:26:36 Volume "test-vol1" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:39 Volume "test-vol10" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol11" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol12" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol13" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol14" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol15" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol16" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol2" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol3" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol4" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol5" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol6" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol7" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol8" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:40 Volume "test-vol9" is in "Attached" state. Waiting for it to come in "Available" state.
    DEBUG: 2018/09/27 06:26:41 Deleted pvc : test-vol-claim1 successfully.
    DEBUG: 2018/09/27 06:26:41 Deleted pvc : test-vol-claim10 successfully.
    DEBUG: 2018/09/27 06:26:41 Deleted pvc : test-vol-claim11 successfully.
    DEBUG: 2018/09/27 06:26:41 Deleted pvc : test-vol-claim12 successfully.
    DEBUG: 2018/09/27 06:26:41 Deleted pvc : test-vol-claim13 successfully.
    DEBUG: 2018/09/27 06:26:41 Deleted pvc : test-vol-claim14 successfully.
    DEBUG: 2018/09/27 06:26:41 Deleted pvc : test-vol-claim15 successfully.
    DEBUG: 2018/09/27 06:26:42 Deleted pvc : test-vol-claim16 successfully.
    DEBUG: 2018/09/27 06:26:42 Deleted pvc : test-vol-claim2 successfully.
    DEBUG: 2018/09/27 06:26:42 Deleted pvc : test-vol-claim3 successfully.
    DEBUG: 2018/09/27 06:26:42 Deleted pvc : test-vol-claim4 successfully.
    DEBUG: 2018/09/27 06:26:42 Deleted pvc : test-vol-claim5 successfully.
    DEBUG: 2018/09/27 06:26:42 Deleted pvc : test-vol-claim6 successfully.
    DEBUG: 2018/09/27 06:26:43 Deleted pvc : test-vol-claim7 successfully.
    DEBUG: 2018/09/27 06:26:43 Deleted pvc : test-vol-claim8 successfully.
    DEBUG: 2018/09/27 06:26:43 Deleted pvc : test-vol-claim9 successfully.
    DEBUG: 2018/09/27 06:26:43 Delete volumes: 
[AfterEach] Remote storage, static provisioning, Multiple pods multiple PVCs.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:246
    DEBUG: 2018/09/27 06:28:41 END_TEST RemoteStorageStaticProvisioning.MultiplePodsMultiplePvcs Time-taken : 390.165383543

[32m• [SLOW TEST:390.165 seconds][0m
RemoteStorageStaticProvisioning.MultiplePodsMultiplePvcs Weekly PVC_Remote-1.4 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:226[0m
  Remote storage, static provisioning, Multiple pods multiple PVCs.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:227[0m
    Remote storage, static provisioning, multiple pods, multiple PVCs.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/pvc.go:251[0m
[90m------------------------------[0m
[0mRemoteStorage.SinglePodOneRemoteVolume Daily RSP_Basic-1.0 Qos[0m [90mOne Pod, One remote volume.[0m 
  [1mOne Pod, Single remote volume.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3060[0m
[BeforeEach] One Pod, One remote volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3048
    DEBUG: 2018/09/27 06:28:41 START_TEST RemoteStorage.SinglePodOneRemoteVolume
    DEBUG: 2018/09/27 06:28:41 Login to cluster
    DEBUG: 2018/09/27 06:28:41 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 06:28:42 Checking basic Vnic usage
    DEBUG: 2018/09/27 06:28:42 Updating inventory struct
[It] One Pod, Single remote volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3060
    DEBUG: 2018/09/27 06:28:49 Creating 1 volumes. Mirror count: 1.
    DEBUG: 2018/09/27 06:28:50 Creating 1 fio pods: 
    DEBUG: 2018/09/27 06:28:50 Checking if given pods are in Running state
    DEBUG: 2018/09/27 06:28:56 Wait for volumes to move into attached state: 
    DEBUG: 2018/09/27 06:31:56 Validating qos associated with each volume: 
    DEBUG: 2018/09/27 06:31:56 Deleting pods : 
    DEBUG: 2018/09/27 06:32:01 Wait for volumes to come in Available state: 
    DEBUG: 2018/09/27 06:32:01 Delete volumes: 
[AfterEach] One Pod, One remote volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3055
    DEBUG: 2018/09/27 06:33:42 END_TEST RemoteStorage.SinglePodOneRemoteVolume Time-taken : 300.019835761

[32m• [SLOW TEST:300.020 seconds][0m
RemoteStorage.SinglePodOneRemoteVolume Daily RSP_Basic-1.0 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3041[0m
  One Pod, One remote volume.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3043[0m
    One Pod, Single remote volume.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3060[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.NicVFsSchedulingWithCustomQos Daily AT_Scheduling-2.1 Qos[0m [90mPod with custom qos(180K iops) should schedule on one nicID and pods with high qos should schedule on other nicID[0m 
  [1mCreate pods and check scheduling on nicID(s)[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3290[0m
[BeforeEach] Pod with custom qos(180K iops) should schedule on one nicID and pods with high qos should schedule on other nicID
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3275
    DEBUG: 2018/09/27 06:33:42 START_TEST RemoteStorage.NicVFsSchedulingWithCustomQos
    DEBUG: 2018/09/27 06:33:42 Login to cluster
    DEBUG: 2018/09/27 06:33:42 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 06:33:42 Checking basic Vnic usage
    DEBUG: 2018/09/27 06:33:42 Updating inventory struct
[It] Create pods and check scheduling on nicID(s)
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3290
    DEBUG: 2018/09/27 06:33:49 Create the perf-tier custom with 180K iops
    DEBUG: 2018/09/27 06:33:54 Creating 1 pod and 1 remote volume with custom qos: 
    DEBUG: 2018/09/27 06:33:54 Create 1 remote volumes: 
    DEBUG: 2018/09/27 06:33:55 Create 1 fio pod(s):
    DEBUG: 2018/09/27 06:33:55 Creating fio pod: fio-pod-custom-1
    DEBUG: 2018/09/27 06:33:55 Checking if given pods are in Running state
    DEBUG: 2018/09/27 06:34:02 Creating 3 pods and 3 remote volumes with high qos: 
    DEBUG: 2018/09/27 06:34:02 Create 3 remote volumes: 
    DEBUG: 2018/09/27 06:34:06 Create 3 fio pod(s):
    DEBUG: 2018/09/27 06:34:06 Creating fio pod: fio-pod-high-1
    DEBUG: 2018/09/27 06:34:06 Creating fio pod: fio-pod-high-2
    DEBUG: 2018/09/27 06:34:06 Creating fio pod: fio-pod-high-3
    DEBUG: 2018/09/27 06:34:06 Checking if given pods are in Running state
    DEBUG: 2018/09/27 06:34:21 Pod scheduled as expected
    DEBUG: 2018/09/27 06:34:21 Deleting all the pods: 
    DEBUG: 2018/09/27 06:34:57 Delete the perf-tier custom
    DEBUG: 2018/09/27 06:34:57 Waitting for volume to move to "Available" state
    DEBUG: 2018/09/27 06:34:57 Deleting the volumes: 
[AfterEach] Pod with custom qos(180K iops) should schedule on one nicID and pods with high qos should schedule on other nicID
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3285
    DEBUG: 2018/09/27 06:36:42 END_TEST RemoteStorage.NicVFsSchedulingWithCustomQos Time-taken : 180.34974142

[32m• [SLOW TEST:180.350 seconds][0m
RemoteStorage.NicVFsSchedulingWithCustomQos Daily AT_Scheduling-2.1 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3263[0m
  Pod with custom qos(180K iops) should schedule on one nicID and pods with high qos should schedule on other nicID
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3265[0m
    Create pods and check scheduling on nicID(s)
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3290[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.OSBasedTargetReboot Weekly AT_Other-3.0 Qos[0m [90mReboot the node having volume.[0m 
  [1mReboot the node having volume.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:259[0m
[BeforeEach] Reboot the node having volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:245
    DEBUG: 2018/09/27 06:36:42 START_TEST RemoteStorage.OSBasedTargetReboot
    DEBUG: 2018/09/27 06:36:42 Login to cluster
    DEBUG: 2018/09/27 06:36:42 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 06:36:42 Checking basic Vnic usage
    DEBUG: 2018/09/27 06:36:43 Updating inventory struct
[It] Reboot the node having volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:259
    DEBUG: 2018/09/27 06:36:49 Creating 8 volumes. Mirror count: 1.
    DEBUG: 2018/09/27 06:36:58 Creating 8 fio pods: 
    DEBUG: 2018/09/27 06:37:01 Checking if given pods are in Running state
    DEBUG: 2018/09/27 06:37:16 Wait for volumes to move into attached state: 
    DEBUG: 2018/09/27 06:37:16 Waiting for 180 sec., so that prometheus database will have some stats...
    DEBUG: 2018/09/27 06:40:16 Validate qos for every volume: 
    DEBUG: 2018/09/27 06:40:16 Rebooting cluster node "bosserv5". Reboot Type: OS_BASED.
    DEBUG: 2018/09/27 06:40:16 Doing sync on 172.16.230.10
    DEBUG: 2018/09/27 06:40:17 Waiting till node goes down: 
    DEBUG: 2018/09/27 06:40:17 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:40:21 bosserv5 is pingable from local machine
    DEBUG: 2018/09/27 06:40:26 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:40:31 bosserv5 is pingable from local machine
    DEBUG: 2018/09/27 06:40:36 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:40:45 Cluster node "bosserv5" become unreachable.
    DEBUG: 2018/09/27 06:40:45 Checking reachability of rebooted node: bosserv5
    DEBUG: 2018/09/27 06:40:45 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:41:04 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:41:23 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:41:40 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:41:57 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:42:14 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:42:31 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:42:48 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:43:05 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 06:43:09 bosserv5 is pingable from local machine
    DEBUG: 2018/09/27 06:43:09 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2018/09/27 06:43:20 Nodes are up, waiting for armada to start
....    DEBUG: 2018/09/27 06:44:00 Waiting for all the nodes to go into Ready state

    DEBUG: 2018/09/27 06:44:00 Found '3' nodes
    DEBUG: 2018/09/27 06:44:34 All nodes are in ready state
    DEBUG: 2018/09/27 06:44:34 After power cycle/reboot, updating timestamp of node : bosserv5
    DEBUG: 2018/09/27 06:44:36 Deleting fio pods, after rebooting target node:
    DEBUG: 2018/09/27 06:44:36 Deleting pods : 
    DEBUG: 2018/09/27 06:44:56 After target node reboot & fio pod deletion, waiting for all volumes to come in "Available" state.
    DEBUG: 2018/09/27 06:44:56 After target node reboot & fio pod deletion, recreating pods: 
    DEBUG: 2018/09/27 06:45:39 Waiting for 180 sec., so that prometheus database will have some stats...
    DEBUG: 2018/09/27 06:48:39 Validate qos for every volume: 
    DEBUG: 2018/09/27 06:48:39 Delete Pods: 
    DEBUG: 2018/09/27 06:48:39 Deleting pods : 
    DEBUG: 2018/09/27 06:48:50 Wait for volumes to come in Available state: 
    DEBUG: 2018/09/27 06:48:50 Delete volumes: 
[AfterEach] Reboot the node having volume.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:254
    DEBUG: 2018/09/27 06:50:41 END_TEST RemoteStorage.OSBasedTargetReboot Time-taken : 839.553932392

[32m• [SLOW TEST:839.554 seconds][0m
RemoteStorage.OSBasedTargetReboot Weekly AT_Other-3.0 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:234[0m
  Reboot the node having volume.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:235[0m
    Reboot the node having volume.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/storage-pod.go:259[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.RebootInitiatorAndTarget Weekly RS_Reboot-1.4 Qos[0m [90mreboot initiator and target nodes after running IO and verify data before and after reboot[0m 
  [1mreboot initiator and target nodes after running IO and verify data before and after reboot[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2591[0m
[BeforeEach] reboot initiator and target nodes after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2573
    DEBUG: 2018/09/27 06:50:41 START_TEST RemoteStorage.RebootInitiatorAndTarget
    DEBUG: 2018/09/27 06:50:41 Login to cluster
    DEBUG: 2018/09/27 06:50:41 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 06:50:42 Checking basic Vnic usage
    DEBUG: 2018/09/27 06:50:42 Updating inventory struct
[It] reboot initiator and target nodes after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2591
    DEBUG: 2018/09/27 06:50:48 Verifying whether FBM and L1 usage is zero across all nodes
    DEBUG: 2018/09/27 06:51:03 FBM and L1 usage is Zero across all nodes

    DEBUG: 2018/09/27 06:51:03 Creating 8 volumes of random sizes
    DEBUG: 2018/09/27 06:51:03 Mirror Count: 1
    DEBUG: 2018/09/27 06:51:12 Attaching all 8 volumes
    DEBUG: 2018/09/27 06:51:48 Initiator node : bosserv5
    DEBUG: 2018/09/27 06:51:48 Nodes to reboot : bosserv5 bosserv4
    DEBUG: 2018/09/27 06:51:52 List of devices :  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1

    DEBUG: 2018/09/27 06:51:52 Running WRITE fio job on node : bosserv5
    DEBUG: 2018/09/27 06:51:52 FIO Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"efgh\"-12 --verify_interval=4096 --runtime=300 --blocksize=512K --iodepth=8  --time_based  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1

    DEBUG: 2018/09/27 06:56:53 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2018/09/27 06:56:53 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2018/09/27 06:56:53 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2018/09/27 06:56:53 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2018/09/27 06:56:53 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2018/09/27 06:56:53 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2018/09/27 06:56:53 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2018/09/27 06:56:54 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2018/09/27 07:03:38 Getting cluster quorum nodes
    DEBUG: 2018/09/27 07:03:38 Powering OFF the node bosserv5
    DEBUG: 2018/09/27 07:03:42 Node 172.16.230.10 took 4 seconds to power off
    DEBUG: 2018/09/27 07:03:42 Powering OFF the node bosserv4
    DEBUG: 2018/09/27 07:03:47 Node 172.16.230.8 took 5 seconds to power off
    DEBUG: 2018/09/27 07:03:47 Ensuring that bosserv5 node is unreachable: 
    DEBUG: 2018/09/27 07:03:47 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:03:56 Ensuring that bosserv4 node is unreachable: 
    DEBUG: 2018/09/27 07:03:56 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 07:04:25 Powering ON the node bosserv5
    DEBUG: 2018/09/27 07:04:26 Node 172.16.230.10 took 1 seconds to power on
    DEBUG: 2018/09/27 07:04:26 Powering ON the node bosserv4
    DEBUG: 2018/09/27 07:04:28 Node 172.16.230.8 took 1 seconds to power on
    DEBUG: 2018/09/27 07:04:28 Checking if node bosserv5 is reachable or not: 
    DEBUG: 2018/09/27 07:04:28 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:04:47 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:05:04 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:05:21 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:05:38 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:05:55 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:06:12 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:06:29 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:06:46 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:07:03 Executing ping command: ping  -c 5 -W 5 bosserv5
    DEBUG: 2018/09/27 07:07:07 bosserv5 is pingable from local machine
    DEBUG: 2018/09/27 07:07:07 Checking ssh port is up or not on node: bosserv5
    DEBUG: 2018/09/27 07:07:07 Checking if node bosserv4 is reachable or not: 
    DEBUG: 2018/09/27 07:07:07 Executing ping command: ping  -c 5 -W 5 bosserv4
    DEBUG: 2018/09/27 07:07:11 bosserv4 is pingable from local machine
    DEBUG: 2018/09/27 07:07:11 Checking ssh port is up or not on node: bosserv4
    DEBUG: 2018/09/27 07:07:41 Waiting for the node(s) to come up and rejoin the cluster
    DEBUG: 2018/09/27 07:07:41 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:07:44 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:07:47 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:07:50 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:07:53 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:07:56 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:07:59 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:02 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:05 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:08 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:11 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:14 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:17 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:18 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:19 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:20 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Error: . Retrying once again...
    DEBUG: 2018/09/27 07:08:21 Found '3' nodes
    DEBUG: 2018/09/27 07:08:32 All nodes are in ready state
    DEBUG: 2018/09/27 07:08:42 After power cycle/reboot, updating timestamp of node : bosserv5
    DEBUG: 2018/09/27 07:08:43 After power cycle/reboot, updating timestamp of node : bosserv4
    DEBUG: 2018/09/27 07:08:45 Getting cluster quorum nodes
    DEBUG: 2018/09/27 07:08:45 Updating timestamp of master, because cluster was not in quorum majority
    DEBUG: 2018/09/27 07:09:48 Updating inventory struct
    DEBUG: 2018/09/27 07:09:48 Waiting for nodes to come up, will wait upto 800 seconds
    DEBUG: 2018/09/27 07:10:00 Nodes are up, waiting for armada to start
.
    DEBUG: 2018/09/27 07:11:10 Waiting for the nodes to go into Ready state
    DEBUG: 2018/09/27 07:11:10 Found '3' nodes
    DEBUG: 2018/09/27 07:11:10 All nodes are in ready state
    DEBUG: 2018/09/27 07:11:10 Waiting for volumes to come into Attached state after rebooting cluster nodes.
    DEBUG: 2018/09/27 07:11:10 Detaching all 8 volumes
    DEBUG: 2018/09/27 07:11:14 Re-attaching all 8 volumes
    DEBUG: 2018/09/27 07:11:57 Comparing Volume's UUID with nvme id-ns for all volumes
    DEBUG: 2018/09/27 07:12:01 Comparing the device path & uuid on initiator before and after reboot
    DEBUG: 2018/09/27 07:12:35 Calculating cksum for volume test-vol1 and plex p0
    DEBUG: 2018/09/27 07:12:35 Calculating cksum for volume test-vol2 and plex p0
    DEBUG: 2018/09/27 07:12:35 Calculating cksum for volume test-vol3 and plex p0
    DEBUG: 2018/09/27 07:12:35 Calculating cksum for volume test-vol4 and plex p0
    DEBUG: 2018/09/27 07:12:35 Calculating cksum for volume test-vol5 and plex p0
    DEBUG: 2018/09/27 07:12:35 Calculating cksum for volume test-vol6 and plex p0
    DEBUG: 2018/09/27 07:12:35 Calculating cksum for volume test-vol7 and plex p0
    DEBUG: 2018/09/27 07:12:35 Calculating cksum for volume test-vol8 and plex p0
    DEBUG: 2018/09/27 07:18:40 Successfully completed Verification on all the volumes
    DEBUG: 2018/09/27 07:18:40 Detach & Delete all volumes
[AfterEach] reboot initiator and target nodes after running IO and verify data before and after reboot
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2586
    DEBUG: 2018/09/27 07:34:22 END_TEST RemoteStorage.RebootInitiatorAndTarget Time-taken : 2621.044665824

[32m• [SLOW TEST:2621.045 seconds][0m
RemoteStorage.RebootInitiatorAndTarget Weekly RS_Reboot-1.4 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2566[0m
  reboot initiator and target nodes after running IO and verify data before and after reboot
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2568[0m
    reboot initiator and target nodes after running IO and verify data before and after reboot
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:2591[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.Basic Weekly RS_Basic-1.1 RS_Basic-1.2 RS_Basic-1.3 RS_Basic-1.5 RS_Verify-1.0 RS_Stress-1.1[0m [90mRemote Storage volume basic test for weekly[0m 
  [1mremote storage volume basic operations[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1074[0m
[BeforeEach] Remote Storage volume basic test for weekly
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1058
    DEBUG: 2018/09/27 07:34:22 START_TEST RemoteStorage.Basic
    DEBUG: 2018/09/27 07:34:22 Login to cluster
    DEBUG: 2018/09/27 07:34:22 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 07:34:23 Checking basic Vnic usage
    DEBUG: 2018/09/27 07:34:23 Updating inventory struct
[It] remote storage volume basic operations
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1074
    DEBUG: 2018/09/27 07:34:30 Pick up bosserv4 as targetNode and bosserv5 as initiatorNode
    DEBUG: 2018/09/27 07:34:30 Computing total available storage space on targetNode bosserv4
    DEBUG: 2018/09/27 07:34:30 Storage available : 3051037392896, capacity : 3051037392896
    DEBUG: 2018/09/27 07:34:30 Create volumes until vol-size is >  max free space on targetNode or maxvols created
    DEBUG: 2018/09/27 07:35:43 Attach all 64 volumes of bosserv4 on bosserv5
    DEBUG: 2018/09/27 07:40:57 List of devices :  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:40:57 Running WRITE IOs with SHA512 checksum : IO SIZE (4K)
    DEBUG: 2018/09/27 07:40:57 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize=4K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:41:33 output : job1: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job6: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job7: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job8: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job9: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job10: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job11: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job12: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job13: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job14: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job15: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job16: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job17: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job18: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job19: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job20: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job21: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job22: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job23: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job24: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job25: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job26: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job27: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job28: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job29: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job30: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job31: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job32: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job33: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job34: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job35: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job36: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job37: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job38: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job39: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job40: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job41: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job42: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job43: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job44: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job45: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job46: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job47: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job48: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job49: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job50: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job51: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job52: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job53: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job54: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job55: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job56: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job57: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job58: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job59: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job60: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job61: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job62: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job63: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job64: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=64): [w(64)][17.1%][r=0KiB/s,w=17.4MiB/s][r=0,w=4433 IOPS][eta 00m:29s]Jobs: 64 (f=64): [w(64)][20.0%][r=0KiB/s,w=591MiB/s][r=0,w=151k IOPS][eta 00m:28s] Jobs: 64 (f=64): [w(64)][22.9%][r=0KiB/s,w=617MiB/s][r=0,w=158k IOPS][eta 00m:27s]Jobs: 64 (f=64): [w(64)][25.7%][r=0KiB/s,w=598MiB/s][r=0,w=153k IOPS][eta 00m:26s]Jobs: 64 (f=64): [w(64)][28.6%][r=0KiB/s,w=640MiB/s][r=0,w=164k IOPS][eta 00m:25s]Jobs: 64 (f=64): [w(64)][31.4%][r=0KiB/s,w=647MiB/s][r=0,w=166k IOPS][eta 00m:24s]Jobs: 64 (f=64): [w(64)][34.3%][r=0KiB/s,w=657MiB/s][r=0,w=168k IOPS][eta 00m:23s]Jobs: 64 (f=64): [w(64)][37.1%][r=0KiB/s,w=660MiB/s][r=0,w=169k IOPS][eta 00m:22s]Jobs: 64 (f=64): [w(64)][40.0%][r=0KiB/s,w=670MiB/s][r=0,w=172k IOPS][eta 00m:21s]Jobs: 64 (f=64): [w(64)][42.9%][r=0KiB/s,w=668MiB/s][r=0,w=171k IOPS][eta 00m:20s]Jobs: 64 (f=64): [w(64)][45.7%][r=0KiB/s,w=674MiB/s][r=0,w=173k IOPS][eta 00m:19s]Jobs: 64 (f=64): [w(64)][48.6%][r=0KiB/s,w=675MiB/s][r=0,w=173k IOPS][eta 00m:18s]Jobs: 64 (f=64): [w(64)][51.4%][r=0KiB/s,w=683MiB/s][r=0,w=175k IOPS][eta 00m:17s]Jobs: 64 (f=64): [w(64)][54.3%][r=0KiB/s,w=679MiB/s][r=0,w=174k IOPS][eta 00m:16s]Jobs: 64 (f=64): [w(64)][57.1%][r=0KiB/s,w=685MiB/s][r=0,w=175k IOPS][eta 00m:15s]Jobs: 64 (f=64): [w(64)][60.0%][r=0KiB/s,w=685MiB/s][r=0,w=175k IOPS][eta 00m:14s]Jobs: 64 (f=64): [w(64)][62.9%][r=0KiB/s,w=692MiB/s][r=0,w=177k IOPS][eta 00m:13s]Jobs: 64 (f=64): [w(64)][65.7%][r=0KiB/s,w=689MiB/s][r=0,w=176k IOPS][eta 00m:12s]Jobs: 64 (f=64): [w(64)][68.6%][r=0KiB/s,w=689MiB/s][r=0,w=176k IOPS][eta 00m:11s]Jobs: 64 (f=64): [w(64)][71.4%][r=0KiB/s,w=693MiB/s][r=0,w=177k IOPS][eta 00m:10s]Jobs: 64 (f=64): [w(64)][74.3%][r=0KiB/s,w=694MiB/s][r=0,w=178k IOPS][eta 00m:09s]Jobs: 64 (f=64): [w(64)][77.1%][r=0KiB/s,w=691MiB/s][r=0,w=177k IOPS][eta 00m:08s]Jobs: 64 (f=64): [w(64)][80.0%][r=0KiB/s,w=690MiB/s][r=0,w=177k IOPS][eta 00m:07s]Jobs: 64 (f=64): [w(64)][82.9%][r=0KiB/s,w=692MiB/s][r=0,w=177k IOPS][eta 00m:06s]Jobs: 64 (f=64): [w(64)][85.7%][r=0KiB/s,w=696MiB/s][r=0,w=178k IOPS][eta 00m:05s]Jobs: 64 (f=64): [w(64)][88.6%][r=0KiB/s,w=698MiB/s][r=0,w=179k IOPS][eta 00m:04s]Jobs: 64 (f=64): [w(64)][91.4%][r=0KiB/s,w=694MiB/s][r=0,w=178k IOPS][eta 00m:03s]Jobs: 64 (f=64): [w(64)][94.3%][r=0KiB/s,w=694MiB/s][r=0,w=178k IOPS][eta 00m:02s]Jobs: 64 (f=64): [w(64)][97.1%][r=0KiB/s,w=696MiB/s][r=0,w=178k IOPS][eta 00m:01s]Jobs: 64 (f=64): [w(64)][100.0%][r=0KiB/s,w=694MiB/s][r=0,w=178k IOPS][eta 00m:00s]
job1: (groupid=0, jobs=64): err= 0: pid=24140: Thu Sep 27 07:41:33 2018
  write: IOPS=172k, BW=673MiB/s (706MB/s)(19.8GiB/30001msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=5.33%, sys=1.85%, ctx=5177886, majf=0, minf=38381
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,5169853,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=673MiB/s (706MB/s), 673MiB/s-673MiB/s (706MB/s-706MB/s), io=19.8GiB (21.2GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=43/82465, merge=0/0, ticks=6/27913, in_queue=27905, util=79.61%
  nvme2n1: ios=43/82273, merge=0/0, ticks=6/27902, in_queue=27889, util=79.90%
  nvme3n1: ios=43/82142, merge=0/0, ticks=10/27785, in_queue=27773, util=79.85%
  nvme4n1: ios=43/81915, merge=0/0, ticks=11/27698, in_queue=27687, util=79.92%
  nvme5n1: ios=43/81932, merge=0/0, ticks=7/27830, in_queue=27825, util=80.65%
  nvme6n1: ios=43/81884, merge=0/0, ticks=10/27881, in_queue=27886, util=81.14%
  nvme7n1: ios=43/81944, merge=0/0, ticks=7/27784, in_queue=27776, util=81.18%
  nvme8n1: ios=43/81953, merge=0/0, ticks=14/27802, in_queue=27797, util=81.59%
  nvme9n1: ios=43/81701, merge=0/0, ticks=13/27863, in_queue=27861, util=82.14%
  nvme10n1: ios=43/81719, merge=0/0, ticks=18/27898, in_queue=27897, util=82.24%
  nvme11n1: ios=45/81718, merge=0/0, ticks=16/27751, in_queue=27750, util=81.84%
  nvme12n1: ios=45/81643, merge=0/0, ticks=15/27833, in_queue=27833, util=82.12%
  nvme13n1: ios=45/81505, merge=0/0, ticks=11/27761, in_queue=27762, util=81.95%
  nvme14n1: ios=45/81584, merge=0/0, ticks=9/27757, in_queue=27747, util=81.95%
  nvme15n1: ios=45/81293, merge=0/0, ticks=18/27708, in_queue=27712, util=81.87%
  nvme16n1: ios=45/81598, merge=0/0, ticks=22/27813, in_queue=27817, util=82.20%
  nvme17n1: ios=45/80569, merge=0/0, ticks=19/27772, in_queue=27742, util=82.05%
  nvme18n1: ios=45/81263, merge=0/0, ticks=12/27920, in_queue=27919, util=82.66%
  nvme19n1: ios=45/81011, merge=0/0, ticks=10/27808, in_queue=27804, util=82.39%
  nvme20n1: ios=45/81262, merge=0/0, ticks=16/27840, in_queue=27843, util=82.54%
  nvme21n1: ios=45/81172, merge=0/0, ticks=12/27793, in_queue=27789, util=82.49%
  nvme22n1: ios=45/80965, merge=0/0, ticks=13/27790, in_queue=27793, util=82.57%
  nvme23n1: ios=45/81151, merge=0/0, ticks=15/27847, in_queue=27843, util=82.80%
  nvme24n1: ios=45/80858, merge=0/0, ticks=12/27812, in_queue=27805, util=82.78%
  nvme25n1: ios=45/81030, merge=0/0, ticks=14/27781, in_queue=27784, util=82.81%
  nvme26n1: ios=45/80788, merge=0/0, ticks=10/27890, in_queue=27882, util=83.21%
  nvme27n1: ios=45/80748, merge=0/0, ticks=10/27871, in_queue=27865, util=83.27%
  nvme28n1: ios=45/80819, merge=0/0, ticks=18/27881, in_queue=27880, util=83.40%
  nvme29n1: ios=45/80770, merge=0/0, ticks=14/27821, in_queue=27832, util=83.39%
  nvme30n1: ios=45/80686, merge=0/0, ticks=8/27925, in_queue=27918, util=83.79%
  nvme31n1: ios=45/80687, merge=0/0, ticks=13/27731, in_queue=27731, util=83.35%
  nvme32n1: ios=45/80731, merge=0/0, ticks=10/27804, in_queue=27801, util=83.71%
  nvme33n1: ios=45/80635, merge=0/0, ticks=19/27850, in_queue=27854, util=84.01%
  nvme34n1: ios=45/80570, merge=0/0, ticks=20/27857, in_queue=27870, util=84.20%
  nvme35n1: ios=45/80396, merge=0/0, ticks=10/27922, in_queue=27920, util=84.55%
  nvme36n1: ios=45/80438, merge=0/0, ticks=19/27876, in_queue=27884, util=84.57%
  nvme37n1: ios=45/80408, merge=0/0, ticks=17/27801, in_queue=27792, util=84.47%
  nvme38n1: ios=45/79972, merge=0/0, ticks=23/27773, in_queue=27784, util=84.59%
  nvme39n1: ios=45/80076, merge=0/0, ticks=17/27865, in_queue=27869, util=85.04%
  nvme40n1: ios=45/80504, merge=0/0, ticks=16/27800, in_queue=27801, util=85.01%
  nvme41n1: ios=45/80324, merge=0/0, ticks=22/27879, in_queue=27888, util=85.47%
  nvme42n1: ios=45/80292, merge=0/0, ticks=16/27804, in_queue=27812, util=85.43%
  nvme43n1: ios=45/80160, merge=0/0, ticks=8/27901, in_queue=27890, util=85.89%
  nvme44n1: ios=43/80007, merge=0/0, ticks=12/27886, in_queue=27879, util=86.05%
  nvme45n1: ios=43/79828, merge=0/0, ticks=13/27834, in_queue=27834, util=86.13%
  nvme46n1: ios=43/80032, merge=0/0, ticks=21/27804, in_queue=27811, util=86.26%
  nvme47n1: ios=43/79769, merge=0/0, ticks=16/27905, in_queue=27911, util=86.82%
  nvme48n1: ios=43/79743, merge=0/0, ticks=10/27889, in_queue=27887, util=87.00%
  nvme49n1: ios=43/79901, merge=0/0, ticks=19/27884, in_queue=27890, util=87.24%
  nvme50n1: ios=43/79742, merge=0/0, ticks=23/27889, in_queue=27897, util=87.48%
  nvme51n1: ios=43/79752, merge=0/0, ticks=17/27832, in_queue=27839, util=87.59%
  nvme52n1: ios=43/79783, merge=0/0, ticks=17/27892, in_queue=27892, util=88.03%
  nvme53n1: ios=43/79651, merge=0/0, ticks=16/27772, in_queue=27775, util=87.92%
  nvme54n1: ios=43/79557, merge=0/0, ticks=12/27866, in_queue=27868, util=88.51%
  nvme55n1: ios=43/79538, merge=0/0, ticks=18/27959, in_queue=27964, util=89.10%
  nvme56n1: ios=43/79700, merge=0/0, ticks=15/27895, in_queue=27899, util=89.19%
  nvme57n1: ios=43/79431, merge=0/0, ticks=19/27842, in_queue=27849, util=89.37%
  nvme58n1: ios=43/79323, merge=0/0, ticks=11/27863, in_queue=27861, util=89.76%
  nvme59n1: ios=43/79262, merge=0/0, ticks=11/27872, in_queue=27869, util=90.23%
  nvme60n1: ios=43/79114, merge=0/0, ticks=14/27942, in_queue=27938, util=90.95%
  nvme61n1: ios=43/79108, merge=0/0, ticks=18/27819, in_queue=27821, util=91.06%
  nvme62n1: ios=43/79228, merge=0/0, ticks=24/27880, in_queue=27891, util=91.90%
  nvme63n1: ios=43/78983, merge=0/0, ticks=8/27766, in_queue=27767, util=92.03%
  nvme64n1: ios=43/79092, merge=0/0, ticks=16/27824, in_queue=27827, util=92.71%


    DEBUG: 2018/09/27 07:41:33 Running VERIFY IOs with SHA512 checksum : IO SIZE (4K)
    DEBUG: 2018/09/27 07:41:33 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:42:02 output : job1: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job6: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job7: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job8: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job9: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job10: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job11: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job12: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job13: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job14: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job15: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job16: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job17: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job18: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job19: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job20: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job21: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job22: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job23: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job24: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job25: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job26: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job27: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job28: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job29: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job30: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job31: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job32: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job33: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job34: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job35: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job36: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job37: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job38: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job39: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job40: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job41: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job42: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job43: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job44: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job45: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job46: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job47: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job48: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job49: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job50: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job51: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job52: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job53: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job54: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job55: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job56: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job57: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job58: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job59: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job60: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job61: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job62: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job63: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job64: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=64): [V(64)][0.0%][r=22.1MiB/s,w=0KiB/s][r=5655,w=0 IOPS][eta 11h:21m:07s]Jobs: 64 (f=64): [V(64)][0.1%][r=825MiB/s,w=0KiB/s][r=211k,w=0 IOPS][eta 02h:27m:34s] Jobs: 64 (f=64): [V(64)][0.1%][r=788MiB/s,w=0KiB/s][r=202k,w=0 IOPS][eta 02h:00m:15s]Jobs: 64 (f=64): [V(64)][0.1%][r=830MiB/s,w=0KiB/s][r=213k,w=0 IOPS][eta 01h:48m:15s]Jobs: 64 (f=64): [V(64)][0.2%][r=833MiB/s,w=0KiB/s][r=213k,w=0 IOPS][eta 01h:42m:16s]Jobs: 64 (f=64): [V(64)][0.2%][r=831MiB/s,w=0KiB/s][r=213k,w=0 IOPS][eta 01h:38m:51s]Jobs: 64 (f=64): [V(64)][0.2%][r=825MiB/s,w=0KiB/s][r=211k,w=0 IOPS][eta 01h:36m:26s]Jobs: 64 (f=64): [V(64)][0.2%][r=818MiB/s,w=0KiB/s][r=209k,w=0 IOPS][eta 01h:34m:40s]Jobs: 64 (f=64): [V(64)][0.2%][r=822MiB/s,w=0KiB/s][r=210k,w=0 IOPS][eta 01h:33m:22s]Jobs: 64 (f=64): [V(64)][0.3%][r=870MiB/s,w=0KiB/s][r=223k,w=0 IOPS][eta 01h:31m:47s]Jobs: 64 (f=64): [V(64)][0.3%][r=916MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:30m:02s]Jobs: 64 (f=64): [V(64)][0.3%][r=915MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:28m:40s]Jobs: 64 (f=64): [V(64)][0.3%][r=915MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:27m:30s]Jobs: 64 (f=64): [V(64)][0.4%][r=915MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:26m:33s]Jobs: 64 (f=64): [V(64)][0.4%][r=915MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:25m:47s]Jobs: 64 (f=64): [V(64)][0.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:25m:05s]Jobs: 64 (f=64): [V(64)][0.4%][r=915MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:24m:29s]Jobs: 64 (f=64): [V(64)][0.5%][r=917MiB/s,w=0KiB/s][r=235k,w=0 IOPS][eta 01h:23m:56s]Jobs: 64 (f=64): [V(64)][0.5%][r=917MiB/s,w=0KiB/s][r=235k,w=0 IOPS][eta 01h:23m:27s]Jobs: 64 (f=64): [V(64)][0.5%][r=917MiB/s,w=0KiB/s][r=235k,w=0 IOPS][eta 01h:23m:00s]Jobs: 64 (f=64): [V(64)][0.5%][r=918MiB/s,w=0KiB/s][r=235k,w=0 IOPS][eta 01h:22m:36s]Jobs: 64 (f=64): [V(64)][0.5%][r=918MiB/s,w=0KiB/s][r=235k,w=0 IOPS][eta 01h:22m:15s]Jobs: 64 (f=64): [V(64)][0.6%][r=917MiB/s,w=0KiB/s][r=235k,w=0 IOPS][eta 01h:21m:56s]Jobs: 11 (f=11): [V(11),_(53)][3.4%][r=716MiB/s,w=0KiB/s][r=183k,w=0 IOPS][eta 13m:46s]
job1: (groupid=0, jobs=64): err= 0: pid=24820: Thu Sep 27 07:42:02 2018
   read: IOPS=222k, BW=867MiB/s (909MB/s)(19.8GiB/23298msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=6.44%, sys=1.98%, ctx=5173028, majf=0, minf=23192
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=5169853,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=867MiB/s (909MB/s), 867MiB/s-867MiB/s (909MB/s-909MB/s), io=19.8GiB (21.2GB), run=23298-23298msec

Disk stats (read/write):
  nvme1n1: ios=82113/0, merge=0/0, ticks=21261/0, in_queue=21249, util=75.02%
  nvme2n1: ios=82006/0, merge=0/0, ticks=21251/0, in_queue=21237, util=75.38%
  nvme3n1: ios=81777/0, merge=0/0, ticks=21348/0, in_queue=21327, util=76.02%
  nvme4n1: ios=81928/0, merge=0/0, ticks=21208/0, in_queue=21196, util=75.96%
  nvme5n1: ios=81748/0, merge=0/0, ticks=21228/0, in_queue=21218, util=76.39%
  nvme6n1: ios=82006/0, merge=0/0, ticks=21273/0, in_queue=21266, util=76.99%
  nvme7n1: ios=81851/0, merge=0/0, ticks=21275/0, in_queue=21268, util=77.45%
  nvme8n1: ios=82087/0, merge=0/0, ticks=21237/0, in_queue=21223, util=77.71%
  nvme9n1: ios=81778/0, merge=0/0, ticks=21260/0, in_queue=21246, util=78.23%
  nvme10n1: ios=81911/0, merge=0/0, ticks=21347/0, in_queue=21336, util=78.54%
  nvme11n1: ios=81568/0, merge=0/0, ticks=21299/0, in_queue=21287, util=78.43%
  nvme12n1: ios=80981/0, merge=0/0, ticks=21003/0, in_queue=20999, util=78.10%
  nvme13n1: ios=81009/0, merge=0/0, ticks=21002/0, in_queue=20989, util=78.14%
  nvme14n1: ios=80863/0, merge=0/0, ticks=21014/0, in_queue=21002, util=78.18%
  nvme15n1: ios=81056/0, merge=0/0, ticks=21067/0, in_queue=21052, util=78.49%
  nvme16n1: ios=81152/0, merge=0/0, ticks=21098/0, in_queue=21080, util=78.60%
  nvme17n1: ios=80654/0, merge=0/0, ticks=21027/0, in_queue=21002, util=78.37%
  nvme18n1: ios=80655/0, merge=0/0, ticks=20994/0, in_queue=20978, util=78.36%
  nvme19n1: ios=80585/0, merge=0/0, ticks=21063/0, in_queue=21050, util=78.71%
  nvme20n1: ios=80661/0, merge=0/0, ticks=21029/0, in_queue=21016, util=78.68%
  nvme21n1: ios=80554/0, merge=0/0, ticks=21033/0, in_queue=21018, util=78.76%
  nvme22n1: ios=80916/0, merge=0/0, ticks=21011/0, in_queue=21000, util=78.77%
  nvme23n1: ios=80711/0, merge=0/0, ticks=21030/0, in_queue=21014, util=78.94%
  nvme24n1: ios=80751/0, merge=0/0, ticks=20973/0, in_queue=20959, util=78.85%
  nvme25n1: ios=80581/0, merge=0/0, ticks=20922/0, in_queue=20902, util=78.75%
  nvme26n1: ios=80664/0, merge=0/0, ticks=21076/0, in_queue=21065, util=79.44%
  nvme27n1: ios=80581/0, merge=0/0, ticks=21021/0, in_queue=21004, util=79.40%
  nvme28n1: ios=80846/0, merge=0/0, ticks=21050/0, in_queue=21035, util=79.61%
  nvme29n1: ios=80691/0, merge=0/0, ticks=21054/0, in_queue=21041, util=79.81%
  nvme30n1: ios=79909/0, merge=0/0, ticks=20826/0, in_queue=20815, util=79.83%
  nvme31n1: ios=80684/0, merge=0/0, ticks=21112/0, in_queue=21096, util=80.32%
  nvme32n1: ios=80876/0, merge=0/0, ticks=21089/0, in_queue=21070, util=80.35%
  nvme33n1: ios=80666/0, merge=0/0, ticks=21014/0, in_queue=20997, util=80.22%
  nvme34n1: ios=79825/0, merge=0/0, ticks=20776/0, in_queue=20765, util=80.30%
  nvme35n1: ios=80579/0, merge=0/0, ticks=21101/0, in_queue=21092, util=80.97%
  nvme36n1: ios=79844/0, merge=0/0, ticks=20814/0, in_queue=20798, util=80.78%
  nvme37n1: ios=80571/0, merge=0/0, ticks=21058/0, in_queue=21050, util=81.22%
  nvme38n1: ios=79915/0, merge=0/0, ticks=20774/0, in_queue=20766, util=81.06%
  nvme39n1: ios=79708/0, merge=0/0, ticks=20917/0, in_queue=20902, util=81.83%
  nvme40n1: ios=79763/0, merge=0/0, ticks=20895/0, in_queue=20886, util=81.98%
  nvme41n1: ios=79737/0, merge=0/0, ticks=20775/0, in_queue=20765, util=81.72%
  nvme42n1: ios=79591/0, merge=0/0, ticks=20723/0, in_queue=20712, util=81.78%
  nvme43n1: ios=79874/0, merge=0/0, ticks=20819/0, in_queue=20802, util=82.35%
  nvme44n1: ios=80084/0, merge=0/0, ticks=20856/0, in_queue=20850, util=82.77%
  nvme45n1: ios=79394/0, merge=0/0, ticks=20881/0, in_queue=20869, util=83.14%
  nvme46n1: ios=79750/0, merge=0/0, ticks=20780/0, in_queue=20771, util=83.02%
  nvme47n1: ios=79603/0, merge=0/0, ticks=20722/0, in_queue=20706, util=83.05%
  nvme48n1: ios=79836/0, merge=0/0, ticks=20828/0, in_queue=20812, util=83.79%
  nvme49n1: ios=79556/0, merge=0/0, ticks=20827/0, in_queue=20809, util=84.07%
  nvme50n1: ios=79132/0, merge=0/0, ticks=20573/0, in_queue=20560, util=84.18%
  nvme51n1: ios=79724/0, merge=0/0, ticks=20701/0, in_queue=20688, util=84.26%
  nvme52n1: ios=79893/0, merge=0/0, ticks=20709/0, in_queue=20687, util=84.56%
  nvme53n1: ios=79856/0, merge=0/0, ticks=20790/0, in_queue=20784, util=85.44%
  nvme54n1: ios=78851/0, merge=0/0, ticks=20591/0, in_queue=20578, util=85.96%
  nvme55n1: ios=79477/0, merge=0/0, ticks=20775/0, in_queue=20766, util=86.37%
  nvme56n1: ios=79001/0, merge=0/0, ticks=20615/0, in_queue=20604, util=87.09%
  nvme57n1: ios=78803/0, merge=0/0, ticks=20635/0, in_queue=20621, util=87.67%
  nvme58n1: ios=79114/0, merge=0/0, ticks=20513/0, in_queue=20506, util=87.76%
  nvme59n1: ios=78675/0, merge=0/0, ticks=20594/0, in_queue=20586, util=88.52%
  nvme60n1: ios=78616/0, merge=0/0, ticks=20523/0, in_queue=20507, util=88.57%
  nvme61n1: ios=78809/0, merge=0/0, ticks=20551/0, in_queue=20541, util=89.45%
  nvme62n1: ios=78774/0, merge=0/0, ticks=20610/0, in_queue=20595, util=90.27%
  nvme63n1: ios=78655/0, merge=0/0, ticks=20567/0, in_queue=20553, util=90.74%
  nvme64n1: ios=79099/0, merge=0/0, ticks=20550/0, in_queue=20535, util=91.30%


    DEBUG: 2018/09/27 07:42:02 Running WRITE IOs with SHA512 checksum : IO SIZE (64K)
    DEBUG: 2018/09/27 07:42:02 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize=64K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:42:39 output : job1: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job6: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job7: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job8: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job9: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job10: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job11: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job12: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job13: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job14: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job15: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job16: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job17: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job18: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job19: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job20: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job21: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job22: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job23: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job24: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job25: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job26: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job27: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job28: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job29: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job30: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job31: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job32: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job33: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job34: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job35: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job36: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job37: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job38: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job39: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job40: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job41: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job42: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job43: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job44: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job45: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job46: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job47: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job48: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job49: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job50: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job51: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job52: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job53: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job54: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job55: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job56: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job57: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job58: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job59: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job60: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job61: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job62: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job63: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job64: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=64): [w(64)][17.1%][r=0KiB/s,w=61.3MiB/s][r=0,w=976 IOPS][eta 00m:29s]Jobs: 64 (f=64): [w(64)][20.0%][r=0KiB/s,w=2171MiB/s][r=0,w=34.8k IOPS][eta 00m:28s]Jobs: 64 (f=64): [w(64)][22.9%][r=0KiB/s,w=2141MiB/s][r=0,w=34.3k IOPS][eta 00m:27s]Jobs: 64 (f=64): [w(64)][25.7%][r=0KiB/s,w=2136MiB/s][r=0,w=34.2k IOPS][eta 00m:26s]Jobs: 64 (f=64): [w(64)][28.6%][r=0KiB/s,w=2128MiB/s][r=0,w=34.5k IOPS][eta 00m:25s]Jobs: 64 (f=64): [w(64)][31.4%][r=0KiB/s,w=2094MiB/s][r=0,w=33.6k IOPS][eta 00m:24s]Jobs: 64 (f=64): [w(64)][34.3%][r=0KiB/s,w=2161MiB/s][r=0,w=34.6k IOPS][eta 00m:23s]Jobs: 64 (f=64): [w(64)][37.1%][r=0KiB/s,w=2143MiB/s][r=0,w=34.3k IOPS][eta 00m:22s]Jobs: 64 (f=64): [w(64)][40.0%][r=0KiB/s,w=2175MiB/s][r=0,w=34.8k IOPS][eta 00m:21s]Jobs: 64 (f=64): [w(64)][42.9%][r=0KiB/s,w=2159MiB/s][r=0,w=34.6k IOPS][eta 00m:20s]Jobs: 64 (f=64): [w(64)][45.7%][r=0KiB/s,w=2228MiB/s][r=0,w=35.7k IOPS][eta 00m:19s]Jobs: 64 (f=64): [w(64)][48.6%][r=0KiB/s,w=2117MiB/s][r=0,w=33.9k IOPS][eta 00m:18s]Jobs: 64 (f=64): [w(64)][51.4%][r=0KiB/s,w=2220MiB/s][r=0,w=35.6k IOPS][eta 00m:17s]Jobs: 64 (f=64): [w(64)][54.3%][r=0KiB/s,w=2088MiB/s][r=0,w=33.5k IOPS][eta 00m:16s]Jobs: 64 (f=64): [w(64)][57.1%][r=0KiB/s,w=2082MiB/s][r=0,w=33.4k IOPS][eta 00m:15s]Jobs: 64 (f=64): [w(64)][60.0%][r=0KiB/s,w=2140MiB/s][r=0,w=34.3k IOPS][eta 00m:14s]Jobs: 64 (f=64): [w(64)][62.9%][r=0KiB/s,w=2109MiB/s][r=0,w=33.8k IOPS][eta 00m:13s]Jobs: 64 (f=64): [w(64)][65.7%][r=0KiB/s,w=2217MiB/s][r=0,w=35.5k IOPS][eta 00m:12s]Jobs: 64 (f=64): [w(64)][68.6%][r=0KiB/s,w=2131MiB/s][r=0,w=34.2k IOPS][eta 00m:11s]Jobs: 64 (f=64): [w(64)][71.4%][r=0KiB/s,w=2232MiB/s][r=0,w=35.8k IOPS][eta 00m:10s]Jobs: 64 (f=64): [w(64)][74.3%][r=0KiB/s,w=2118MiB/s][r=0,w=33.9k IOPS][eta 00m:09s]Jobs: 64 (f=64): [w(64)][77.1%][r=0KiB/s,w=2149MiB/s][r=0,w=34.4k IOPS][eta 00m:08s]Jobs: 64 (f=64): [w(64)][80.0%][r=0KiB/s,w=2173MiB/s][r=0,w=34.8k IOPS][eta 00m:07s]Jobs: 64 (f=64): [w(64)][82.9%][r=0KiB/s,w=2140MiB/s][r=0,w=34.3k IOPS][eta 00m:06s]Jobs: 64 (f=64): [w(64)][85.7%][r=0KiB/s,w=2207MiB/s][r=0,w=35.4k IOPS][eta 00m:05s]Jobs: 64 (f=64): [w(64)][88.6%][r=0KiB/s,w=2140MiB/s][r=0,w=34.3k IOPS][eta 00m:04s]Jobs: 64 (f=64): [w(64)][91.4%][r=0KiB/s,w=2165MiB/s][r=0,w=34.7k IOPS][eta 00m:03s]Jobs: 64 (f=64): [w(64)][94.3%][r=0KiB/s,w=2161MiB/s][r=0,w=34.6k IOPS][eta 00m:02s]Jobs: 64 (f=64): [w(64)][97.1%][r=0KiB/s,w=2192MiB/s][r=0,w=35.8k IOPS][eta 00m:01s]Jobs: 64 (f=64): [w(64)][100.0%][r=0KiB/s,w=2149MiB/s][r=0,w=34.4k IOPS][eta 00m:00s]
job1: (groupid=0, jobs=64): err= 0: pid=25494: Thu Sep 27 07:42:39 2018
  write: IOPS=34.5k, BW=2155MiB/s (2260MB/s)(63.2GiB/30003msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=15.46%, sys=0.58%, ctx=1037775, majf=0, minf=13035
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,1034527,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=2155MiB/s (2260MB/s), 2155MiB/s-2155MiB/s (2260MB/s-2260MB/s), io=63.2GiB (67.8GB), run=30003-30003msec

Disk stats (read/write):
  nvme1n1: ios=43/16189, merge=0/0, ticks=13/25195, in_queue=25206, util=71.33%
  nvme2n1: ios=43/16118, merge=0/0, ticks=11/25142, in_queue=25150, util=71.47%
  nvme3n1: ios=43/16151, merge=0/0, ticks=130/25133, in_queue=25264, util=71.86%
  nvme4n1: ios=43/16138, merge=0/0, ticks=112/25197, in_queue=25307, util=72.40%
  nvme5n1: ios=43/16143, merge=0/0, ticks=114/25038, in_queue=25150, util=72.34%
  nvme6n1: ios=43/16147, merge=0/0, ticks=128/25263, in_queue=25390, util=73.37%
  nvme7n1: ios=43/16126, merge=0/0, ticks=103/25076, in_queue=25176, util=73.14%
  nvme8n1: ios=43/16040, merge=0/0, ticks=102/25045, in_queue=25147, util=73.39%
  nvme9n1: ios=43/16169, merge=0/0, ticks=110/25093, in_queue=25199, util=73.84%
  nvme10n1: ios=43/16123, merge=0/0, ticks=122/25196, in_queue=25311, util=74.18%
  nvme11n1: ios=43/16114, merge=0/0, ticks=110/25076, in_queue=25186, util=73.86%
  nvme12n1: ios=43/16132, merge=0/0, ticks=113/25153, in_queue=25264, util=74.12%
  nvme13n1: ios=45/16155, merge=0/0, ticks=104/25065, in_queue=25168, util=73.87%
  nvme14n1: ios=45/16076, merge=0/0, ticks=113/24971, in_queue=25084, util=73.65%
  nvme15n1: ios=45/16135, merge=0/0, ticks=109/24994, in_queue=25101, util=73.75%
  nvme16n1: ios=45/16119, merge=0/0, ticks=114/25184, in_queue=25293, util=74.33%
  nvme17n1: ios=45/16148, merge=0/0, ticks=105/25190, in_queue=25286, util=74.37%
  nvme18n1: ios=45/16075, merge=0/0, ticks=105/25013, in_queue=25116, util=73.96%
  nvme19n1: ios=45/16150, merge=0/0, ticks=106/25096, in_queue=25199, util=74.25%
  nvme20n1: ios=45/16151, merge=0/0, ticks=106/25183, in_queue=25288, util=74.58%
  nvme21n1: ios=45/16152, merge=0/0, ticks=107/24958, in_queue=25064, util=74.03%
  nvme22n1: ios=45/16087, merge=0/0, ticks=103/25041, in_queue=25144, util=74.39%
  nvme23n1: ios=45/16154, merge=0/0, ticks=110/24976, in_queue=25083, util=74.30%
  nvme24n1: ios=45/16131, merge=0/0, ticks=109/25242, in_queue=25348, util=75.19%
  nvme25n1: ios=45/16118, merge=0/0, ticks=105/25018, in_queue=25116, util=74.65%
  nvme26n1: ios=45/16100, merge=0/0, ticks=105/25082, in_queue=25187, util=74.97%
  nvme27n1: ios=45/16169, merge=0/0, ticks=103/25126, in_queue=25229, util=75.21%
  nvme28n1: ios=45/16063, merge=0/0, ticks=117/25057, in_queue=25169, util=75.15%
  nvme29n1: ios=45/16134, merge=0/0, ticks=104/24960, in_queue=25060, util=75.01%
  nvme30n1: ios=45/16121, merge=0/0, ticks=106/25177, in_queue=25279, util=75.81%
  nvme31n1: ios=45/16155, merge=0/0, ticks=106/25204, in_queue=25308, util=76.05%
  nvme32n1: ios=45/16107, merge=0/0, ticks=108/25155, in_queue=25259, util=76.04%
  nvme33n1: ios=45/16144, merge=0/0, ticks=101/25002, in_queue=25096, util=75.74%
  nvme34n1: ios=45/16054, merge=0/0, ticks=107/25001, in_queue=25105, util=75.92%
  nvme35n1: ios=45/16130, merge=0/0, ticks=106/24990, in_queue=25094, util=76.04%
  nvme36n1: ios=45/16091, merge=0/0, ticks=107/25123, in_queue=25227, util=76.62%
  nvme37n1: ios=45/16171, merge=0/0, ticks=103/25178, in_queue=25276, util=76.94%
  nvme38n1: ios=45/16086, merge=0/0, ticks=98/25146, in_queue=25242, util=76.98%
  nvme39n1: ios=45/16138, merge=0/0, ticks=97/25071, in_queue=25164, util=76.91%
  nvme40n1: ios=45/16091, merge=0/0, ticks=96/25135, in_queue=25229, util=77.33%
  nvme41n1: ios=45/16146, merge=0/0, ticks=99/25048, in_queue=25147, util=77.35%
  nvme42n1: ios=45/16051, merge=0/0, ticks=105/25017, in_queue=25121, util=77.48%
  nvme43n1: ios=45/16156, merge=0/0, ticks=99/25023, in_queue=25119, util=77.76%
  nvme44n1: ios=45/16098, merge=0/0, ticks=98/25071, in_queue=25165, util=78.12%
  nvme45n1: ios=45/16158, merge=0/0, ticks=102/25084, in_queue=25181, util=78.44%
  nvme46n1: ios=45/16023, merge=0/0, ticks=101/25069, in_queue=25171, util=78.68%
  nvme47n1: ios=43/16152, merge=0/0, ticks=97/25104, in_queue=25201, util=79.06%
  nvme48n1: ios=43/16081, merge=0/0, ticks=108/25025, in_queue=25131, util=79.01%
  nvme49n1: ios=43/16144, merge=0/0, ticks=101/25070, in_queue=25172, util=79.39%
  nvme50n1: ios=43/16083, merge=0/0, ticks=106/25204, in_queue=25309, util=80.03%
  nvme51n1: ios=43/16170, merge=0/0, ticks=100/25169, in_queue=25268, util=80.17%
  nvme52n1: ios=43/16069, merge=0/0, ticks=111/24931, in_queue=25039, util=79.66%
  nvme53n1: ios=43/16142, merge=0/0, ticks=108/25021, in_queue=25127, util=80.21%
  nvme54n1: ios=43/16092, merge=0/0, ticks=99/25160, in_queue=25259, util=80.91%
  nvme55n1: ios=43/16150, merge=0/0, ticks=111/25086, in_queue=25195, util=80.95%
  nvme56n1: ios=43/16073, merge=0/0, ticks=104/25055, in_queue=25154, util=81.11%
  nvme57n1: ios=43/16137, merge=0/0, ticks=99/25142, in_queue=25242, util=81.69%
  nvme58n1: ios=43/16137, merge=0/0, ticks=102/25215, in_queue=25311, util=82.21%
  nvme59n1: ios=43/16167, merge=0/0, ticks=100/25083, in_queue=25180, util=82.07%
  nvme60n1: ios=43/16107, merge=0/0, ticks=106/25080, in_queue=25183, util=82.36%
  nvme61n1: ios=43/16142, merge=0/0, ticks=99/25003, in_queue=25103, util=82.42%
  nvme62n1: ios=43/16059, merge=0/0, ticks=104/25024, in_queue=25125, util=82.80%
  nvme63n1: ios=43/16172, merge=0/0, ticks=97/25183, in_queue=25280, util=83.68%
  nvme64n1: ios=43/16109, merge=0/0, ticks=105/25107, in_queue=25210, util=83.78%


    DEBUG: 2018/09/27 07:42:39 Running VERIFY IOs with SHA512 checksum : IO SIZE (64K)
    DEBUG: 2018/09/27 07:42:39 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize=64K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:43:16 output : job1: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job6: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job7: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job8: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job9: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job10: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job11: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job12: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job13: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job14: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job15: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job16: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job17: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job18: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job19: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job20: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job21: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job22: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job23: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job24: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job25: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job26: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job27: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job28: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job29: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job30: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job31: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job32: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job33: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job34: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job35: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job36: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job37: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job38: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job39: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job40: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job41: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job42: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job43: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job44: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job45: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job46: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job47: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job48: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job49: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job50: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job51: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job52: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job53: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job54: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job55: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job56: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job57: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job58: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job59: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job60: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job61: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job62: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job63: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job64: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=64): [V(64)][0.0%][r=29.4MiB/s,w=0KiB/s][r=468,w=0 IOPS][eta 06h:49m:44s]Jobs: 64 (f=64): [V(64)][0.2%][r=1944MiB/s,w=0KiB/s][r=31.1k,w=0 IOPS][eta 01h:06m:55s]Jobs: 64 (f=64): [V(64)][0.3%][r=1850MiB/s,w=0KiB/s][r=29.6k,w=0 IOPS][eta 53m:11s]    Jobs: 64 (f=64): [V(64)][0.3%][r=1893MiB/s,w=0KiB/s][r=30.3k,w=0 IOPS][eta 47m:49s]Jobs: 64 (f=64): [V(64)][0.4%][r=1910MiB/s,w=0KiB/s][r=30.6k,w=0 IOPS][eta 45m:00s]Jobs: 64 (f=64): [V(64)][0.4%][r=1919MiB/s,w=0KiB/s][r=30.8k,w=0 IOPS][eta 43m:04s]Jobs: 64 (f=64): [V(64)][0.5%][r=1933MiB/s,w=0KiB/s][r=30.1k,w=0 IOPS][eta 41m:55s]Jobs: 64 (f=64): [V(64)][0.5%][r=1928MiB/s,w=0KiB/s][r=30.9k,w=0 IOPS][eta 41m:07s]Jobs: 64 (f=64): [V(64)][0.6%][r=2074MiB/s,w=0KiB/s][r=33.2k,w=0 IOPS][eta 39m:59s]Jobs: 64 (f=64): [V(64)][0.6%][r=2126MiB/s,w=0KiB/s][r=34.9k,w=0 IOPS][eta 39m:04s]Jobs: 64 (f=64): [V(64)][0.7%][r=2146MiB/s,w=0KiB/s][r=34.4k,w=0 IOPS][eta 38m:20s]Jobs: 64 (f=64): [V(64)][0.7%][r=2109MiB/s,w=0KiB/s][r=33.8k,w=0 IOPS][eta 37m:46s]Jobs: 64 (f=64): [V(64)][0.8%][r=2099MiB/s,w=0KiB/s][r=33.6k,w=0 IOPS][eta 37m:19s]Jobs: 64 (f=64): [V(64)][0.8%][r=2162MiB/s,w=0KiB/s][r=34.6k,w=0 IOPS][eta 36m:58s]Jobs: 64 (f=64): [V(64)][0.9%][r=2101MiB/s,w=0KiB/s][r=33.7k,w=0 IOPS][eta 36m:41s]Jobs: 64 (f=64): [V(64)][1.0%][r=2099MiB/s,w=0KiB/s][r=33.6k,w=0 IOPS][eta 36m:25s]Jobs: 64 (f=64): [V(64)][1.0%][r=2098MiB/s,w=0KiB/s][r=33.6k,w=0 IOPS][eta 36m:12s]Jobs: 64 (f=64): [V(64)][1.1%][r=2099MiB/s,w=0KiB/s][r=33.6k,w=0 IOPS][eta 35m:59s]Jobs: 64 (f=64): [V(64)][1.1%][r=2113MiB/s,w=0KiB/s][r=33.8k,w=0 IOPS][eta 35m:48s]Jobs: 64 (f=64): [V(64)][1.2%][r=2146MiB/s,w=0KiB/s][r=34.4k,w=0 IOPS][eta 35m:36s]Jobs: 64 (f=64): [V(64)][1.2%][r=2274MiB/s,w=0KiB/s][r=36.4k,w=0 IOPS][eta 35m:19s]Jobs: 64 (f=64): [V(64)][1.3%][r=2195MiB/s,w=0KiB/s][r=35.2k,w=0 IOPS][eta 35m:08s]Jobs: 64 (f=64): [V(64)][1.3%][r=2286MiB/s,w=0KiB/s][r=36.6k,w=0 IOPS][eta 34m:52s]Jobs: 64 (f=64): [V(64)][1.4%][r=2215MiB/s,w=0KiB/s][r=35.5k,w=0 IOPS][eta 34m:41s]Jobs: 64 (f=64): [V(64)][1.4%][r=2186MiB/s,w=0KiB/s][r=34.1k,w=0 IOPS][eta 34m:28s]Jobs: 64 (f=64): [V(64)][1.5%][r=2251MiB/s,w=0KiB/s][r=36.2k,w=0 IOPS][eta 34m:16s]Jobs: 64 (f=64): [V(64)][1.5%][r=2139MiB/s,w=0KiB/s][r=34.3k,w=0 IOPS][eta 34m:10s]Jobs: 64 (f=64): [V(64)][1.6%][r=2102MiB/s,w=0KiB/s][r=33.7k,w=0 IOPS][eta 34m:06s]Jobs: 64 (f=64): [V(64)][1.6%][r=2112MiB/s,w=0KiB/s][r=33.8k,w=0 IOPS][eta 34m:03s]Jobs: 64 (f=64): [V(64)][1.7%][r=2100MiB/s,w=0KiB/s][r=33.6k,w=0 IOPS][eta 33m:59s]Jobs: 64 (f=64): [V(64)][1.7%][r=2103MiB/s,w=0KiB/s][r=33.7k,w=0 IOPS][eta 33m:56s]Jobs: 2 (f=2): [_(30),V(1),_(19),E(1),_(7),E(1),_(3),V(1),_(1)][1.8%][r=1779MiB/s,w=0KiB/s][r=28.5k,w=0 IOPS][eta 33m:26s]
job1: (groupid=0, jobs=64): err= 0: pid=26187: Thu Sep 27 07:43:16 2018
   read: IOPS=33.3k, BW=2078MiB/s (2179MB/s)(63.2GiB/31114msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=12.93%, sys=0.49%, ctx=1036334, majf=0, minf=12800
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=1034527,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=2078MiB/s (2179MB/s), 2078MiB/s-2078MiB/s (2179MB/s-2179MB/s), io=63.2GiB (67.8GB), run=31114-31114msec

Disk stats (read/write):
  nvme1n1: ios=16112/0, merge=0/0, ticks=26776/0, in_queue=26772, util=73.31%
  nvme2n1: ios=16095/0, merge=0/0, ticks=26527/0, in_queue=26525, util=73.39%
  nvme3n1: ios=16069/0, merge=0/0, ticks=26755/0, in_queue=26755, util=73.47%
  nvme4n1: ios=16172/0, merge=0/0, ticks=26629/0, in_queue=26630, util=74.23%
  nvme5n1: ios=16137/0, merge=0/0, ticks=26849/0, in_queue=26849, util=74.27%
  nvme6n1: ios=16115/0, merge=0/0, ticks=26784/0, in_queue=26782, util=74.91%
  nvme7n1: ios=16061/0, merge=0/0, ticks=26862/0, in_queue=26860, util=74.92%
  nvme8n1: ios=16063/0, merge=0/0, ticks=26606/0, in_queue=26603, util=75.00%
  nvme9n1: ios=16085/0, merge=0/0, ticks=26797/0, in_queue=26796, util=75.34%
  nvme10n1: ios=16135/0, merge=0/0, ticks=26678/0, in_queue=26679, util=75.59%
  nvme11n1: ios=16100/0, merge=0/0, ticks=26897/0, in_queue=26894, util=75.71%
  nvme12n1: ios=16087/0, merge=0/0, ticks=26702/0, in_queue=26699, util=75.63%
  nvme13n1: ios=16138/0, merge=0/0, ticks=26964/0, in_queue=26966, util=75.98%
  nvme14n1: ios=16057/0, merge=0/0, ticks=26615/0, in_queue=26615, util=75.53%
  nvme15n1: ios=16132/0, merge=0/0, ticks=26888/0, in_queue=26888, util=75.91%
  nvme16n1: ios=16155/0, merge=0/0, ticks=26817/0, in_queue=26812, util=76.17%
  nvme17n1: ios=16103/0, merge=0/0, ticks=26892/0, in_queue=26873, util=75.92%
  nvme18n1: ios=16110/0, merge=0/0, ticks=26695/0, in_queue=26696, util=76.07%
  nvme19n1: ios=16131/0, merge=0/0, ticks=26943/0, in_queue=26942, util=76.33%
  nvme20n1: ios=16052/0, merge=0/0, ticks=26655/0, in_queue=26652, util=76.11%
  nvme21n1: ios=16130/0, merge=0/0, ticks=26907/0, in_queue=26904, util=76.37%
  nvme22n1: ios=16091/0, merge=0/0, ticks=26582/0, in_queue=26582, util=76.06%
  nvme23n1: ios=16089/0, merge=0/0, ticks=26767/0, in_queue=26764, util=76.14%
  nvme24n1: ios=16075/0, merge=0/0, ticks=26599/0, in_queue=26598, util=76.33%
  nvme25n1: ios=16127/0, merge=0/0, ticks=26906/0, in_queue=26904, util=76.75%
  nvme26n1: ios=16071/0, merge=0/0, ticks=26668/0, in_queue=26664, util=76.74%
  nvme27n1: ios=16137/0, merge=0/0, ticks=26984/0, in_queue=26980, util=77.21%
  nvme28n1: ios=16126/0, merge=0/0, ticks=26738/0, in_queue=26736, util=77.21%
  nvme29n1: ios=16153/0, merge=0/0, ticks=26996/0, in_queue=26994, util=77.52%
  nvme30n1: ios=16083/0, merge=0/0, ticks=26640/0, in_queue=26639, util=77.22%
  nvme31n1: ios=16234/0, merge=0/0, ticks=27098/0, in_queue=27094, util=77.56%
  nvme32n1: ios=16053/0, merge=0/0, ticks=26608/0, in_queue=26604, util=77.38%
  nvme33n1: ios=16104/0, merge=0/0, ticks=26786/0, in_queue=26783, util=77.56%
  nvme34n1: ios=16021/0, merge=0/0, ticks=26542/0, in_queue=26536, util=77.58%
  nvme35n1: ios=16140/0, merge=0/0, ticks=26966/0, in_queue=26966, util=78.44%
  nvme36n1: ios=16169/0, merge=0/0, ticks=26826/0, in_queue=26824, util=78.73%
  nvme37n1: ios=16082/0, merge=0/0, ticks=26834/0, in_queue=26831, util=78.40%
  nvme38n1: ios=16072/0, merge=0/0, ticks=26673/0, in_queue=26670, util=78.66%
  nvme39n1: ios=16077/0, merge=0/0, ticks=26854/0, in_queue=26854, util=78.75%
  nvme40n1: ios=16104/0, merge=0/0, ticks=26754/0, in_queue=26752, util=79.21%
  nvme41n1: ios=16089/0, merge=0/0, ticks=26814/0, in_queue=26814, util=79.01%
  nvme42n1: ios=16103/0, merge=0/0, ticks=26720/0, in_queue=26717, util=79.52%
  nvme43n1: ios=16185/0, merge=0/0, ticks=26953/0, in_queue=26953, util=79.77%
  nvme44n1: ios=16037/0, merge=0/0, ticks=26553/0, in_queue=26553, util=79.52%
  nvme45n1: ios=16092/0, merge=0/0, ticks=26872/0, in_queue=26872, util=80.21%
  nvme46n1: ios=16063/0, merge=0/0, ticks=26691/0, in_queue=26689, util=80.54%
  nvme47n1: ios=16083/0, merge=0/0, ticks=26771/0, in_queue=26769, util=80.58%
  nvme48n1: ios=16076/0, merge=0/0, ticks=26553/0, in_queue=26552, util=81.39%
  nvme49n1: ios=16119/0, merge=0/0, ticks=26921/0, in_queue=26922, util=81.59%
  nvme50n1: ios=16082/0, merge=0/0, ticks=26642/0, in_queue=26642, util=81.73%
  nvme51n1: ios=16086/0, merge=0/0, ticks=26797/0, in_queue=26791, util=81.81%
  nvme52n1: ios=16027/0, merge=0/0, ticks=26531/0, in_queue=26530, util=81.93%
  nvme53n1: ios=16095/0, merge=0/0, ticks=26796/0, in_queue=26795, util=82.51%
  nvme54n1: ios=16126/0, merge=0/0, ticks=26682/0, in_queue=26680, util=83.20%
  nvme55n1: ios=16092/0, merge=0/0, ticks=26830/0, in_queue=26830, util=83.36%
  nvme56n1: ios=16036/0, merge=0/0, ticks=26510/0, in_queue=26511, util=83.35%
  nvme57n1: ios=16071/0, merge=0/0, ticks=26793/0, in_queue=26791, util=83.96%
  nvme58n1: ios=16039/0, merge=0/0, ticks=26493/0, in_queue=26490, util=83.88%
  nvme59n1: ios=16082/0, merge=0/0, ticks=26786/0, in_queue=26785, util=84.49%
  nvme60n1: ios=16076/0, merge=0/0, ticks=26549/0, in_queue=26544, util=84.76%
  nvme61n1: ios=16066/0, merge=0/0, ticks=26759/0, in_queue=26755, util=85.05%
  nvme62n1: ios=16069/0, merge=0/0, ticks=26642/0, in_queue=26642, util=85.69%
  nvme63n1: ios=16249/0, merge=0/0, ticks=27037/0, in_queue=27036, util=86.00%
  nvme64n1: ios=16035/0, merge=0/0, ticks=26567/0, in_queue=26567, util=86.18%


    DEBUG: 2018/09/27 07:43:16 Running WRITE IOs with SHA512 checksum : BS Range (4K to 1M)
    DEBUG: 2018/09/27 07:43:16 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize_range=4K-1024K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:43:52 output : job1: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job6: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job7: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job8: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job9: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job10: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job11: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job12: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job13: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job14: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job15: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job16: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job17: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job18: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job19: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job20: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job21: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job22: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job23: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job24: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job25: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job26: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job27: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job28: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job29: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job30: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job31: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job32: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job33: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job34: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job35: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job36: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job37: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job38: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job39: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job40: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job41: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job42: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job43: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job44: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job45: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job46: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job47: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job48: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job49: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job50: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job51: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job52: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job53: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job54: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job55: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job56: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job57: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job58: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job59: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job60: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job61: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job62: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job63: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job64: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=64): [w(64)][17.1%][r=0KiB/s,w=37.9MiB/s][r=0,w=82 IOPS][eta 00m:29s]Jobs: 64 (f=64): [w(64)][20.0%][r=0KiB/s,w=2113MiB/s][r=0,w=4212 IOPS][eta 00m:28s]Jobs: 64 (f=64): [w(64)][22.9%][r=0KiB/s,w=2141MiB/s][r=0,w=4299 IOPS][eta 00m:27s]Jobs: 64 (f=64): [w(64)][25.7%][r=0KiB/s,w=2094MiB/s][r=0,w=4252 IOPS][eta 00m:26s]Jobs: 64 (f=64): [w(64)][28.6%][r=0KiB/s,w=2099MiB/s][r=0,w=4235 IOPS][eta 00m:25s]Jobs: 64 (f=64): [w(64)][31.4%][r=0KiB/s,w=2095MiB/s][r=0,w=4244 IOPS][eta 00m:24s]Jobs: 64 (f=64): [w(64)][34.3%][r=0KiB/s,w=2115MiB/s][r=0,w=4341 IOPS][eta 00m:23s]Jobs: 64 (f=64): [w(64)][37.1%][r=0KiB/s,w=2113MiB/s][r=0,w=4226 IOPS][eta 00m:22s]Jobs: 64 (f=64): [w(64)][40.0%][r=0KiB/s,w=2098MiB/s][r=0,w=4271 IOPS][eta 00m:21s]Jobs: 64 (f=64): [w(64)][42.9%][r=0KiB/s,w=2096MiB/s][r=0,w=4256 IOPS][eta 00m:20s]Jobs: 64 (f=64): [w(64)][45.7%][r=0KiB/s,w=2144MiB/s][r=0,w=4362 IOPS][eta 00m:19s]Jobs: 64 (f=64): [w(64)][48.6%][r=0KiB/s,w=2113MiB/s][r=0,w=4324 IOPS][eta 00m:18s]Jobs: 64 (f=64): [w(64)][51.4%][r=0KiB/s,w=2088MiB/s][r=0,w=4220 IOPS][eta 00m:17s]Jobs: 64 (f=64): [w(64)][54.3%][r=0KiB/s,w=2051MiB/s][r=0,w=4222 IOPS][eta 00m:16s]Jobs: 64 (f=64): [w(64)][57.1%][r=0KiB/s,w=2134MiB/s][r=0,w=4411 IOPS][eta 00m:15s]Jobs: 64 (f=64): [w(64)][60.0%][r=0KiB/s,w=2087MiB/s][r=0,w=4289 IOPS][eta 00m:14s]Jobs: 64 (f=64): [w(64)][62.9%][r=0KiB/s,w=2110MiB/s][r=0,w=4329 IOPS][eta 00m:13s]Jobs: 64 (f=64): [w(64)][65.7%][r=0KiB/s,w=2093MiB/s][r=0,w=4401 IOPS][eta 00m:12s]Jobs: 64 (f=64): [w(64)][68.6%][r=0KiB/s,w=2122MiB/s][r=0,w=4454 IOPS][eta 00m:11s]Jobs: 64 (f=64): [w(64)][71.4%][r=0KiB/s,w=2077MiB/s][r=0,w=4290 IOPS][eta 00m:10s]Jobs: 64 (f=64): [w(64)][74.3%][r=0KiB/s,w=2131MiB/s][r=0,w=4437 IOPS][eta 00m:09s]Jobs: 64 (f=64): [w(64)][77.1%][r=0KiB/s,w=2084MiB/s][r=0,w=4337 IOPS][eta 00m:08s]Jobs: 64 (f=64): [w(64)][80.0%][r=0KiB/s,w=2106MiB/s][r=0,w=4381 IOPS][eta 00m:07s]Jobs: 64 (f=64): [w(64)][82.9%][r=0KiB/s,w=2120MiB/s][r=0,w=4395 IOPS][eta 00m:06s]Jobs: 64 (f=64): [w(64)][85.7%][r=0KiB/s,w=2114MiB/s][r=0,w=4368 IOPS][eta 00m:05s]Jobs: 64 (f=64): [w(64)][88.6%][r=0KiB/s,w=2107MiB/s][r=0,w=4333 IOPS][eta 00m:04s]Jobs: 64 (f=64): [w(64)][91.4%][r=0KiB/s,w=2114MiB/s][r=0,w=4526 IOPS][eta 00m:03s]Jobs: 64 (f=64): [w(64)][94.3%][r=0KiB/s,w=2093MiB/s][r=0,w=4458 IOPS][eta 00m:02s]Jobs: 64 (f=64): [w(64)][97.1%][r=0KiB/s,w=2102MiB/s][r=0,w=4359 IOPS][eta 00m:01s]Jobs: 64 (f=64): [w(64)][100.0%][r=0KiB/s,w=2108MiB/s][r=0,w=4437 IOPS][eta 00m:00s]
job1: (groupid=0, jobs=64): err= 0: pid=26877: Thu Sep 27 07:43:52 2018
  write: IOPS=4334, BW=2105MiB/s (2207MB/s)(61.8GiB/30025msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=12.64%, sys=0.52%, ctx=134339, majf=0, minf=41989
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,130145,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=2105MiB/s (2207MB/s), 2105MiB/s-2105MiB/s (2207MB/s-2207MB/s), io=61.8GiB (66.3GB), run=30025-30025msec

Disk stats (read/write):
  nvme1n1: ios=43/9056, merge=0/0, ticks=15/75952, in_queue=75993, util=75.16%
  nvme2n1: ios=43/8927, merge=0/0, ticks=6/83002, in_queue=83050, util=75.29%
  nvme3n1: ios=43/8848, merge=0/0, ticks=511/84415, in_queue=84952, util=75.32%
  nvme4n1: ios=43/8935, merge=0/0, ticks=306/84107, in_queue=84419, util=75.75%
  nvme5n1: ios=43/8895, merge=0/0, ticks=408/85198, in_queue=85643, util=76.16%
  nvme6n1: ios=43/8904, merge=0/0, ticks=484/86570, in_queue=87069, util=76.46%
  nvme7n1: ios=43/8898, merge=0/0, ticks=358/86985, in_queue=87377, util=76.78%
  nvme8n1: ios=43/8885, merge=0/0, ticks=379/87124, in_queue=87524, util=77.06%
  nvme9n1: ios=43/8849, merge=0/0, ticks=278/86562, in_queue=86847, util=77.25%
  nvme10n1: ios=43/8799, merge=0/0, ticks=468/85831, in_queue=86305, util=76.87%
  nvme11n1: ios=45/8830, merge=0/0, ticks=296/86951, in_queue=87267, util=76.90%
  nvme12n1: ios=45/8857, merge=0/0, ticks=447/87971, in_queue=88417, util=77.30%
  nvme13n1: ios=45/8898, merge=0/0, ticks=393/87742, in_queue=88167, util=77.62%
  nvme14n1: ios=45/8866, merge=0/0, ticks=420/87539, in_queue=87976, util=77.51%
  nvme15n1: ios=45/8856, merge=0/0, ticks=316/86742, in_queue=87070, util=77.23%
  nvme16n1: ios=45/8899, merge=0/0, ticks=373/86996, in_queue=87368, util=77.53%
  nvme17n1: ios=45/8875, merge=0/0, ticks=455/87839, in_queue=88331, util=77.69%
  nvme18n1: ios=45/8873, merge=0/0, ticks=416/87575, in_queue=88001, util=77.69%
  nvme19n1: ios=45/8834, merge=0/0, ticks=350/87347, in_queue=87718, util=77.58%
  nvme20n1: ios=45/8836, merge=0/0, ticks=340/87316, in_queue=87693, util=77.55%
  nvme21n1: ios=45/8847, merge=0/0, ticks=324/88210, in_queue=88564, util=77.84%
  nvme22n1: ios=45/8914, merge=0/0, ticks=320/87305, in_queue=87641, util=78.13%
  nvme23n1: ios=45/8854, merge=0/0, ticks=369/88251, in_queue=88634, util=78.11%
  nvme24n1: ios=45/8862, merge=0/0, ticks=399/86065, in_queue=86504, util=77.74%
  nvme25n1: ios=45/8878, merge=0/0, ticks=438/87137, in_queue=87586, util=78.18%
  nvme26n1: ios=45/8906, merge=0/0, ticks=325/87355, in_queue=87699, util=78.38%
  nvme27n1: ios=45/8892, merge=0/0, ticks=286/88225, in_queue=88545, util=78.44%
  nvme28n1: ios=45/8795, merge=0/0, ticks=333/86463, in_queue=86793, util=78.07%
  nvme29n1: ios=45/8816, merge=0/0, ticks=318/87427, in_queue=87749, util=77.94%
  nvme30n1: ios=45/8831, merge=0/0, ticks=362/86506, in_queue=86907, util=78.21%
  nvme31n1: ios=45/8874, merge=0/0, ticks=408/87535, in_queue=87969, util=78.97%
  nvme32n1: ios=45/8797, merge=0/0, ticks=342/88050, in_queue=88426, util=78.50%
  nvme33n1: ios=45/8850, merge=0/0, ticks=336/87163, in_queue=87524, util=78.61%
  nvme34n1: ios=45/8779, merge=0/0, ticks=397/87163, in_queue=87555, util=78.88%
  nvme35n1: ios=45/8804, merge=0/0, ticks=435/87247, in_queue=87714, util=78.96%
  nvme36n1: ios=45/8795, merge=0/0, ticks=353/87548, in_queue=87920, util=78.86%
  nvme37n1: ios=45/8880, merge=0/0, ticks=347/88378, in_queue=88734, util=79.65%
  nvme38n1: ios=45/8823, merge=0/0, ticks=341/87972, in_queue=88307, util=79.43%
  nvme39n1: ios=45/8802, merge=0/0, ticks=376/88630, in_queue=89034, util=79.55%
  nvme40n1: ios=45/8806, merge=0/0, ticks=452/88024, in_queue=88509, util=79.94%
  nvme41n1: ios=45/8782, merge=0/0, ticks=443/88929, in_queue=89404, util=80.07%
  nvme42n1: ios=45/8812, merge=0/0, ticks=348/86995, in_queue=87378, util=80.03%
  nvme43n1: ios=45/8815, merge=0/0, ticks=417/88488, in_queue=88921, util=80.70%
  nvme44n1: ios=45/8802, merge=0/0, ticks=395/87347, in_queue=87750, util=80.51%
  nvme45n1: ios=43/8851, merge=0/0, ticks=343/87551, in_queue=87923, util=80.86%
  nvme46n1: ios=43/8782, merge=0/0, ticks=331/86359, in_queue=86689, util=80.63%
  nvme47n1: ios=43/8799, merge=0/0, ticks=265/86369, in_queue=86633, util=81.05%
  nvme48n1: ios=43/8763, merge=0/0, ticks=299/88419, in_queue=88738, util=80.99%
  nvme49n1: ios=43/8761, merge=0/0, ticks=453/86786, in_queue=87285, util=81.62%
  nvme50n1: ios=43/8879, merge=0/0, ticks=304/88114, in_queue=88466, util=82.22%
  nvme51n1: ios=43/8779, merge=0/0, ticks=329/88153, in_queue=88537, util=82.26%
  nvme52n1: ios=43/8819, merge=0/0, ticks=317/87299, in_queue=87616, util=82.16%
  nvme53n1: ios=43/8818, merge=0/0, ticks=501/88320, in_queue=88820, util=82.60%
  nvme54n1: ios=43/8819, merge=0/0, ticks=397/88507, in_queue=88918, util=83.13%
  nvme55n1: ios=43/8897, merge=0/0, ticks=408/88200, in_queue=88616, util=83.62%
  nvme56n1: ios=43/8791, merge=0/0, ticks=237/88719, in_queue=88986, util=83.34%
  nvme57n1: ios=43/8780, merge=0/0, ticks=387/87893, in_queue=88292, util=83.73%
  nvme58n1: ios=43/8879, merge=0/0, ticks=336/88524, in_queue=88875, util=84.89%
  nvme59n1: ios=43/8826, merge=0/0, ticks=383/88024, in_queue=88428, util=84.79%
  nvme60n1: ios=43/8811, merge=0/0, ticks=398/87232, in_queue=87637, util=84.87%
  nvme61n1: ios=43/8836, merge=0/0, ticks=351/87848, in_queue=88197, util=85.63%
  nvme62n1: ios=43/8892, merge=0/0, ticks=394/88501, in_queue=88917, util=86.45%
  nvme63n1: ios=43/8822, merge=0/0, ticks=340/88196, in_queue=88549, util=86.80%
  nvme64n1: ios=43/8839, merge=0/0, ticks=353/87161, in_queue=87522, util=87.03%


    DEBUG: 2018/09/27 07:43:52 Running VERIFY IOs with SHA512 checksum : BS Range (4K to 1M)
    DEBUG: 2018/09/27 07:43:52 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize_range=4K-1024K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:44:27 output : job1: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job6: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job7: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job8: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job9: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job10: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job11: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job12: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job13: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job14: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job15: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job16: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job17: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job18: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job19: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job20: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job21: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job22: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job23: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job24: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job25: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job26: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job27: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job28: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job29: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job30: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job31: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job32: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job33: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job34: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job35: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job36: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job37: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job38: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job39: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job40: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job41: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job42: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job43: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job44: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job45: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job46: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job47: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job48: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job49: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job50: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job51: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job52: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job53: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job54: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job55: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job56: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job57: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job58: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job59: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job60: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job61: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job62: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job63: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job64: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=63): [V(43),r(1),V(20)][0.0%][r=3785KiB/s,w=0KiB/s][r=10,w=0 IOPS][eta 18d:05h:02m:12s]Jobs: 64 (f=64): [V(64)][0.2%][r=2177MiB/s,w=0KiB/s][r=4365,w=0 IOPS][eta 01h:02m:17s]             Jobs: 64 (f=64): [V(64)][0.3%][r=2134MiB/s,w=0KiB/s][r=4268,w=0 IOPS][eta 47m:47s]    Jobs: 64 (f=64): [V(64)][0.4%][r=2173MiB/s,w=0KiB/s][r=4408,w=0 IOPS][eta 41m:47s]Jobs: 64 (f=64): [V(64)][0.4%][r=2186MiB/s,w=0KiB/s][r=4407,w=0 IOPS][eta 39m:23s]Jobs: 64 (f=64): [V(64)][0.5%][r=2172MiB/s,w=0KiB/s][r=4415,w=0 IOPS][eta 37m:47s]Jobs: 64 (f=64): [V(64)][0.5%][r=2179MiB/s,w=0KiB/s][r=4461,w=0 IOPS][eta 36m:42s]Jobs: 64 (f=64): [V(64)][0.6%][r=2186MiB/s,w=0KiB/s][r=4376,w=0 IOPS][eta 35m:43s]Jobs: 64 (f=64): [V(64)][0.7%][r=2179MiB/s,w=0KiB/s][r=4428,w=0 IOPS][eta 35m:14s]Jobs: 64 (f=64): [V(64)][0.7%][r=2202MiB/s,w=0KiB/s][r=4496,w=0 IOPS][eta 34m:48s]Jobs: 64 (f=64): [V(64)][0.8%][r=2151MiB/s,w=0KiB/s][r=4386,w=0 IOPS][eta 34m:31s]Jobs: 64 (f=64): [V(64)][0.8%][r=2180MiB/s,w=0KiB/s][r=4411,w=0 IOPS][eta 34m:09s]Jobs: 64 (f=64): [V(64)][0.9%][r=2212MiB/s,w=0KiB/s][r=4479,w=0 IOPS][eta 33m:55s]Jobs: 64 (f=64): [V(64)][0.9%][r=2182MiB/s,w=0KiB/s][r=4542,w=0 IOPS][eta 33m:46s]Jobs: 64 (f=64): [V(64)][1.0%][r=2196MiB/s,w=0KiB/s][r=4542,w=0 IOPS][eta 33m:34s]Jobs: 64 (f=64): [V(64)][1.0%][r=2190MiB/s,w=0KiB/s][r=4495,w=0 IOPS][eta 33m:27s]Jobs: 64 (f=64): [V(64)][1.1%][r=2175MiB/s,w=0KiB/s][r=4515,w=0 IOPS][eta 33m:17s]Jobs: 64 (f=64): [V(64)][1.1%][r=2180MiB/s,w=0KiB/s][r=4583,w=0 IOPS][eta 33m:13s]Jobs: 64 (f=64): [V(64)][1.2%][r=2172MiB/s,w=0KiB/s][r=4505,w=0 IOPS][eta 33m:09s]Jobs: 64 (f=64): [V(64)][1.2%][r=2185MiB/s,w=0KiB/s][r=4525,w=0 IOPS][eta 33m:01s]Jobs: 64 (f=64): [V(64)][1.3%][r=2196MiB/s,w=0KiB/s][r=4572,w=0 IOPS][eta 32m:51s]Jobs: 64 (f=64): [V(64)][1.4%][r=2195MiB/s,w=0KiB/s][r=4570,w=0 IOPS][eta 32m:44s]Jobs: 64 (f=64): [V(64)][1.4%][r=2165MiB/s,w=0KiB/s][r=4474,w=0 IOPS][eta 32m:39s]Jobs: 64 (f=64): [V(64)][1.5%][r=2193MiB/s,w=0KiB/s][r=4566,w=0 IOPS][eta 32m:35s]Jobs: 64 (f=64): [V(64)][1.5%][r=2160MiB/s,w=0KiB/s][r=4416,w=0 IOPS][eta 32m:33s]Jobs: 64 (f=64): [V(64)][1.6%][r=2184MiB/s,w=0KiB/s][r=4681,w=0 IOPS][eta 32m:29s]Jobs: 64 (f=64): [V(64)][1.6%][r=2172MiB/s,w=0KiB/s][r=4611,w=0 IOPS][eta 32m:27s]Jobs: 64 (f=64): [V(64)][1.7%][r=2146MiB/s,w=0KiB/s][r=4479,w=0 IOPS][eta 32m:23s]Jobs: 64 (f=64): [V(64)][1.7%][r=2178MiB/s,w=0KiB/s][r=4586,w=0 IOPS][eta 32m:19s]Jobs: 15 (f=15): [_(12),V(1),_(2),V(1),_(9),V(2),_(1),V(1),_(1),V(1),_(3),V(3),_(4),V(1),_(7),V(1),_(3),V(2),_(2),V(1),_(5),V(1)][1.8%][r=2147MiB/s,w=0KiB/s][r=4491,w=0 IOPS][eta 31m:34s]
job1: (groupid=0, jobs=64): err= 0: pid=27594: Thu Sep 27 07:44:27 2018
   read: IOPS=4476, BW=2174MiB/s (2279MB/s)(61.8GiB/29070msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=12.53%, sys=0.47%, ctx=132551, majf=0, minf=76052
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=130145,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=2174MiB/s (2279MB/s), 2174MiB/s-2174MiB/s (2279MB/s-2279MB/s), io=61.8GiB (66.3GB), run=29070-29070msec

Disk stats (read/write):
  nvme1n1: ios=9081/0, merge=0/0, ticks=73426/0, in_queue=73424, util=74.81%
  nvme2n1: ios=8934/0, merge=0/0, ticks=80399/0, in_queue=80402, util=74.97%
  nvme3n1: ios=8925/0, merge=0/0, ticks=82009/0, in_queue=82039, util=75.12%
  nvme4n1: ios=8970/0, merge=0/0, ticks=82275/0, in_queue=82301, util=75.60%
  nvme5n1: ios=8902/0, merge=0/0, ticks=82281/0, in_queue=82281, util=75.16%
  nvme6n1: ios=8932/0, merge=0/0, ticks=84380/0, in_queue=84380, util=76.19%
  nvme7n1: ios=8890/0, merge=0/0, ticks=84774/0, in_queue=84773, util=76.64%
  nvme8n1: ios=8911/0, merge=0/0, ticks=84840/0, in_queue=84858, util=76.93%
  nvme9n1: ios=8879/0, merge=0/0, ticks=83790/0, in_queue=83802, util=77.01%
  nvme10n1: ios=8861/0, merge=0/0, ticks=82791/0, in_queue=82804, util=76.94%
  nvme11n1: ios=8866/0, merge=0/0, ticks=84584/0, in_queue=84585, util=76.84%
  nvme12n1: ios=8931/0, merge=0/0, ticks=85947/0, in_queue=85988, util=77.38%
  nvme13n1: ios=8980/0, merge=0/0, ticks=84904/0, in_queue=84901, util=76.95%
  nvme14n1: ios=8870/0, merge=0/0, ticks=85197/0, in_queue=85231, util=77.25%
  nvme15n1: ios=8856/0, merge=0/0, ticks=84608/0, in_queue=84627, util=77.22%
  nvme16n1: ios=8972/0, merge=0/0, ticks=85139/0, in_queue=85150, util=77.51%
  nvme17n1: ios=8867/0, merge=0/0, ticks=84842/0, in_queue=84840, util=77.23%
  nvme18n1: ios=8886/0, merge=0/0, ticks=84406/0, in_queue=84420, util=77.22%
  nvme19n1: ios=8922/0, merge=0/0, ticks=85374/0, in_queue=85405, util=77.53%
  nvme20n1: ios=8836/0, merge=0/0, ticks=85143/0, in_queue=85163, util=77.41%
  nvme21n1: ios=8851/0, merge=0/0, ticks=86064/0, in_queue=86064, util=77.67%
  nvme22n1: ios=8979/0, merge=0/0, ticks=85195/0, in_queue=85229, util=78.01%
  nvme23n1: ios=8869/0, merge=0/0, ticks=85864/0, in_queue=85894, util=77.92%
  nvme24n1: ios=8894/0, merge=0/0, ticks=84179/0, in_queue=84194, util=78.19%
  nvme25n1: ios=8884/0, merge=0/0, ticks=84912/0, in_queue=84908, util=78.00%
  nvme26n1: ios=8943/0, merge=0/0, ticks=84590/0, in_queue=84587, util=77.73%
  nvme27n1: ios=8936/0, merge=0/0, ticks=85784/0, in_queue=85795, util=78.10%
  nvme28n1: ios=8884/0, merge=0/0, ticks=84477/0, in_queue=84516, util=78.66%
  nvme29n1: ios=8883/0, merge=0/0, ticks=85717/0, in_queue=85722, util=78.00%
  nvme30n1: ios=8840/0, merge=0/0, ticks=84229/0, in_queue=84226, util=78.42%
  nvme31n1: ios=8945/0, merge=0/0, ticks=85115/0, in_queue=85113, util=78.25%
  nvme32n1: ios=8824/0, merge=0/0, ticks=85832/0, in_queue=85877, util=78.62%
  nvme33n1: ios=8890/0, merge=0/0, ticks=84648/0, in_queue=84672, util=78.96%
  nvme34n1: ios=8791/0, merge=0/0, ticks=84497/0, in_queue=84506, util=79.20%
  nvme35n1: ios=8891/0, merge=0/0, ticks=85151/0, in_queue=85158, util=78.91%
  nvme36n1: ios=8874/0, merge=0/0, ticks=85764/0, in_queue=85770, util=79.43%
  nvme37n1: ios=8969/0, merge=0/0, ticks=85917/0, in_queue=85917, util=79.55%
  nvme38n1: ios=8831/0, merge=0/0, ticks=85531/0, in_queue=85557, util=79.79%
  nvme39n1: ios=8841/0, merge=0/0, ticks=85921/0, in_queue=85921, util=79.82%
  nvme40n1: ios=8814/0, merge=0/0, ticks=85121/0, in_queue=85151, util=80.18%
  nvme41n1: ios=8814/0, merge=0/0, ticks=85882/0, in_queue=85902, util=80.99%
  nvme42n1: ios=8889/0, merge=0/0, ticks=85068/0, in_queue=85067, util=80.57%
  nvme43n1: ios=8875/0, merge=0/0, ticks=85820/0, in_queue=85831, util=81.18%
  nvme44n1: ios=8855/0, merge=0/0, ticks=84828/0, in_queue=84836, util=81.16%
  nvme45n1: ios=8837/0, merge=0/0, ticks=85101/0, in_queue=85114, util=81.19%
  nvme46n1: ios=8827/0, merge=0/0, ticks=84254/0, in_queue=84250, util=81.41%
  nvme47n1: ios=8842/0, merge=0/0, ticks=83807/0, in_queue=83816, util=81.62%
  nvme48n1: ios=8810/0, merge=0/0, ticks=85764/0, in_queue=85765, util=82.34%
  nvme49n1: ios=8845/0, merge=0/0, ticks=84348/0, in_queue=84366, util=82.29%
  nvme50n1: ios=8916/0, merge=0/0, ticks=85534/0, in_queue=85541, util=82.31%
  nvme51n1: ios=8833/0, merge=0/0, ticks=85081/0, in_queue=85114, util=82.72%
  nvme52n1: ios=8810/0, merge=0/0, ticks=84893/0, in_queue=84903, util=82.90%
  nvme53n1: ios=8853/0, merge=0/0, ticks=85534/0, in_queue=85542, util=83.18%
  nvme54n1: ios=8901/0, merge=0/0, ticks=86229/0, in_queue=86238, util=83.34%
  nvme55n1: ios=8916/0, merge=0/0, ticks=85757/0, in_queue=85756, util=83.65%
  nvme56n1: ios=8797/0, merge=0/0, ticks=86055/0, in_queue=86075, util=84.23%
  nvme57n1: ios=8825/0, merge=0/0, ticks=85652/0, in_queue=85672, util=84.62%
  nvme58n1: ios=8912/0, merge=0/0, ticks=85636/0, in_queue=85636, util=84.32%
  nvme59n1: ios=8885/0, merge=0/0, ticks=85867/0, in_queue=85904, util=85.89%
  nvme60n1: ios=8830/0, merge=0/0, ticks=84926/0, in_queue=84936, util=85.25%
  nvme61n1: ios=8862/0, merge=0/0, ticks=85656/0, in_queue=85672, util=86.08%
  nvme62n1: ios=8881/0, merge=0/0, ticks=85866/0, in_queue=85868, util=86.45%
  nvme63n1: ios=8835/0, merge=0/0, ticks=84771/0, in_queue=84768, util=86.39%
  nvme64n1: ios=8922/0, merge=0/0, ticks=84965/0, in_queue=84966, util=86.87%


    DEBUG: 2018/09/27 07:44:27 Running WRITE IOs with SHA512 checksum : BS Range (32K to 1024K)
    DEBUG: 2018/09/27 07:44:27 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize_range=32K-1024K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:45:04 output : job1: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job6: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job7: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job8: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job9: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job10: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job11: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job12: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job13: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job14: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job15: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job16: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job17: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job18: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job19: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job20: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job21: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job22: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job23: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job24: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job25: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job26: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job27: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job28: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job29: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job30: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job31: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job32: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job33: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job34: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job35: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job36: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job37: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job38: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job39: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job40: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job41: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job42: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job43: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job44: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job45: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job46: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job47: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job48: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job49: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job50: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job51: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job52: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job53: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job54: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job55: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job56: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job57: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job58: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job59: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job60: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job61: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job62: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job63: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job64: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=62): [w(64)][17.1%][r=0KiB/s,w=4912KiB/s][r=0,w=14 IOPS][eta 00m:29s]Jobs: 64 (f=64): [w(64)][19.4%][r=0KiB/s,w=2121MiB/s][r=0,w=4350 IOPS][eta 00m:29s]Jobs: 64 (f=64): [w(64)][25.0%][r=0KiB/s,w=2086MiB/s][r=0,w=4286 IOPS][eta 00m:27s]Jobs: 64 (f=64): [w(64)][25.0%][r=0KiB/s,w=2112MiB/s][r=0,w=4403 IOPS][eta 00m:27s]Jobs: 64 (f=64): [w(64)][29.7%][r=0KiB/s,w=2097MiB/s][r=0,w=4342 IOPS][eta 00m:26s]Jobs: 64 (f=64): [w(64)][32.4%][r=0KiB/s,w=2109MiB/s][r=0,w=4383 IOPS][eta 00m:25s]Jobs: 64 (f=64): [w(64)][35.1%][r=0KiB/s,w=2108MiB/s][r=0,w=4423 IOPS][eta 00m:24s]Jobs: 64 (f=64): [w(64)][37.8%][r=0KiB/s,w=2125MiB/s][r=0,w=4345 IOPS][eta 00m:23s]Jobs: 64 (f=64): [w(64)][40.5%][r=0KiB/s,w=2077MiB/s][r=0,w=4364 IOPS][eta 00m:22s]Jobs: 64 (f=64): [w(64)][43.2%][r=0KiB/s,w=2132MiB/s][r=0,w=4441 IOPS][eta 00m:21s]Jobs: 64 (f=64): [w(64)][45.9%][r=0KiB/s,w=2079MiB/s][r=0,w=4333 IOPS][eta 00m:20s]Jobs: 64 (f=64): [w(64)][50.0%][r=0KiB/s,w=2062MiB/s][r=0,w=4289 IOPS][eta 00m:18s]Jobs: 64 (f=64): [w(64)][52.8%][r=0KiB/s,w=2108MiB/s][r=0,w=4391 IOPS][eta 00m:17s]Jobs: 64 (f=64): [w(64)][55.6%][r=0KiB/s,w=2115MiB/s][r=0,w=4476 IOPS][eta 00m:16s]Jobs: 64 (f=64): [w(64)][58.3%][r=0KiB/s,w=2106MiB/s][r=0,w=4452 IOPS][eta 00m:15s]Jobs: 64 (f=64): [w(64)][61.1%][r=0KiB/s,w=2112MiB/s][r=0,w=4439 IOPS][eta 00m:14s]Jobs: 64 (f=64): [w(64)][63.9%][r=0KiB/s,w=2104MiB/s][r=0,w=4436 IOPS][eta 00m:13s]Jobs: 64 (f=64): [w(64)][66.7%][r=0KiB/s,w=2118MiB/s][r=0,w=4555 IOPS][eta 00m:12s]Jobs: 64 (f=64): [w(64)][69.4%][r=0KiB/s,w=2085MiB/s][r=0,w=4436 IOPS][eta 00m:11s]Jobs: 64 (f=64): [w(64)][72.2%][r=0KiB/s,w=2102MiB/s][r=0,w=4413 IOPS][eta 00m:10s]Jobs: 64 (f=64): [w(64)][75.0%][r=0KiB/s,w=2127MiB/s][r=0,w=4575 IOPS][eta 00m:09s]Jobs: 64 (f=64): [w(64)][77.8%][r=0KiB/s,w=2099MiB/s][r=0,w=4459 IOPS][eta 00m:08s]Jobs: 64 (f=64): [w(64)][80.6%][r=0KiB/s,w=2121MiB/s][r=0,w=4458 IOPS][eta 00m:07s]Jobs: 64 (f=64): [w(64)][83.3%][r=0KiB/s,w=2136MiB/s][r=0,w=4577 IOPS][eta 00m:06s]Jobs: 64 (f=64): [w(64)][86.1%][r=0KiB/s,w=2117MiB/s][r=0,w=4401 IOPS][eta 00m:05s]Jobs: 64 (f=64): [w(64)][88.9%][r=0KiB/s,w=2122MiB/s][r=0,w=4590 IOPS][eta 00m:04s]Jobs: 64 (f=64): [w(64)][91.7%][r=0KiB/s,w=2101MiB/s][r=0,w=4536 IOPS][eta 00m:03s]Jobs: 64 (f=64): [w(64)][94.4%][r=0KiB/s,w=2112MiB/s][r=0,w=4468 IOPS][eta 00m:02s]Jobs: 64 (f=64): [w(64)][97.2%][r=0KiB/s,w=2125MiB/s][r=0,w=4549 IOPS][eta 00m:01s]Jobs: 64 (f=64): [w(64)][100.0%][r=0KiB/s,w=2112MiB/s][r=0,w=4517 IOPS][eta 00m:00s]
job1: (groupid=0, jobs=64): err= 0: pid=28279: Thu Sep 27 07:45:04 2018
  write: IOPS=4439, BW=2107MiB/s (2210MB/s)(61.8GiB/30021msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=13.32%, sys=0.26%, ctx=136486, majf=0, minf=54745
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,133272,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=2107MiB/s (2210MB/s), 2107MiB/s-2107MiB/s (2210MB/s-2210MB/s), io=61.8GiB (66.4GB), run=30021-30021msec

Disk stats (read/write):
  nvme1n1: ios=43/8774, merge=0/0, ticks=14/73656, in_queue=73669, util=72.85%
  nvme2n1: ios=43/8700, merge=0/0, ticks=13/80083, in_queue=80093, util=73.06%
  nvme3n1: ios=43/8762, merge=0/0, ticks=11/80884, in_queue=80938, util=73.18%
  nvme4n1: ios=43/8666, merge=0/0, ticks=450/81474, in_queue=81955, util=73.62%
  nvme5n1: ios=43/8747, merge=0/0, ticks=430/82059, in_queue=82488, util=73.80%
  nvme6n1: ios=43/8672, merge=0/0, ticks=541/82819, in_queue=83389, util=74.19%
  nvme7n1: ios=43/8748, merge=0/0, ticks=387/83714, in_queue=84099, util=74.80%
  nvme8n1: ios=43/8638, merge=0/0, ticks=355/83144, in_queue=83518, util=74.64%
  nvme9n1: ios=43/8697, merge=0/0, ticks=394/83821, in_queue=84214, util=75.48%
  nvme10n1: ios=43/8656, merge=0/0, ticks=416/83363, in_queue=83818, util=75.40%
  nvme11n1: ios=43/8697, merge=0/0, ticks=488/84025, in_queue=84526, util=75.36%
  nvme12n1: ios=43/8685, merge=0/0, ticks=428/85126, in_queue=85553, util=75.56%
  nvme13n1: ios=43/8663, merge=0/0, ticks=388/83667, in_queue=84085, util=75.27%
  nvme14n1: ios=43/8705, merge=0/0, ticks=447/84651, in_queue=85109, util=75.94%
  nvme15n1: ios=45/8674, merge=0/0, ticks=446/83600, in_queue=84047, util=75.28%
  nvme16n1: ios=45/8637, merge=0/0, ticks=401/83777, in_queue=84216, util=75.54%
  nvme17n1: ios=45/8724, merge=0/0, ticks=422/84378, in_queue=84792, util=75.65%
  nvme18n1: ios=45/8671, merge=0/0, ticks=450/84426, in_queue=84887, util=75.89%
  nvme19n1: ios=45/8671, merge=0/0, ticks=377/83886, in_queue=84270, util=75.59%
  nvme20n1: ios=45/8620, merge=0/0, ticks=400/84580, in_queue=85022, util=75.69%
  nvme21n1: ios=45/8634, merge=0/0, ticks=461/84335, in_queue=84821, util=75.80%
  nvme22n1: ios=45/8602, merge=0/0, ticks=490/83403, in_queue=83892, util=75.75%
  nvme23n1: ios=45/8658, merge=0/0, ticks=396/84540, in_queue=84934, util=75.75%
  nvme24n1: ios=45/8683, merge=0/0, ticks=413/83917, in_queue=84328, util=76.27%
  nvme25n1: ios=45/8714, merge=0/0, ticks=420/83931, in_queue=84352, util=75.91%
  nvme26n1: ios=45/8593, merge=0/0, ticks=408/83067, in_queue=83539, util=75.84%
  nvme27n1: ios=45/8666, merge=0/0, ticks=405/83953, in_queue=84397, util=75.93%
  nvme28n1: ios=45/8583, merge=0/0, ticks=397/83532, in_queue=83955, util=75.98%
  nvme29n1: ios=45/8665, merge=0/0, ticks=413/84244, in_queue=84656, util=76.26%
  nvme30n1: ios=45/8560, merge=0/0, ticks=475/83596, in_queue=84072, util=76.48%
  nvme31n1: ios=45/8756, merge=0/0, ticks=455/84622, in_queue=85098, util=77.35%
  nvme32n1: ios=45/8712, merge=0/0, ticks=423/86300, in_queue=86771, util=77.60%
  nvme33n1: ios=45/8622, merge=0/0, ticks=440/83723, in_queue=84162, util=76.72%
  nvme34n1: ios=45/8599, merge=0/0, ticks=514/83917, in_queue=84441, util=77.36%
  nvme35n1: ios=45/8717, merge=0/0, ticks=426/84282, in_queue=84715, util=77.58%
  nvme36n1: ios=45/8680, merge=0/0, ticks=422/84720, in_queue=85143, util=78.45%
  nvme37n1: ios=45/8715, merge=0/0, ticks=459/85396, in_queue=85869, util=78.52%
  nvme38n1: ios=45/8615, merge=0/0, ticks=360/85215, in_queue=85578, util=78.11%
  nvme39n1: ios=45/8730, merge=0/0, ticks=455/86170, in_queue=86654, util=78.90%
  nvme40n1: ios=45/8671, merge=0/0, ticks=358/84889, in_queue=85287, util=78.93%
  nvme41n1: ios=45/8651, merge=0/0, ticks=466/85624, in_queue=86088, util=78.94%
  nvme42n1: ios=45/8594, merge=0/0, ticks=439/84370, in_queue=84818, util=79.17%
  nvme43n1: ios=45/8686, merge=0/0, ticks=378/84721, in_queue=85101, util=79.27%
  nvme44n1: ios=45/8626, merge=0/0, ticks=363/84217, in_queue=84614, util=79.39%
  nvme45n1: ios=45/8719, merge=0/0, ticks=420/85363, in_queue=85785, util=80.19%
  nvme46n1: ios=45/8635, merge=0/0, ticks=383/83940, in_queue=84321, util=80.07%
  nvme47n1: ios=45/8680, merge=0/0, ticks=386/82987, in_queue=83396, util=79.87%
  nvme48n1: ios=45/8675, merge=0/0, ticks=435/85971, in_queue=86412, util=80.81%
  nvme49n1: ios=45/8657, merge=0/0, ticks=464/83447, in_queue=83905, util=80.33%
  nvme50n1: ios=45/8679, merge=0/0, ticks=518/85059, in_queue=85587, util=81.44%
  nvme51n1: ios=45/8675, merge=0/0, ticks=411/84747, in_queue=85187, util=81.26%
  nvme52n1: ios=45/8648, merge=0/0, ticks=405/84360, in_queue=84792, util=81.78%
  nvme53n1: ios=43/8716, merge=0/0, ticks=408/85785, in_queue=86192, util=82.41%
  nvme54n1: ios=43/8598, merge=0/0, ticks=418/85049, in_queue=85494, util=82.17%
  nvme55n1: ios=43/8663, merge=0/0, ticks=361/84141, in_queue=84522, util=82.41%
  nvme56n1: ios=43/8602, merge=0/0, ticks=498/85573, in_queue=86072, util=83.00%
  nvme57n1: ios=43/8663, merge=0/0, ticks=402/85032, in_queue=85444, util=83.33%
  nvme58n1: ios=43/8611, merge=0/0, ticks=401/85026, in_queue=85430, util=83.91%
  nvme59n1: ios=43/8638, merge=0/0, ticks=439/84453, in_queue=84897, util=84.11%
  nvme60n1: ios=43/8648, merge=0/0, ticks=448/84892, in_queue=85398, util=84.52%
  nvme61n1: ios=43/8724, merge=0/0, ticks=362/85464, in_queue=85844, util=85.58%
  nvme62n1: ios=43/8666, merge=0/0, ticks=434/85575, in_queue=86019, util=85.81%
  nvme63n1: ios=43/8751, merge=0/0, ticks=361/84940, in_queue=85340, util=86.37%
  nvme64n1: ios=43/8651, merge=0/0, ticks=389/84007, in_queue=84392, util=86.41%


    DEBUG: 2018/09/27 07:45:04 Running VERIFY IOs with SHA512 checksum : BS Range (32K to 1024K)
    DEBUG: 2018/09/27 07:45:04 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize_range=32K-1024K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:45:39 output : job1: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job6: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job7: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job8: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job9: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job10: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job11: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job12: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job13: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job14: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job15: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job16: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job17: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job18: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job19: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job20: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job21: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job22: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job23: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job24: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job25: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job26: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job27: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job28: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job29: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job30: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job31: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job32: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job33: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job34: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job35: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job36: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job37: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job38: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job39: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job40: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job41: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job42: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job43: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job44: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job45: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job46: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job47: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job48: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job49: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job50: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job51: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job52: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job53: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job54: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job55: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job56: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job57: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job58: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job59: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job60: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job61: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job62: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job63: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job64: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=64): [V(64)][0.0%][r=44.3MiB/s,w=0KiB/s][r=95,w=0 IOPS][eta 05h:32m:21s]Jobs: 64 (f=64): [V(64)][0.2%][r=2159MiB/s,w=0KiB/s][r=4412,w=0 IOPS][eta 59m:04s]  Jobs: 64 (f=64): [V(64)][0.3%][r=2152MiB/s,w=0KiB/s][r=4459,w=0 IOPS][eta 46m:01s]Jobs: 64 (f=64): [V(64)][0.4%][r=2194MiB/s,w=0KiB/s][r=4549,w=0 IOPS][eta 41m:30s]Jobs: 64 (f=64): [V(64)][0.4%][r=2177MiB/s,w=0KiB/s][r=4528,w=0 IOPS][eta 39m:15s]Jobs: 64 (f=64): [V(64)][0.5%][r=2204MiB/s,w=0KiB/s][r=4612,w=0 IOPS][eta 37m:36s]Jobs: 64 (f=64): [V(64)][0.5%][r=2186MiB/s,w=0KiB/s][r=4499,w=0 IOPS][eta 36m:51s]Jobs: 64 (f=64): [V(64)][0.6%][r=2183MiB/s,w=0KiB/s][r=4544,w=0 IOPS][eta 36m:15s]Jobs: 64 (f=64): [V(64)][0.6%][r=2166MiB/s,w=0KiB/s][r=4502,w=0 IOPS][eta 35m:51s]Jobs: 64 (f=64): [V(64)][0.7%][r=2167MiB/s,w=0KiB/s][r=4497,w=0 IOPS][eta 35m:26s]Jobs: 64 (f=64): [V(64)][0.8%][r=2179MiB/s,w=0KiB/s][r=4591,w=0 IOPS][eta 35m:07s]Jobs: 64 (f=64): [V(64)][0.8%][r=2157MiB/s,w=0KiB/s][r=4461,w=0 IOPS][eta 34m:50s]Jobs: 64 (f=64): [V(64)][0.9%][r=2209MiB/s,w=0KiB/s][r=4598,w=0 IOPS][eta 34m:31s]Jobs: 64 (f=64): [V(64)][0.9%][r=2178MiB/s,w=0KiB/s][r=4664,w=0 IOPS][eta 34m:17s]Jobs: 64 (f=64): [V(64)][1.0%][r=2182MiB/s,w=0KiB/s][r=4585,w=0 IOPS][eta 34m:08s]Jobs: 64 (f=64): [V(64)][1.0%][r=2164MiB/s,w=0KiB/s][r=4543,w=0 IOPS][eta 33m:57s]Jobs: 64 (f=64): [V(64)][1.1%][r=2193MiB/s,w=0KiB/s][r=4727,w=0 IOPS][eta 33m:48s]Jobs: 64 (f=64): [V(64)][1.1%][r=2200MiB/s,w=0KiB/s][r=4693,w=0 IOPS][eta 33m:35s]Jobs: 64 (f=64): [V(64)][1.2%][r=2173MiB/s,w=0KiB/s][r=4558,w=0 IOPS][eta 33m:28s]Jobs: 64 (f=64): [V(64)][1.2%][r=2179MiB/s,w=0KiB/s][r=4651,w=0 IOPS][eta 33m:25s]Jobs: 64 (f=64): [V(64)][1.3%][r=2185MiB/s,w=0KiB/s][r=4661,w=0 IOPS][eta 33m:16s]Jobs: 64 (f=64): [V(64)][1.3%][r=2180MiB/s,w=0KiB/s][r=4607,w=0 IOPS][eta 33m:11s]Jobs: 64 (f=64): [V(64)][1.4%][r=2157MiB/s,w=0KiB/s][r=4594,w=0 IOPS][eta 33m:08s]Jobs: 64 (f=64): [V(64)][1.4%][r=2178MiB/s,w=0KiB/s][r=4552,w=0 IOPS][eta 33m:05s]Jobs: 64 (f=64): [V(64)][1.5%][r=2190MiB/s,w=0KiB/s][r=4694,w=0 IOPS][eta 33m:01s]Jobs: 64 (f=64): [V(64)][1.5%][r=2167MiB/s,w=0KiB/s][r=4701,w=0 IOPS][eta 32m:55s]Jobs: 64 (f=64): [V(64)][1.6%][r=2156MiB/s,w=0KiB/s][r=4594,w=0 IOPS][eta 32m:51s]Jobs: 64 (f=64): [V(64)][1.6%][r=2174MiB/s,w=0KiB/s][r=4601,w=0 IOPS][eta 32m:48s]Jobs: 64 (f=64): [V(64)][1.7%][r=2197MiB/s,w=0KiB/s][r=4719,w=0 IOPS][eta 32m:45s]Jobs: 5 (f=5): [_(2),E(1),_(1),E(1),_(19),V(1),_(5),V(1),_(3),V(1),_(5),V(1),_(21),V(1),_(1)][1.8%][r=2045MiB/s,w=0KiB/s][r=4371,w=0 IOPS][eta 31m:47s]
job1: (groupid=0, jobs=64): err= 0: pid=28974: Thu Sep 27 07:45:39 2018
   read: IOPS=4572, BW=2171MiB/s (2276MB/s)(61.8GiB/29146msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=13.09%, sys=0.51%, ctx=135164, majf=0, minf=11959
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=133272,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=2171MiB/s (2276MB/s), 2171MiB/s-2171MiB/s (2276MB/s-2276MB/s), io=61.8GiB (66.4GB), run=29146-29146msec

Disk stats (read/write):
  nvme1n1: ios=8848/0, merge=0/0, ticks=71908/0, in_queue=71914, util=74.07%
  nvme2n1: ios=8741/0, merge=0/0, ticks=78037/0, in_queue=78037, util=74.25%
  nvme3n1: ios=8746/0, merge=0/0, ticks=79129/0, in_queue=79132, util=74.62%
  nvme4n1: ios=8752/0, merge=0/0, ticks=79085/0, in_queue=79093, util=74.39%
  nvme5n1: ios=8734/0, merge=0/0, ticks=79688/0, in_queue=79710, util=74.89%
  nvme6n1: ios=8755/0, merge=0/0, ticks=81546/0, in_queue=81569, util=75.66%
  nvme7n1: ios=8802/0, merge=0/0, ticks=81899/0, in_queue=81910, util=75.98%
  nvme8n1: ios=8666/0, merge=0/0, ticks=81325/0, in_queue=81336, util=76.10%
  nvme9n1: ios=8745/0, merge=0/0, ticks=81508/0, in_queue=81513, util=76.40%
  nvme10n1: ios=8761/0, merge=0/0, ticks=81289/0, in_queue=81317, util=76.21%
  nvme11n1: ios=8737/0, merge=0/0, ticks=82533/0, in_queue=82539, util=76.69%
  nvme12n1: ios=8706/0, merge=0/0, ticks=82959/0, in_queue=82961, util=76.44%
  nvme13n1: ios=8698/0, merge=0/0, ticks=81732/0, in_queue=81729, util=76.65%
  nvme14n1: ios=8768/0, merge=0/0, ticks=82700/0, in_queue=82699, util=77.08%
  nvme15n1: ios=8710/0, merge=0/0, ticks=81803/0, in_queue=81811, util=76.62%
  nvme16n1: ios=8669/0, merge=0/0, ticks=81270/0, in_queue=81277, util=76.89%
  nvme17n1: ios=8772/0, merge=0/0, ticks=82498/0, in_queue=82518, util=77.04%
  nvme18n1: ios=8784/0, merge=0/0, ticks=82923/0, in_queue=82922, util=77.29%
  nvme19n1: ios=8724/0, merge=0/0, ticks=81526/0, in_queue=81543, util=77.33%
  nvme20n1: ios=8688/0, merge=0/0, ticks=82082/0, in_queue=82110, util=77.19%
  nvme21n1: ios=8679/0, merge=0/0, ticks=82733/0, in_queue=82753, util=77.22%
  nvme22n1: ios=8601/0, merge=0/0, ticks=80422/0, in_queue=80438, util=77.51%
  nvme23n1: ios=8741/0, merge=0/0, ticks=83131/0, in_queue=83129, util=77.61%
  nvme24n1: ios=8762/0, merge=0/0, ticks=82097/0, in_queue=82098, util=77.94%
  nvme25n1: ios=8812/0, merge=0/0, ticks=82688/0, in_queue=82682, util=77.12%
  nvme26n1: ios=8688/0, merge=0/0, ticks=81454/0, in_queue=81453, util=77.55%
  nvme27n1: ios=8682/0, merge=0/0, ticks=82355/0, in_queue=82359, util=77.52%
  nvme28n1: ios=8614/0, merge=0/0, ticks=80523/0, in_queue=80525, util=78.14%
  nvme29n1: ios=8753/0, merge=0/0, ticks=82741/0, in_queue=82756, util=78.05%
  nvme30n1: ios=8625/0, merge=0/0, ticks=80970/0, in_queue=81018, util=78.22%
  nvme31n1: ios=8839/0, merge=0/0, ticks=82551/0, in_queue=82559, util=78.25%
  nvme32n1: ios=8664/0, merge=0/0, ticks=83017/0, in_queue=83016, util=78.30%
  nvme33n1: ios=8700/0, merge=0/0, ticks=82035/0, in_queue=82061, util=78.62%
  nvme34n1: ios=8693/0, merge=0/0, ticks=82145/0, in_queue=82148, util=79.00%
  nvme35n1: ios=8804/0, merge=0/0, ticks=82835/0, in_queue=82832, util=79.00%
  nvme36n1: ios=8683/0, merge=0/0, ticks=82041/0, in_queue=82053, util=79.07%
  nvme37n1: ios=8761/0, merge=0/0, ticks=83632/0, in_queue=83671, util=79.99%
  nvme38n1: ios=8681/0, merge=0/0, ticks=82447/0, in_queue=82454, util=79.43%
  nvme39n1: ios=8723/0, merge=0/0, ticks=83750/0, in_queue=83760, util=79.95%
  nvme40n1: ios=8724/0, merge=0/0, ticks=83291/0, in_queue=83302, util=80.30%
  nvme41n1: ios=8754/0, merge=0/0, ticks=83918/0, in_queue=83916, util=79.83%
  nvme42n1: ios=8661/0, merge=0/0, ticks=81793/0, in_queue=81810, util=80.50%
  nvme43n1: ios=8702/0, merge=0/0, ticks=83337/0, in_queue=83358, util=80.52%
  nvme44n1: ios=8725/0, merge=0/0, ticks=82550/0, in_queue=82547, util=80.68%
  nvme45n1: ios=8746/0, merge=0/0, ticks=83487/0, in_queue=83494, util=81.34%
  nvme46n1: ios=8703/0, merge=0/0, ticks=81743/0, in_queue=81746, util=80.91%
  nvme47n1: ios=8680/0, merge=0/0, ticks=81538/0, in_queue=81552, util=81.27%
  nvme48n1: ios=8766/0, merge=0/0, ticks=84142/0, in_queue=84142, util=82.27%
  nvme49n1: ios=8766/0, merge=0/0, ticks=82668/0, in_queue=82666, util=82.62%
  nvme50n1: ios=8722/0, merge=0/0, ticks=82817/0, in_queue=82825, util=82.10%
  nvme51n1: ios=8690/0, merge=0/0, ticks=82578/0, in_queue=82595, util=82.37%
  nvme52n1: ios=8704/0, merge=0/0, ticks=82244/0, in_queue=82243, util=82.67%
  nvme53n1: ios=8709/0, merge=0/0, ticks=83140/0, in_queue=83140, util=82.78%
  nvme54n1: ios=8642/0, merge=0/0, ticks=82886/0, in_queue=82928, util=83.16%
  nvme55n1: ios=8759/0, merge=0/0, ticks=82760/0, in_queue=82771, util=83.93%
  nvme56n1: ios=8702/0, merge=0/0, ticks=83412/0, in_queue=83435, util=83.54%
  nvme57n1: ios=8701/0, merge=0/0, ticks=83402/0, in_queue=83403, util=84.59%
  nvme58n1: ios=8697/0, merge=0/0, ticks=82770/0, in_queue=82789, util=84.83%
  nvme59n1: ios=8726/0, merge=0/0, ticks=83299/0, in_queue=83326, util=85.23%
  nvme60n1: ios=8681/0, merge=0/0, ticks=82534/0, in_queue=82562, util=84.98%
  nvme61n1: ios=8758/0, merge=0/0, ticks=83447/0, in_queue=83476, util=85.85%
  nvme62n1: ios=8743/0, merge=0/0, ticks=83521/0, in_queue=83538, util=85.91%
  nvme63n1: ios=8849/0, merge=0/0, ticks=83085/0, in_queue=83085, util=85.92%
  nvme64n1: ios=8700/0, merge=0/0, ticks=82042/0, in_queue=82054, util=86.61%


    DEBUG: 2018/09/27 07:45:39 Running WRITE IOs with SHA512 checksum : IO SIZE(4K), bs_unaligned
    DEBUG: 2018/09/27 07:45:39 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize=4K  --blocksize_unaligned=1 --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:46:31 output : job1: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job6: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job7: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job8: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job9: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job10: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job11: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job12: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job13: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job14: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job15: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job16: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job17: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job18: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job19: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job20: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job21: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job22: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job23: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job24: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job25: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job26: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job27: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job28: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job29: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job30: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job31: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job32: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job33: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job34: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job35: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job36: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job37: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job38: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job39: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job40: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job41: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job42: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job43: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job44: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job45: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job46: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job47: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job48: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job49: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job50: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job51: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job52: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job53: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job54: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job55: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job56: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job57: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job58: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job59: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job60: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job61: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job62: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job63: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job64: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 36 (f=35): [w(36),I(28)][16.7%][r=0KiB/s,w=11.2MiB/s][r=0,w=2845 IOPS][eta 00m:30s]Jobs: 64 (f=64): [w(64)][19.4%][r=0KiB/s,w=3767MiB/s][r=0,w=964k IOPS][eta 00m:29s]      Jobs: 64 (f=64): [w(64)][22.2%][r=0KiB/s,w=3955MiB/s][r=0,w=1013k IOPS][eta 00m:28s]Jobs: 64 (f=64): [w(64)][25.0%][r=0KiB/s,w=3938MiB/s][r=0,w=1008k IOPS][eta 00m:27s]Jobs: 64 (f=64): [w(64)][27.8%][r=0KiB/s,w=3715MiB/s][r=0,w=951k IOPS][eta 00m:26s] Jobs: 64 (f=64): [w(64)][30.6%][r=0KiB/s,w=3703MiB/s][r=0,w=948k IOPS][eta 00m:25s]Jobs: 64 (f=64): [w(64)][33.3%][r=0KiB/s,w=3703MiB/s][r=0,w=948k IOPS][eta 00m:24s]Jobs: 64 (f=64): [w(64)][36.1%][r=0KiB/s,w=3536MiB/s][r=0,w=905k IOPS][eta 00m:23s]Jobs: 64 (f=64): [w(64)][38.9%][r=0KiB/s,w=3350MiB/s][r=0,w=858k IOPS][eta 00m:22s]Jobs: 64 (f=64): [w(64)][41.7%][r=0KiB/s,w=3485MiB/s][r=0,w=892k IOPS][eta 00m:21s]Jobs: 64 (f=64): [w(64)][44.4%][r=0KiB/s,w=2008MiB/s][r=0,w=514k IOPS][eta 00m:20s]Jobs: 64 (f=64): [w(64)][47.2%][r=0KiB/s,w=1660MiB/s][r=0,w=425k IOPS][eta 00m:19s]Jobs: 64 (f=64): [w(64)][50.0%][r=0KiB/s,w=1660MiB/s][r=0,w=425k IOPS][eta 00m:18s]Jobs: 64 (f=64): [w(64)][52.8%][r=0KiB/s,w=1653MiB/s][r=0,w=423k IOPS][eta 00m:17s]Jobs: 64 (f=64): [w(64)][55.6%][r=0KiB/s,w=1660MiB/s][r=0,w=425k IOPS][eta 00m:16s]Jobs: 64 (f=64): [w(64)][58.3%][r=0KiB/s,w=1657MiB/s][r=0,w=424k IOPS][eta 00m:15s]Jobs: 64 (f=64): [w(64)][61.1%][r=0KiB/s,w=1657MiB/s][r=0,w=424k IOPS][eta 00m:14s]Jobs: 64 (f=64): [w(64)][63.9%][r=0KiB/s,w=1660MiB/s][r=0,w=425k IOPS][eta 00m:13s]Jobs: 64 (f=64): [w(64)][66.7%][r=0KiB/s,w=1670MiB/s][r=0,w=428k IOPS][eta 00m:12s]Jobs: 64 (f=64): [w(64)][69.4%][r=0KiB/s,w=1678MiB/s][r=0,w=430k IOPS][eta 00m:11s]Jobs: 64 (f=64): [w(64)][72.2%][r=0KiB/s,w=1676MiB/s][r=0,w=429k IOPS][eta 00m:10s]Jobs: 64 (f=64): [w(64)][75.0%][r=0KiB/s,w=1690MiB/s][r=0,w=433k IOPS][eta 00m:09s]Jobs: 64 (f=64): [w(64)][77.8%][r=0KiB/s,w=1694MiB/s][r=0,w=434k IOPS][eta 00m:08s]Jobs: 64 (f=64): [w(64)][80.6%][r=0KiB/s,w=1709MiB/s][r=0,w=438k IOPS][eta 00m:07s]Jobs: 64 (f=64): [w(64)][83.3%][r=0KiB/s,w=1718MiB/s][r=0,w=440k IOPS][eta 00m:06s]Jobs: 64 (f=64): [w(64)][86.1%][r=0KiB/s,w=1716MiB/s][r=0,w=439k IOPS][eta 00m:05s]Jobs: 64 (f=64): [w(64)][88.9%][r=0KiB/s,w=1711MiB/s][r=0,w=438k IOPS][eta 00m:04s]Jobs: 64 (f=64): [w(64)][91.7%][r=0KiB/s,w=1715MiB/s][r=0,w=439k IOPS][eta 00m:03s]Jobs: 64 (f=64): [w(64)][94.4%][r=0KiB/s,w=1717MiB/s][r=0,w=440k IOPS][eta 00m:02s]Jobs: 64 (f=64): [w(64)][97.2%][r=0KiB/s,w=1710MiB/s][r=0,w=438k IOPS][eta 00m:01s]Jobs: 64 (f=64): [f(36),w(1),f(5),w(22)][3.2%][r=0KiB/s,w=1620MiB/s][r=0,w=415k IOPS][eta 18m:14s]Jobs: 64 (f=64): [f(64)][100.0%][r=0KiB/s,w=13.9MiB/s][r=0,w=3546 IOPS][eta 00m:00s]              Jobs: 64 (f=64): [f(64)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]      Jobs: 64 (f=64): [f(64)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 64 (f=64): [f(64)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 64 (f=64): [f(64)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 64 (f=64): [f(64)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 64 (f=64): [f(64)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 63 (f=63): [f(59),_(1),f(4)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 63 (f=63): [f(59),_(1),f(4)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 63 (f=63): [f(59),_(1),f(4)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 63 (f=63): [f(59),_(1),f(4)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 60 (f=60): [f(3),_(1),f(6),_(1),f(3),_(1),f(44),_(1),f(4)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 56 (f=56): [f(3),_(1),f(6),_(1),f(2),_(2),f(4),_(1),f(12),_(1),f(23),_(1),f(2),_(1),f(4)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 41 (f=39): [f(2),_(5),f(1),_(1),f(1),_(1),f(1),_(4),f(3),_(1),f(7),_(1),f(1),_(1),E(1),f(1),_(1),f(5),_(1),f(2),_(1),f(2),_(1),f(4),_(1),f(6),_(1),f(2),_(1),f(3),_(1)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]
job1: (groupid=0, jobs=64): err= 0: pid=29649: Thu Sep 27 07:46:31 2018
  write: IOPS=587k, BW=2293MiB/s (2404MB/s)(67.4GiB/30071msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=20.67%, sys=3.70%, ctx=352041, majf=0, minf=96946
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,17648093,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=2293MiB/s (2404MB/s), 2293MiB/s-2293MiB/s (2404MB/s-2404MB/s), io=67.4GiB (72.3GB), run=30071-30071msec

Disk stats (read/write):
  nvme1n1: ios=43/87953, merge=0/148610, ticks=16/5946005, in_queue=5958344, util=75.27%
  nvme2n1: ios=43/127204, merge=0/78867, ticks=12/5689755, in_queue=5692982, util=75.70%
  nvme3n1: ios=51/148886, merge=0/44242, ticks=27/5996336, in_queue=6001815, util=75.85%
  nvme4n1: ios=0/158823, merge=0/31279, ticks=0/5611044, in_queue=5615007, util=76.07%
  nvme5n1: ios=0/162083, merge=0/24234, ticks=0/5921726, in_queue=5927689, util=76.15%
  nvme6n1: ios=0/170240, merge=0/19139, ticks=0/6000555, in_queue=6013956, util=76.84%
  nvme7n1: ios=0/173085, merge=0/13809, ticks=0/5986726, in_queue=5991929, util=76.99%
  nvme8n1: ios=0/172403, merge=0/14740, ticks=0/5569534, in_queue=5574158, util=77.29%
  nvme9n1: ios=0/172989, merge=0/11809, ticks=0/5919804, in_queue=5924802, util=77.51%
  nvme10n1: ios=0/175435, merge=0/11596, ticks=0/5996160, in_queue=6001408, util=77.66%
  nvme11n1: ios=2/177148, merge=0/9117, ticks=0/5956404, in_queue=5961856, util=77.71%
  nvme12n1: ios=2/176550, merge=0/10275, ticks=0/5971041, in_queue=5975390, util=77.70%
  nvme13n1: ios=2/176226, merge=0/8175, ticks=0/5896810, in_queue=5902060, util=77.57%
  nvme14n1: ios=2/179482, merge=0/7032, ticks=0/5956916, in_queue=5959036, util=77.73%
  nvme15n1: ios=2/177812, merge=0/6473, ticks=0/5924772, in_queue=5929049, util=77.67%
  nvme16n1: ios=2/178344, merge=0/6425, ticks=0/5551566, in_queue=5556299, util=77.69%
  nvme17n1: ios=2/177987, merge=0/6239, ticks=0/5877310, in_queue=5881579, util=77.77%
  nvme18n1: ios=2/180072, merge=0/6241, ticks=0/5593074, in_queue=5598809, util=77.97%
  nvme19n1: ios=2/179754, merge=0/6083, ticks=0/5963534, in_queue=5965027, util=78.04%
  nvme20n1: ios=2/179530, merge=0/5088, ticks=0/5933978, in_queue=5938720, util=77.93%
  nvme21n1: ios=2/180054, merge=0/3937, ticks=0/5907008, in_queue=5911918, util=78.00%
  nvme22n1: ios=2/179197, merge=0/5619, ticks=0/5526051, in_queue=5530645, util=78.10%
  nvme23n1: ios=2/178109, merge=0/5956, ticks=0/5538100, in_queue=5542561, util=78.14%
  nvme24n1: ios=2/181377, merge=0/4772, ticks=0/5570977, in_queue=5575328, util=78.38%
  nvme25n1: ios=2/181491, merge=0/4222, ticks=0/5952601, in_queue=5953968, util=78.51%
  nvme26n1: ios=2/181619, merge=0/4781, ticks=0/5585426, in_queue=5588055, util=78.60%
  nvme27n1: ios=2/179613, merge=0/4199, ticks=0/5549347, in_queue=5555151, util=78.48%
  nvme28n1: ios=2/183120, merge=0/3716, ticks=0/5971724, in_queue=5973032, util=78.82%
  nvme29n1: ios=2/181469, merge=0/4141, ticks=0/5956021, in_queue=5961224, util=78.85%
  nvme30n1: ios=2/182620, merge=0/3550, ticks=0/5582131, in_queue=5585367, util=78.98%
  nvme31n1: ios=2/183657, merge=0/4001, ticks=0/5628670, in_queue=5631953, util=79.31%
  nvme32n1: ios=2/182797, merge=0/3390, ticks=0/5974111, in_queue=5975435, util=79.36%
  nvme33n1: ios=2/182410, merge=0/2765, ticks=0/5976497, in_queue=5980583, util=79.36%
  nvme34n1: ios=2/182722, merge=0/3410, ticks=0/5934739, in_queue=5936953, util=79.65%
  nvme35n1: ios=2/182398, merge=0/3200, ticks=0/5973472, in_queue=5977766, util=79.94%
  nvme36n1: ios=2/183473, merge=0/3371, ticks=0/5608047, in_queue=5611703, util=80.29%
  nvme37n1: ios=2/182554, merge=0/2871, ticks=0/5934601, in_queue=5939270, util=80.39%
  nvme38n1: ios=2/182494, merge=0/3530, ticks=0/5605203, in_queue=5610297, util=80.73%
  nvme39n1: ios=2/182970, merge=0/2580, ticks=0/5977876, in_queue=5980117, util=80.97%
  nvme40n1: ios=2/183289, merge=0/2721, ticks=0/5921178, in_queue=5926143, util=81.17%
  nvme41n1: ios=2/182640, merge=0/2994, ticks=0/5598261, in_queue=5599884, util=81.44%
  nvme42n1: ios=2/183589, merge=0/2564, ticks=0/6007611, in_queue=6008532, util=81.67%
  nvme43n1: ios=2/182682, merge=0/3032, ticks=0/5583308, in_queue=5587855, util=81.96%
  nvme44n1: ios=2/183236, merge=0/3020, ticks=0/5587190, in_queue=5590261, util=82.24%
  nvme45n1: ios=2/182905, merge=0/2612, ticks=0/5991423, in_queue=5992803, util=82.50%
  nvme46n1: ios=2/183415, merge=0/2613, ticks=0/5607272, in_queue=5611751, util=82.90%
  nvme47n1: ios=2/184456, merge=0/2326, ticks=0/5968782, in_queue=5973971, util=83.17%
  nvme48n1: ios=2/186407, merge=0/2439, ticks=0/5601337, in_queue=5603184, util=83.58%
  nvme49n1: ios=2/187841, merge=0/2712, ticks=0/5980480, in_queue=5982080, util=83.94%
  nvme50n1: ios=2/192230, merge=0/1926, ticks=0/6001525, in_queue=6007273, util=84.28%
  nvme51n1: ios=2/193632, merge=0/2320, ticks=0/5599744, in_queue=5602425, util=84.68%
  nvme52n1: ios=2/194042, merge=0/2357, ticks=0/5602213, in_queue=5606585, util=85.03%
  nvme53n1: ios=2/192770, merge=0/2165, ticks=0/5928491, in_queue=5929607, util=85.19%
  nvme54n1: ios=2/209668, merge=0/2309, ticks=0/5964539, in_queue=5970164, util=85.93%
  nvme55n1: ios=2/202234, merge=0/2293, ticks=0/5589753, in_queue=5592424, util=86.09%
  nvme56n1: ios=2/220382, merge=0/1599, ticks=0/6028755, in_queue=6030199, util=86.66%
  nvme57n1: ios=2/216963, merge=0/1493, ticks=0/5981220, in_queue=5986209, util=86.98%
  nvme58n1: ios=2/228922, merge=0/1758, ticks=0/5973028, in_queue=5977367, util=87.50%
  nvme59n1: ios=2/192186, merge=0/1717, ticks=10/7172866, in_queue=7178891, util=87.08%
  nvme60n1: ios=0/183796, merge=0/2147, ticks=0/8513684, in_queue=8529670, util=87.15%
  nvme61n1: ios=0/183810, merge=0/2358, ticks=0/5565270, in_queue=5566705, util=87.66%
  nvme62n1: ios=0/183794, merge=0/2271, ticks=0/5992857, in_queue=5997382, util=88.09%
  nvme63n1: ios=0/183325, merge=0/2276, ticks=0/5619240, in_queue=5621744, util=88.56%
  nvme64n1: ios=0/183979, merge=0/2249, ticks=0/5932190, in_queue=5934531, util=89.03%


    DEBUG: 2018/09/27 07:46:31 Running VERIFY IOs with SHA512 checksum : IO SIZE(4K), bs_unaligned
    DEBUG: 2018/09/27 07:46:31 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize=4K  --blocksize_unaligned=1 --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1 --name=job6 --filename=/dev/nvme6n1 --name=job7 --filename=/dev/nvme7n1 --name=job8 --filename=/dev/nvme8n1 --name=job9 --filename=/dev/nvme9n1 --name=job10 --filename=/dev/nvme10n1 --name=job11 --filename=/dev/nvme11n1 --name=job12 --filename=/dev/nvme12n1 --name=job13 --filename=/dev/nvme13n1 --name=job14 --filename=/dev/nvme14n1 --name=job15 --filename=/dev/nvme15n1 --name=job16 --filename=/dev/nvme16n1 --name=job17 --filename=/dev/nvme17n1 --name=job18 --filename=/dev/nvme18n1 --name=job19 --filename=/dev/nvme19n1 --name=job20 --filename=/dev/nvme20n1 --name=job21 --filename=/dev/nvme21n1 --name=job22 --filename=/dev/nvme22n1 --name=job23 --filename=/dev/nvme23n1 --name=job24 --filename=/dev/nvme24n1 --name=job25 --filename=/dev/nvme25n1 --name=job26 --filename=/dev/nvme26n1 --name=job27 --filename=/dev/nvme27n1 --name=job28 --filename=/dev/nvme28n1 --name=job29 --filename=/dev/nvme29n1 --name=job30 --filename=/dev/nvme30n1 --name=job31 --filename=/dev/nvme31n1 --name=job32 --filename=/dev/nvme32n1 --name=job33 --filename=/dev/nvme33n1 --name=job34 --filename=/dev/nvme34n1 --name=job35 --filename=/dev/nvme35n1 --name=job36 --filename=/dev/nvme36n1 --name=job37 --filename=/dev/nvme37n1 --name=job38 --filename=/dev/nvme38n1 --name=job39 --filename=/dev/nvme39n1 --name=job40 --filename=/dev/nvme40n1 --name=job41 --filename=/dev/nvme41n1 --name=job42 --filename=/dev/nvme42n1 --name=job43 --filename=/dev/nvme43n1 --name=job44 --filename=/dev/nvme44n1 --name=job45 --filename=/dev/nvme45n1 --name=job46 --filename=/dev/nvme46n1 --name=job47 --filename=/dev/nvme47n1 --name=job48 --filename=/dev/nvme48n1 --name=job49 --filename=/dev/nvme49n1 --name=job50 --filename=/dev/nvme50n1 --name=job51 --filename=/dev/nvme51n1 --name=job52 --filename=/dev/nvme52n1 --name=job53 --filename=/dev/nvme53n1 --name=job54 --filename=/dev/nvme54n1 --name=job55 --filename=/dev/nvme55n1 --name=job56 --filename=/dev/nvme56n1 --name=job57 --filename=/dev/nvme57n1 --name=job58 --filename=/dev/nvme58n1 --name=job59 --filename=/dev/nvme59n1 --name=job60 --filename=/dev/nvme60n1 --name=job61 --filename=/dev/nvme61n1 --name=job62 --filename=/dev/nvme62n1 --name=job63 --filename=/dev/nvme63n1 --name=job64 --filename=/dev/nvme64n1

    DEBUG: 2018/09/27 07:48:02 output : job1: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job6: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job7: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job8: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job9: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job10: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job11: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job12: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job13: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job14: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job15: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job16: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job17: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job18: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job19: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job20: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job21: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job22: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job23: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job24: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job25: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job26: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job27: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job28: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job29: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job30: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job31: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job32: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job33: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job34: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job35: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job36: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job37: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job38: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job39: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job40: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job41: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job42: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job43: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job44: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job45: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job46: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job47: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job48: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job49: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job50: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job51: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job52: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job53: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job54: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job55: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job56: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job57: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job58: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job59: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job60: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job61: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job62: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job63: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job64: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
fio-2.18
Starting 64 processes
Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 0 (f=0)Jobs: 64 (f=64): [V(64)][0.0%][r=18.3MiB/s,w=0KiB/s][r=4671,w=0 IOPS][eta 24d:17h:08m:33s]Jobs: 64 (f=64): [V(64)][0.1%][r=912MiB/s,w=0KiB/s][r=233k,w=0 IOPS][eta 02h:18m:29s]     Jobs: 64 (f=64): [V(64)][0.1%][r=846MiB/s,w=0KiB/s][r=217k,w=0 IOPS][eta 01h:52m:41s]Jobs: 64 (f=64): [V(64)][0.1%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:40m:51s]Jobs: 64 (f=64): [V(64)][0.2%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:34m:51s]Jobs: 64 (f=64): [V(64)][0.2%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:31m:14s]Jobs: 64 (f=64): [V(64)][0.2%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:28m:44s]Jobs: 64 (f=64): [V(64)][0.2%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:26m:58s]Jobs: 64 (f=64): [V(64)][0.3%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:25m:39s]Jobs: 64 (f=64): [V(64)][0.3%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:24m:38s]Jobs: 64 (f=64): [V(64)][0.3%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:23m:49s]Jobs: 64 (f=64): [V(64)][0.3%][r=909MiB/s,w=0KiB/s][r=233k,w=0 IOPS][eta 01h:23m:08s]Jobs: 64 (f=64): [V(64)][0.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:22m:32s]Jobs: 64 (f=64): [V(64)][0.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:22m:02s]Jobs: 64 (f=64): [V(64)][0.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:21m:36s]Jobs: 64 (f=64): [V(64)][0.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:21m:13s]Jobs: 64 (f=64): [V(64)][0.5%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:20m:56s]Jobs: 64 (f=64): [V(64)][0.5%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:20m:38s]Jobs: 64 (f=64): [V(64)][0.5%][r=915MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:20m:23s]Jobs: 64 (f=64): [V(64)][0.5%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:20m:09s]Jobs: 64 (f=64): [V(64)][0.5%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:19m:56s]Jobs: 64 (f=64): [V(64)][0.6%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:19m:45s]Jobs: 64 (f=64): [V(64)][0.6%][r=912MiB/s,w=0KiB/s][r=233k,w=0 IOPS][eta 01h:19m:34s]Jobs: 64 (f=64): [V(64)][0.6%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:19m:25s]Jobs: 64 (f=64): [V(64)][0.6%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:19m:16s]Jobs: 64 (f=64): [V(64)][0.6%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:19m:08s]Jobs: 64 (f=64): [V(64)][0.7%][r=912MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:19m:01s]Jobs: 64 (f=64): [V(64)][0.7%][r=912MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:53s]Jobs: 64 (f=64): [V(64)][0.7%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:46s]Jobs: 64 (f=64): [V(64)][0.7%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:39s]Jobs: 64 (f=64): [V(64)][0.8%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:33s]Jobs: 64 (f=64): [V(64)][0.8%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:27s]Jobs: 64 (f=64): [V(64)][0.8%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:22s]Jobs: 64 (f=64): [V(64)][0.8%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:16s]Jobs: 64 (f=64): [V(64)][0.8%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:10s]Jobs: 64 (f=64): [V(64)][0.9%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:05s]Jobs: 64 (f=64): [V(64)][0.9%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:18m:00s]Jobs: 64 (f=64): [V(64)][0.9%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:56s]Jobs: 64 (f=64): [V(64)][0.9%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:51s]Jobs: 64 (f=64): [V(64)][1.0%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:47s]Jobs: 64 (f=64): [V(64)][1.0%][r=912MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:43s]Jobs: 64 (f=64): [V(64)][1.0%][r=912MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:39s]Jobs: 64 (f=64): [V(64)][1.0%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:36s]Jobs: 64 (f=64): [V(64)][1.0%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:32s]Jobs: 64 (f=64): [V(64)][1.1%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:28s]Jobs: 64 (f=64): [V(64)][1.1%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:25s]Jobs: 64 (f=64): [V(64)][1.1%][r=912MiB/s,w=0KiB/s][r=233k,w=0 IOPS][eta 01h:17m:23s]Jobs: 64 (f=64): [V(64)][1.1%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:20s]Jobs: 64 (f=64): [V(64)][1.2%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:17s]Jobs: 64 (f=64): [V(64)][1.2%][r=912MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:14s]Jobs: 64 (f=64): [V(64)][1.2%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:11s]Jobs: 64 (f=64): [V(64)][1.2%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:09s]Jobs: 64 (f=64): [V(64)][1.2%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:06s]Jobs: 64 (f=64): [V(64)][1.3%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:04s]Jobs: 64 (f=64): [V(64)][1.3%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:17m:01s]Jobs: 64 (f=64): [V(64)][1.3%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:59s]Jobs: 64 (f=64): [V(64)][1.3%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:57s]Jobs: 64 (f=64): [V(64)][1.3%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:54s]Jobs: 64 (f=64): [V(64)][1.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:52s]Jobs: 64 (f=64): [V(64)][1.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:49s]Jobs: 64 (f=64): [V(64)][1.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:47s]Jobs: 64 (f=64): [V(64)][1.4%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:45s]Jobs: 64 (f=64): [V(64)][1.5%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:43s]Jobs: 64 (f=64): [V(64)][1.5%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:41s]Jobs: 64 (f=64): [V(64)][1.5%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:39s]Jobs: 64 (f=64): [V(64)][1.5%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:37s]Jobs: 64 (f=64): [V(64)][1.5%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:35s]Jobs: 64 (f=64): [V(64)][1.6%][r=911MiB/s,w=0KiB/s][r=233k,w=0 IOPS][eta 01h:16m:33s]Jobs: 64 (f=64): [V(64)][1.6%][r=913MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:31s]Jobs: 64 (f=64): [V(64)][1.6%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:29s]Jobs: 64 (f=64): [V(64)][1.6%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:27s]Jobs: 64 (f=64): [V(64)][1.7%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:25s]Jobs: 64 (f=64): [V(64)][1.7%][r=914MiB/s,w=0KiB/s][r=234k,w=0 IOPS][eta 01h:16m:23s]Jobs: 60 (f=60): [V(10),_(1),V(2),_(2),V(17),_(1),V(31)][1.7%][r=893MiB/s,w=0KiB/s][r=229k,w=0 IOPS][eta 01h:16m:20s]Jobs: 43 (f=43): [_(1),V(4),_(4),V(1),_(1),V(1),_(6),V(1),_(1),V(3),_(2),V(4),_(1),V(1),_(2),V(3),_(1),V(1),_(1),V(2),_(1),V(22)][1.7%][r=702MiB/s,w=0KiB/s][r=180k,w=0 IOPS][eta 01h:16m:15s]Jobs: 21 (f=21): [_(1),V(2),_(34),V(1),_(4),V(2),_(4),V(16)][1.7%][r=385MiB/s,w=0KiB/s][r=98.6k,w=0 IOPS][eta 01h:16m:05s]                                                                    Jobs: 13 (f=13): [_(1),V(1),_(46),V(1),_(1),V(11),_(3)][1.9%][r=241MiB/s,w=0KiB/s][r=61.7k,w=0 IOPS][eta 01h:12m:27s]     Jobs: 9 (f=9): [_(1),V(1),_(48),V(2),_(1),V(6),_(5)][1.9%][r=152MiB/s,w=0KiB/s][r=38.1k,w=0 IOPS][eta 01h:09m:45s] Jobs: 6 (f=6): [_(1),V(1),_(51),V(5),_(6)][2.0%][r=98.3MiB/s,w=0KiB/s][r=25.2k,w=0 IOPS][eta 01h:08m:17s]         Jobs: 6 (f=6): [_(1),V(1),_(51),V(5),_(6)][2.0%][r=88.4MiB/s,w=0KiB/s][r=22.6k,w=0 IOPS][eta 01h:08m:12s]Jobs: 5 (f=5): [_(53),V(5),_(6)][2.1%][r=72.7MiB/s,w=0KiB/s][r=18.7k,w=0 IOPS][eta 01h:08m:07s]          Jobs: 4 (f=4): [_(53),V(1),_(1),V(3),_(6)][2.1%][r=57.4MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 01h:08m:07s]Jobs: 2 (f=2): [_(55),V(1),_(1),V(1),_(6)][2.1%][r=34.8MiB/s,w=0KiB/s][r=8900,w=0 IOPS][eta 01h:08m:06s] Jobs: 2 (f=2): [_(55),V(1),_(1),V(1),_(6)][2.1%][r=25.9MiB/s,w=0KiB/s][r=6606,w=0 IOPS][eta 01h:08m:07s]Jobs: 1 (f=1): [_(57),V(1),_(6)][2.2%][r=13.6MiB/s,w=0KiB/s][r=3461,w=0 IOPS][eta 01h:08m:09s]          Jobs: 1 (f=1): [_(57),V(1),_(6)][2.2%][r=10.4MiB/s,w=0KiB/s][r=2650,w=0 IOPS][eta 01h:08m:21s]
job1: (groupid=0, jobs=64): err= 0: pid=30120: Thu Sep 27 07:48:02 2018
   read: IOPS=207k, BW=807MiB/s (847MB/s)(66.1GiB/84929msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=6.86%, sys=2.98%, ctx=17581848, majf=0, minf=108255
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=17553962,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=807MiB/s (847MB/s), 807MiB/s-807MiB/s (847MB/s-847MB/s), io=66.1GiB (71.1GB), run=84929-84929msec

Disk stats (read/write):
  nvme1n1: ios=268497/0, merge=0/0, ticks=66968/0, in_queue=66932, util=84.88%
  nvme2n1: ios=291212/0, merge=0/0, ticks=71895/0, in_queue=71862, util=85.36%
  nvme3n1: ios=276652/0, merge=0/0, ticks=68796/0, in_queue=68758, util=85.40%
  nvme4n1: ios=269817/0, merge=0/0, ticks=67094/0, in_queue=67047, util=85.29%
  nvme5n1: ios=270305/0, merge=0/0, ticks=67536/0, in_queue=67507, util=85.81%
  nvme6n1: ios=267750/0, merge=0/0, ticks=66886/0, in_queue=66851, util=86.01%
  nvme7n1: ios=268054/0, merge=0/0, ticks=66996/0, in_queue=66948, util=86.01%
  nvme8n1: ios=268221/0, merge=0/0, ticks=66771/0, in_queue=66735, util=86.16%
  nvme9n1: ios=266304/0, merge=0/0, ticks=66794/0, in_queue=66769, util=86.64%
  nvme10n1: ios=268939/0, merge=0/0, ticks=67000/0, in_queue=66946, util=86.34%
  nvme11n1: ios=264585/0, merge=0/0, ticks=66030/0, in_queue=65991, util=86.23%
  nvme12n1: ios=271221/0, merge=0/0, ticks=67498/0, in_queue=67440, util=86.45%
  nvme13n1: ios=266514/0, merge=0/0, ticks=66730/0, in_queue=66693, util=86.60%
  nvme14n1: ios=265291/0, merge=0/0, ticks=66041/0, in_queue=65990, util=86.27%
  nvme15n1: ios=263758/0, merge=0/0, ticks=66097/0, in_queue=66062, util=86.68%
  nvme16n1: ios=266076/0, merge=0/0, ticks=66376/0, in_queue=66337, util=86.49%
  nvme17n1: ios=266950/0, merge=0/0, ticks=66630/0, in_queue=66545, util=86.22%
  nvme18n1: ios=269098/0, merge=0/0, ticks=67169/0, in_queue=67135, util=86.74%
  nvme19n1: ios=269620/0, merge=0/0, ticks=67471/0, in_queue=67427, util=86.86%
  nvme20n1: ios=266162/0, merge=0/0, ticks=66471/0, in_queue=66438, util=86.74%
  nvme21n1: ios=270452/0, merge=0/0, ticks=67660/0, in_queue=67624, util=86.91%
  nvme22n1: ios=271172/0, merge=0/0, ticks=67612/0, in_queue=67567, util=86.87%
  nvme23n1: ios=273235/0, merge=0/0, ticks=67822/0, in_queue=67781, util=86.63%
  nvme24n1: ios=268266/0, merge=0/0, ticks=66833/0, in_queue=66798, util=86.78%
  nvme25n1: ios=266779/0, merge=0/0, ticks=66346/0, in_queue=66309, util=86.49%
  nvme26n1: ios=270969/0, merge=0/0, ticks=67586/0, in_queue=67544, util=87.00%
  nvme27n1: ios=269476/0, merge=0/0, ticks=67219/0, in_queue=67165, util=86.85%
  nvme28n1: ios=269315/0, merge=0/0, ticks=67040/0, in_queue=67004, util=86.96%
  nvme29n1: ios=269715/0, merge=0/0, ticks=67200/0, in_queue=67160, util=86.94%
  nvme30n1: ios=266147/0, merge=0/0, ticks=66627/0, in_queue=66599, util=87.39%
  nvme31n1: ios=272827/0, merge=0/0, ticks=67813/0, in_queue=67769, util=86.98%
  nvme32n1: ios=268335/0, merge=0/0, ticks=66782/0, in_queue=66737, util=87.12%
  nvme33n1: ios=263681/0, merge=0/0, ticks=65804/0, in_queue=65773, util=87.07%
  nvme34n1: ios=269328/0, merge=0/0, ticks=66987/0, in_queue=66946, util=87.24%
  nvme35n1: ios=268930/0, merge=0/0, ticks=67059/0, in_queue=67024, util=87.42%
  nvme36n1: ios=272532/0, merge=0/0, ticks=67592/0, in_queue=67557, util=87.32%
  nvme37n1: ios=266697/0, merge=0/0, ticks=66597/0, in_queue=66559, util=87.51%
  nvme38n1: ios=275229/0, merge=0/0, ticks=68236/0, in_queue=68190, util=87.45%
  nvme39n1: ios=265804/0, merge=0/0, ticks=66262/0, in_queue=66215, util=87.50%
  nvme40n1: ios=268956/0, merge=0/0, ticks=67298/0, in_queue=67255, util=88.09%
  nvme41n1: ios=271183/0, merge=0/0, ticks=67450/0, in_queue=67422, util=87.80%
  nvme42n1: ios=269125/0, merge=0/0, ticks=67011/0, in_queue=66957, util=87.86%
  nvme43n1: ios=273822/0, merge=0/0, ticks=68107/0, in_queue=68053, util=87.98%
  nvme44n1: ios=273146/0, merge=0/0, ticks=67972/0, in_queue=67934, util=88.17%
  nvme45n1: ios=271082/0, merge=0/0, ticks=67471/0, in_queue=67434, util=88.19%
  nvme46n1: ios=271196/0, merge=0/0, ticks=67679/0, in_queue=67637, util=88.56%
  nvme47n1: ios=269002/0, merge=0/0, ticks=67025/0, in_queue=66997, util=88.39%
  nvme48n1: ios=273608/0, merge=0/0, ticks=67822/0, in_queue=67779, util=88.40%
  nvme49n1: ios=280399/0, merge=0/0, ticks=69424/0, in_queue=69373, util=88.63%
  nvme50n1: ios=274373/0, merge=0/0, ticks=68246/0, in_queue=68208, util=88.99%
  nvme51n1: ios=281301/0, merge=0/0, ticks=69669/0, in_queue=69631, util=88.95%
  nvme52n1: ios=284112/0, merge=0/0, ticks=70083/0, in_queue=70039, util=89.04%
  nvme53n1: ios=280229/0, merge=0/0, ticks=69400/0, in_queue=69362, util=89.18%
  nvme54n1: ios=299802/0, merge=0/0, ticks=74085/0, in_queue=74049, util=89.59%
  nvme55n1: ios=293156/0, merge=0/0, ticks=72150/0, in_queue=72096, util=88.98%
  nvme56n1: ios=304450/0, merge=0/0, ticks=74737/0, in_queue=74691, util=89.00%
  nvme57n1: ios=298210/0, merge=0/0, ticks=73668/0, in_queue=73621, util=89.72%
  nvme58n1: ios=312252/0, merge=0/0, ticks=77212/0, in_queue=77164, util=90.05%
  nvme59n1: ios=283173/0, merge=0/0, ticks=70269/0, in_queue=70222, util=90.22%
  nvme60n1: ios=280035/0, merge=0/0, ticks=69178/0, in_queue=69133, util=90.11%
  nvme61n1: ios=278138/0, merge=0/0, ticks=69127/0, in_queue=69087, util=90.50%
  nvme62n1: ios=276475/0, merge=0/0, ticks=68768/0, in_queue=68721, util=90.76%
  nvme63n1: ios=276355/0, merge=0/0, ticks=68584/0, in_queue=68546, util=90.68%
  nvme64n1: ios=275787/0, merge=0/0, ticks=68512/0, in_queue=68482, util=90.74%


    DEBUG: 2018/09/27 07:48:02 Create XFS, EXT4 FS and Mount 64 remote volumes
    DEBUG: 2018/09/27 07:48:48 Umount remote volumes and delete mount directories
    DEBUG: 2018/09/27 07:48:49 Detach all 64 remote volumes
    DEBUG: 2018/09/27 07:49:07 Delete all 64 volumes
[AfterEach] Remote Storage volume basic test for weekly
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1069
    DEBUG: 2018/09/27 07:56:57 END_TEST RemoteStorage.Basic Time-taken : 1354.307244299

[32m• [SLOW TEST:1354.307 seconds][0m
RemoteStorage.Basic Weekly RS_Basic-1.1 RS_Basic-1.2 RS_Basic-1.3 RS_Basic-1.5 RS_Verify-1.0 RS_Stress-1.1
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1051[0m
  Remote Storage volume basic test for weekly
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1053[0m
    remote storage volume basic operations
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1074[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.ConfigStress Daily RS_Stress-1.0[0m [90mCreate - Attach - Detach - Delete remote volumes in loop.[0m 
  [1mCreate - Attach - Detach - Delete remote volumes in loop.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4396[0m
[BeforeEach] Create - Attach - Detach - Delete remote volumes in loop.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4381
    DEBUG: 2018/09/27 07:56:57 START_TEST RemoteStorage.ConfigStress
    DEBUG: 2018/09/27 07:56:57 Login to cluster
    DEBUG: 2018/09/27 07:56:57 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 07:56:57 Checking basic Vnic usage
    DEBUG: 2018/09/27 07:56:57 Updating inventory struct
[It] Create - Attach - Detach - Delete remote volumes in loop.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4396
    DEBUG: 2018/09/27 07:57:04 /****************************** Started Iteration: 1 ***********************/
    DEBUG: 2018/09/27 07:57:04 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 07:57:04 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 07:57:04 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 07:57:04 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 07:57:41 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 08:00:13 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 08:02:45 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 08:05:20 Detach volumes:
    DEBUG: 2018/09/27 08:05:20 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 08:05:20 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 08:05:20 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 08:05:30 Delete volumes: 
    DEBUG: 2018/09/27 08:06:34 /****************************** Started Iteration: 2 ***********************/
    DEBUG: 2018/09/27 08:06:35 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 08:06:35 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 08:06:35 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 08:06:35 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 08:07:12 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 08:09:50 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 08:12:21 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 08:15:00 Detach volumes:
    DEBUG: 2018/09/27 08:15:00 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 08:15:00 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 08:15:00 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 08:15:24 Delete volumes: 
    DEBUG: 2018/09/27 08:16:07 /****************************** Started Iteration: 3 ***********************/
    DEBUG: 2018/09/27 08:16:07 Create 32 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 08:16:07 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 08:16:07 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 08:16:07 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 08:16:44 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 08:19:19 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 08:21:53 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 08:24:28 Detach volumes:
    DEBUG: 2018/09/27 08:24:28 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 08:24:28 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 08:24:28 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 08:24:53 Delete volumes: 
[AfterEach] Create - Attach - Detach - Delete remote volumes in loop.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4391
    DEBUG: 2018/09/27 08:25:39 END_TEST RemoteStorage.ConfigStress Time-taken : 1722.675917608

[32m• [SLOW TEST:1722.676 seconds][0m
RemoteStorage.ConfigStress Daily RS_Stress-1.0
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4374[0m
  Create - Attach - Detach - Delete remote volumes in loop.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4375[0m
    Create - Attach - Detach - Delete remote volumes in loop.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4396[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.StressExhaustRemoteStorageCtrlsAndStorageCtrls Weekly RS_Stress-1.4 RS_Stress-1.5[0m [90mExhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.[0m 
  [1mExhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4147[0m
[BeforeEach] Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4132
    DEBUG: 2018/09/27 08:25:39 START_TEST RemoteStorage.StressExhaustRemoteStorageCtrlsAndStorageCtrls
    DEBUG: 2018/09/27 08:25:39 Login to cluster
    DEBUG: 2018/09/27 08:25:39 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 08:25:40 Checking basic Vnic usage
    DEBUG: 2018/09/27 08:25:40 Updating inventory struct
[It] Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4147
    DEBUG: 2018/09/27 08:25:46 Create 64 single plex volumes per cluster node: 
    DEBUG: 2018/09/27 08:25:47 Creating volumes on the node : bosserv5
    DEBUG: 2018/09/27 08:25:47 Creating volumes on the node : bosserv4
    DEBUG: 2018/09/27 08:25:47 Creating volumes on the node : bosserv6
    DEBUG: 2018/09/27 08:27:00 Attaching volumes of node bosserv5 on node bosserv4:
    DEBUG: 2018/09/27 08:29:35 Attaching volumes of node bosserv6 on node bosserv5:
    DEBUG: 2018/09/27 08:32:08 Attaching volumes of node bosserv4 on node bosserv6:
    DEBUG: 2018/09/27 08:34:43 Attach remaining volumes locally: 
    DEBUG: 2018/09/27 08:40:52 Ensure all storage controllers & remote controllers are consumed: 
    DEBUG: 2018/09/27 08:40:52 Do write IOs on volumes attached to each cluster node: 
    DEBUG: 2018/09/27 08:40:53 Running Write IOs on node : bosserv5 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=300 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme33n1 --name=dev2 --filename=/dev/nvme34n1 --name=dev3 --filename=/dev/nvme35n1 --name=dev4 --filename=/dev/nvme36n1 --name=dev5 --filename=/dev/nvme37n1 --name=dev6 --filename=/dev/nvme38n1 --name=dev7 --filename=/dev/nvme39n1 --name=dev8 --filename=/dev/nvme40n1 --name=dev9 --filename=/dev/nvme41n1 --name=dev10 --filename=/dev/nvme42n1 --name=dev11 --filename=/dev/nvme43n1 --name=dev12 --filename=/dev/nvme44n1 --name=dev13 --filename=/dev/nvme45n1 --name=dev14 --filename=/dev/nvme46n1 --name=dev15 --filename=/dev/nvme47n1 --name=dev16 --filename=/dev/nvme48n1 --name=dev17 --filename=/dev/nvme49n1 --name=dev18 --filename=/dev/nvme50n1 --name=dev19 --filename=/dev/nvme51n1 --name=dev20 --filename=/dev/nvme52n1 --name=dev21 --filename=/dev/nvme53n1 --name=dev22 --filename=/dev/nvme54n1 --name=dev23 --filename=/dev/nvme55n1 --name=dev24 --filename=/dev/nvme56n1 --name=dev25 --filename=/dev/nvme57n1 --name=dev26 --filename=/dev/nvme58n1 --name=dev27 --filename=/dev/nvme59n1 --name=dev28 --filename=/dev/nvme60n1 --name=dev29 --filename=/dev/nvme61n1 --name=dev30 --filename=/dev/nvme62n1 --name=dev31 --filename=/dev/nvme63n1 --name=dev32 --filename=/dev/nvme64n1 --name=dev33 --filename=/dev/nvme1n1 --name=dev34 --filename=/dev/nvme10n1 --name=dev35 --filename=/dev/nvme11n1 --name=dev36 --filename=/dev/nvme12n1 --name=dev37 --filename=/dev/nvme13n1 --name=dev38 --filename=/dev/nvme14n1 --name=dev39 --filename=/dev/nvme15n1 --name=dev40 --filename=/dev/nvme16n1 --name=dev41 --filename=/dev/nvme17n1 --name=dev42 --filename=/dev/nvme18n1 --name=dev43 --filename=/dev/nvme19n1 --name=dev44 --filename=/dev/nvme2n1 --name=dev45 --filename=/dev/nvme20n1 --name=dev46 --filename=/dev/nvme21n1 --name=dev47 --filename=/dev/nvme22n1 --name=dev48 --filename=/dev/nvme23n1 --name=dev49 --filename=/dev/nvme24n1 --name=dev50 --filename=/dev/nvme25n1 --name=dev51 --filename=/dev/nvme26n1 --name=dev52 --filename=/dev/nvme27n1 --name=dev53 --filename=/dev/nvme28n1 --name=dev54 --filename=/dev/nvme29n1 --name=dev55 --filename=/dev/nvme3n1 --name=dev56 --filename=/dev/nvme30n1 --name=dev57 --filename=/dev/nvme31n1 --name=dev58 --filename=/dev/nvme32n1 --name=dev59 --filename=/dev/nvme4n1 --name=dev60 --filename=/dev/nvme5n1 --name=dev61 --filename=/dev/nvme6n1 --name=dev62 --filename=/dev/nvme7n1 --name=dev63 --filename=/dev/nvme8n1 --name=dev64 --filename=/dev/nvme9n1
    DEBUG: 2018/09/27 08:40:53 Running Write IOs on node : bosserv4 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=300 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme33n1 --name=dev2 --filename=/dev/nvme34n1 --name=dev3 --filename=/dev/nvme35n1 --name=dev4 --filename=/dev/nvme36n1 --name=dev5 --filename=/dev/nvme37n1 --name=dev6 --filename=/dev/nvme38n1 --name=dev7 --filename=/dev/nvme39n1 --name=dev8 --filename=/dev/nvme40n1 --name=dev9 --filename=/dev/nvme41n1 --name=dev10 --filename=/dev/nvme42n1 --name=dev11 --filename=/dev/nvme43n1 --name=dev12 --filename=/dev/nvme44n1 --name=dev13 --filename=/dev/nvme45n1 --name=dev14 --filename=/dev/nvme46n1 --name=dev15 --filename=/dev/nvme47n1 --name=dev16 --filename=/dev/nvme48n1 --name=dev17 --filename=/dev/nvme49n1 --name=dev18 --filename=/dev/nvme50n1 --name=dev19 --filename=/dev/nvme51n1 --name=dev20 --filename=/dev/nvme52n1 --name=dev21 --filename=/dev/nvme53n1 --name=dev22 --filename=/dev/nvme54n1 --name=dev23 --filename=/dev/nvme55n1 --name=dev24 --filename=/dev/nvme56n1 --name=dev25 --filename=/dev/nvme57n1 --name=dev26 --filename=/dev/nvme58n1 --name=dev27 --filename=/dev/nvme59n1 --name=dev28 --filename=/dev/nvme60n1 --name=dev29 --filename=/dev/nvme61n1 --name=dev30 --filename=/dev/nvme62n1 --name=dev31 --filename=/dev/nvme63n1 --name=dev32 --filename=/dev/nvme64n1 --name=dev33 --filename=/dev/nvme1n1 --name=dev34 --filename=/dev/nvme10n1 --name=dev35 --filename=/dev/nvme11n1 --name=dev36 --filename=/dev/nvme12n1 --name=dev37 --filename=/dev/nvme13n1 --name=dev38 --filename=/dev/nvme14n1 --name=dev39 --filename=/dev/nvme15n1 --name=dev40 --filename=/dev/nvme16n1 --name=dev41 --filename=/dev/nvme17n1 --name=dev42 --filename=/dev/nvme18n1 --name=dev43 --filename=/dev/nvme19n1 --name=dev44 --filename=/dev/nvme2n1 --name=dev45 --filename=/dev/nvme20n1 --name=dev46 --filename=/dev/nvme21n1 --name=dev47 --filename=/dev/nvme22n1 --name=dev48 --filename=/dev/nvme23n1 --name=dev49 --filename=/dev/nvme24n1 --name=dev50 --filename=/dev/nvme25n1 --name=dev51 --filename=/dev/nvme26n1 --name=dev52 --filename=/dev/nvme27n1 --name=dev53 --filename=/dev/nvme28n1 --name=dev54 --filename=/dev/nvme29n1 --name=dev55 --filename=/dev/nvme3n1 --name=dev56 --filename=/dev/nvme30n1 --name=dev57 --filename=/dev/nvme31n1 --name=dev58 --filename=/dev/nvme32n1 --name=dev59 --filename=/dev/nvme4n1 --name=dev60 --filename=/dev/nvme5n1 --name=dev61 --filename=/dev/nvme6n1 --name=dev62 --filename=/dev/nvme7n1 --name=dev63 --filename=/dev/nvme8n1 --name=dev64 --filename=/dev/nvme9n1
    DEBUG: 2018/09/27 08:40:53 Running Write IOs on node : bosserv6 
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randwrite --numjobs=1 --do_verify=0 --verify_state_save=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --runtime=300 --blocksize=4K --direct=1 --time_based  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme10n1 --name=dev3 --filename=/dev/nvme11n1 --name=dev4 --filename=/dev/nvme12n1 --name=dev5 --filename=/dev/nvme13n1 --name=dev6 --filename=/dev/nvme14n1 --name=dev7 --filename=/dev/nvme15n1 --name=dev8 --filename=/dev/nvme16n1 --name=dev9 --filename=/dev/nvme17n1 --name=dev10 --filename=/dev/nvme18n1 --name=dev11 --filename=/dev/nvme19n1 --name=dev12 --filename=/dev/nvme2n1 --name=dev13 --filename=/dev/nvme20n1 --name=dev14 --filename=/dev/nvme21n1 --name=dev15 --filename=/dev/nvme22n1 --name=dev16 --filename=/dev/nvme23n1 --name=dev17 --filename=/dev/nvme24n1 --name=dev18 --filename=/dev/nvme25n1 --name=dev19 --filename=/dev/nvme26n1 --name=dev20 --filename=/dev/nvme27n1 --name=dev21 --filename=/dev/nvme28n1 --name=dev22 --filename=/dev/nvme29n1 --name=dev23 --filename=/dev/nvme3n1 --name=dev24 --filename=/dev/nvme30n1 --name=dev25 --filename=/dev/nvme31n1 --name=dev26 --filename=/dev/nvme32n1 --name=dev27 --filename=/dev/nvme4n1 --name=dev28 --filename=/dev/nvme5n1 --name=dev29 --filename=/dev/nvme6n1 --name=dev30 --filename=/dev/nvme7n1 --name=dev31 --filename=/dev/nvme8n1 --name=dev32 --filename=/dev/nvme9n1 --name=dev33 --filename=/dev/nvme33n1 --name=dev34 --filename=/dev/nvme34n1 --name=dev35 --filename=/dev/nvme35n1 --name=dev36 --filename=/dev/nvme36n1 --name=dev37 --filename=/dev/nvme37n1 --name=dev38 --filename=/dev/nvme38n1 --name=dev39 --filename=/dev/nvme39n1 --name=dev40 --filename=/dev/nvme40n1 --name=dev41 --filename=/dev/nvme41n1 --name=dev42 --filename=/dev/nvme42n1 --name=dev43 --filename=/dev/nvme43n1 --name=dev44 --filename=/dev/nvme44n1 --name=dev45 --filename=/dev/nvme45n1 --name=dev46 --filename=/dev/nvme46n1 --name=dev47 --filename=/dev/nvme47n1 --name=dev48 --filename=/dev/nvme48n1 --name=dev49 --filename=/dev/nvme49n1 --name=dev50 --filename=/dev/nvme50n1 --name=dev51 --filename=/dev/nvme51n1 --name=dev52 --filename=/dev/nvme52n1 --name=dev53 --filename=/dev/nvme53n1 --name=dev54 --filename=/dev/nvme54n1 --name=dev55 --filename=/dev/nvme55n1 --name=dev56 --filename=/dev/nvme56n1 --name=dev57 --filename=/dev/nvme57n1 --name=dev58 --filename=/dev/nvme58n1 --name=dev59 --filename=/dev/nvme59n1 --name=dev60 --filename=/dev/nvme60n1 --name=dev61 --filename=/dev/nvme61n1 --name=dev62 --filename=/dev/nvme62n1 --name=dev63 --filename=/dev/nvme63n1 --name=dev64 --filename=/dev/nvme64n1
    DEBUG: 2018/09/27 08:46:00 Read pattern written on volumes: 
    DEBUG: 2018/09/27 08:46:00 Running Verify IOs on node : bosserv6 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme1n1 --name=dev2 --filename=/dev/nvme10n1 --name=dev3 --filename=/dev/nvme11n1 --name=dev4 --filename=/dev/nvme12n1 --name=dev5 --filename=/dev/nvme13n1 --name=dev6 --filename=/dev/nvme14n1 --name=dev7 --filename=/dev/nvme15n1 --name=dev8 --filename=/dev/nvme16n1 --name=dev9 --filename=/dev/nvme17n1 --name=dev10 --filename=/dev/nvme18n1 --name=dev11 --filename=/dev/nvme19n1 --name=dev12 --filename=/dev/nvme2n1 --name=dev13 --filename=/dev/nvme20n1 --name=dev14 --filename=/dev/nvme21n1 --name=dev15 --filename=/dev/nvme22n1 --name=dev16 --filename=/dev/nvme23n1 --name=dev17 --filename=/dev/nvme24n1 --name=dev18 --filename=/dev/nvme25n1 --name=dev19 --filename=/dev/nvme26n1 --name=dev20 --filename=/dev/nvme27n1 --name=dev21 --filename=/dev/nvme28n1 --name=dev22 --filename=/dev/nvme29n1 --name=dev23 --filename=/dev/nvme3n1 --name=dev24 --filename=/dev/nvme30n1 --name=dev25 --filename=/dev/nvme31n1 --name=dev26 --filename=/dev/nvme32n1 --name=dev27 --filename=/dev/nvme4n1 --name=dev28 --filename=/dev/nvme5n1 --name=dev29 --filename=/dev/nvme6n1 --name=dev30 --filename=/dev/nvme7n1 --name=dev31 --filename=/dev/nvme8n1 --name=dev32 --filename=/dev/nvme9n1 --name=dev33 --filename=/dev/nvme33n1 --name=dev34 --filename=/dev/nvme34n1 --name=dev35 --filename=/dev/nvme35n1 --name=dev36 --filename=/dev/nvme36n1 --name=dev37 --filename=/dev/nvme37n1 --name=dev38 --filename=/dev/nvme38n1 --name=dev39 --filename=/dev/nvme39n1 --name=dev40 --filename=/dev/nvme40n1 --name=dev41 --filename=/dev/nvme41n1 --name=dev42 --filename=/dev/nvme42n1 --name=dev43 --filename=/dev/nvme43n1 --name=dev44 --filename=/dev/nvme44n1 --name=dev45 --filename=/dev/nvme45n1 --name=dev46 --filename=/dev/nvme46n1 --name=dev47 --filename=/dev/nvme47n1 --name=dev48 --filename=/dev/nvme48n1 --name=dev49 --filename=/dev/nvme49n1 --name=dev50 --filename=/dev/nvme50n1 --name=dev51 --filename=/dev/nvme51n1 --name=dev52 --filename=/dev/nvme52n1 --name=dev53 --filename=/dev/nvme53n1 --name=dev54 --filename=/dev/nvme54n1 --name=dev55 --filename=/dev/nvme55n1 --name=dev56 --filename=/dev/nvme56n1 --name=dev57 --filename=/dev/nvme57n1 --name=dev58 --filename=/dev/nvme58n1 --name=dev59 --filename=/dev/nvme59n1 --name=dev60 --filename=/dev/nvme60n1 --name=dev61 --filename=/dev/nvme61n1 --name=dev62 --filename=/dev/nvme62n1 --name=dev63 --filename=/dev/nvme63n1 --name=dev64 --filename=/dev/nvme64n1
    DEBUG: 2018/09/27 08:46:00 Running Verify IOs on node : bosserv4 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme33n1 --name=dev2 --filename=/dev/nvme34n1 --name=dev3 --filename=/dev/nvme35n1 --name=dev4 --filename=/dev/nvme36n1 --name=dev5 --filename=/dev/nvme37n1 --name=dev6 --filename=/dev/nvme38n1 --name=dev7 --filename=/dev/nvme39n1 --name=dev8 --filename=/dev/nvme40n1 --name=dev9 --filename=/dev/nvme41n1 --name=dev10 --filename=/dev/nvme42n1 --name=dev11 --filename=/dev/nvme43n1 --name=dev12 --filename=/dev/nvme44n1 --name=dev13 --filename=/dev/nvme45n1 --name=dev14 --filename=/dev/nvme46n1 --name=dev15 --filename=/dev/nvme47n1 --name=dev16 --filename=/dev/nvme48n1 --name=dev17 --filename=/dev/nvme49n1 --name=dev18 --filename=/dev/nvme50n1 --name=dev19 --filename=/dev/nvme51n1 --name=dev20 --filename=/dev/nvme52n1 --name=dev21 --filename=/dev/nvme53n1 --name=dev22 --filename=/dev/nvme54n1 --name=dev23 --filename=/dev/nvme55n1 --name=dev24 --filename=/dev/nvme56n1 --name=dev25 --filename=/dev/nvme57n1 --name=dev26 --filename=/dev/nvme58n1 --name=dev27 --filename=/dev/nvme59n1 --name=dev28 --filename=/dev/nvme60n1 --name=dev29 --filename=/dev/nvme61n1 --name=dev30 --filename=/dev/nvme62n1 --name=dev31 --filename=/dev/nvme63n1 --name=dev32 --filename=/dev/nvme64n1 --name=dev33 --filename=/dev/nvme1n1 --name=dev34 --filename=/dev/nvme10n1 --name=dev35 --filename=/dev/nvme11n1 --name=dev36 --filename=/dev/nvme12n1 --name=dev37 --filename=/dev/nvme13n1 --name=dev38 --filename=/dev/nvme14n1 --name=dev39 --filename=/dev/nvme15n1 --name=dev40 --filename=/dev/nvme16n1 --name=dev41 --filename=/dev/nvme17n1 --name=dev42 --filename=/dev/nvme18n1 --name=dev43 --filename=/dev/nvme19n1 --name=dev44 --filename=/dev/nvme2n1 --name=dev45 --filename=/dev/nvme20n1 --name=dev46 --filename=/dev/nvme21n1 --name=dev47 --filename=/dev/nvme22n1 --name=dev48 --filename=/dev/nvme23n1 --name=dev49 --filename=/dev/nvme24n1 --name=dev50 --filename=/dev/nvme25n1 --name=dev51 --filename=/dev/nvme26n1 --name=dev52 --filename=/dev/nvme27n1 --name=dev53 --filename=/dev/nvme28n1 --name=dev54 --filename=/dev/nvme29n1 --name=dev55 --filename=/dev/nvme3n1 --name=dev56 --filename=/dev/nvme30n1 --name=dev57 --filename=/dev/nvme31n1 --name=dev58 --filename=/dev/nvme32n1 --name=dev59 --filename=/dev/nvme4n1 --name=dev60 --filename=/dev/nvme5n1 --name=dev61 --filename=/dev/nvme6n1 --name=dev62 --filename=/dev/nvme7n1 --name=dev63 --filename=/dev/nvme8n1 --name=dev64 --filename=/dev/nvme9n1
    DEBUG: 2018/09/27 08:46:00 Running Verify IOs on node : bosserv5 and plex p0
Command : sudo /usr/local/bin/fio --ioengine=libaio --direct=1 --group_reporting --gtod_reduce=1 --clat_percentiles=0 --rw=randread --numjobs=1 --do_verify=1 --verify_state_load=1 --verify=pattern --verify_pattern=0xff%o\"abcd\"-21 --verify_interval=4096 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=dev1 --filename=/dev/nvme33n1 --name=dev2 --filename=/dev/nvme34n1 --name=dev3 --filename=/dev/nvme35n1 --name=dev4 --filename=/dev/nvme36n1 --name=dev5 --filename=/dev/nvme37n1 --name=dev6 --filename=/dev/nvme38n1 --name=dev7 --filename=/dev/nvme39n1 --name=dev8 --filename=/dev/nvme40n1 --name=dev9 --filename=/dev/nvme41n1 --name=dev10 --filename=/dev/nvme42n1 --name=dev11 --filename=/dev/nvme43n1 --name=dev12 --filename=/dev/nvme44n1 --name=dev13 --filename=/dev/nvme45n1 --name=dev14 --filename=/dev/nvme46n1 --name=dev15 --filename=/dev/nvme47n1 --name=dev16 --filename=/dev/nvme48n1 --name=dev17 --filename=/dev/nvme49n1 --name=dev18 --filename=/dev/nvme50n1 --name=dev19 --filename=/dev/nvme51n1 --name=dev20 --filename=/dev/nvme52n1 --name=dev21 --filename=/dev/nvme53n1 --name=dev22 --filename=/dev/nvme54n1 --name=dev23 --filename=/dev/nvme55n1 --name=dev24 --filename=/dev/nvme56n1 --name=dev25 --filename=/dev/nvme57n1 --name=dev26 --filename=/dev/nvme58n1 --name=dev27 --filename=/dev/nvme59n1 --name=dev28 --filename=/dev/nvme60n1 --name=dev29 --filename=/dev/nvme61n1 --name=dev30 --filename=/dev/nvme62n1 --name=dev31 --filename=/dev/nvme63n1 --name=dev32 --filename=/dev/nvme64n1 --name=dev33 --filename=/dev/nvme1n1 --name=dev34 --filename=/dev/nvme10n1 --name=dev35 --filename=/dev/nvme11n1 --name=dev36 --filename=/dev/nvme12n1 --name=dev37 --filename=/dev/nvme13n1 --name=dev38 --filename=/dev/nvme14n1 --name=dev39 --filename=/dev/nvme15n1 --name=dev40 --filename=/dev/nvme16n1 --name=dev41 --filename=/dev/nvme17n1 --name=dev42 --filename=/dev/nvme18n1 --name=dev43 --filename=/dev/nvme19n1 --name=dev44 --filename=/dev/nvme2n1 --name=dev45 --filename=/dev/nvme20n1 --name=dev46 --filename=/dev/nvme21n1 --name=dev47 --filename=/dev/nvme22n1 --name=dev48 --filename=/dev/nvme23n1 --name=dev49 --filename=/dev/nvme24n1 --name=dev50 --filename=/dev/nvme25n1 --name=dev51 --filename=/dev/nvme26n1 --name=dev52 --filename=/dev/nvme27n1 --name=dev53 --filename=/dev/nvme28n1 --name=dev54 --filename=/dev/nvme29n1 --name=dev55 --filename=/dev/nvme3n1 --name=dev56 --filename=/dev/nvme30n1 --name=dev57 --filename=/dev/nvme31n1 --name=dev58 --filename=/dev/nvme32n1 --name=dev59 --filename=/dev/nvme4n1 --name=dev60 --filename=/dev/nvme5n1 --name=dev61 --filename=/dev/nvme6n1 --name=dev62 --filename=/dev/nvme7n1 --name=dev63 --filename=/dev/nvme8n1 --name=dev64 --filename=/dev/nvme9n1
    DEBUG: 2018/09/27 08:50:06 Detach volumes:
    DEBUG: 2018/09/27 08:50:06 Detaching volumes on the node : bosserv6
    DEBUG: 2018/09/27 08:50:06 Detaching volumes on the node : bosserv4
    DEBUG: 2018/09/27 08:50:06 Detaching volumes on the node : bosserv5
    DEBUG: 2018/09/27 08:50:25 Delete volumes: 
[AfterEach] Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4142
    DEBUG: 2018/09/27 09:01:58 END_TEST RemoteStorage.StressExhaustRemoteStorageCtrlsAndStorageCtrls Time-taken : 2178.699263046

[32m• [SLOW TEST:2178.699 seconds][0m
RemoteStorage.StressExhaustRemoteStorageCtrlsAndStorageCtrls Weekly RS_Stress-1.4 RS_Stress-1.5
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4119[0m
  Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4121[0m
    Exhaust all remote storage controllers and storage controlers, Do write IOs, Verify Data.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:4147[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mNetworkRemoteStorage.NicVFsScheduling Daily AT_Scheduling-1.2 Qos[0m [90mNetwork plus remote storage nic & VFs scheduling[0m 
  [1mNetwork plus remote storage nic & VFs scheduling[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1754[0m
[BeforeEach] Network plus remote storage nic & VFs scheduling
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1739
    DEBUG: 2018/09/27 09:01:58 START_TEST NetworkRemoteStorage.NicVFsScheduling
    DEBUG: 2018/09/27 09:01:58 Login to cluster
    DEBUG: 2018/09/27 09:01:58 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:01:59 Checking basic Vnic usage
    DEBUG: 2018/09/27 09:01:59 Updating inventory struct
[It] Network plus remote storage nic & VFs scheduling
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1754
    DEBUG: 2018/09/27 09:02:05 Creating 2 pair of iperf client-server pod
    DEBUG: 2018/09/27 09:02:05 Creating iperf server pod: iperf-serverhigh1
    DEBUG: 2018/09/27 09:02:11 Creating service with name: iperf-serverhigh1
    DEBUG: 2018/09/27 09:02:11 Creating iperf server pod: iperf-serverhigh2
    DEBUG: 2018/09/27 09:02:15 Creating service with name: iperf-serverhigh2
    DEBUG: 2018/09/27 09:02:45 Creating iperf Client pod: iperf-clienthigh1
    DEBUG: 2018/09/27 09:02:49 Creating iperf Client pod: iperf-clienthigh2
    DEBUG: 2018/09/27 09:02:53 Getting pods scheduled on network nicIds
    DEBUG: 2018/09/27 09:02:53 Checking distribution of network pods across nicId(s)
    DEBUG: 2018/09/27 09:02:53 Pod scheduled as expected
    DEBUG: 2018/09/27 09:02:53 Creating fio pod and remote volume with high qos: 
    DEBUG: 2018/09/27 09:02:53 Create 2 remote volumes: 
    DEBUG: 2018/09/27 09:02:55 Create 2 fio pod(s):
    DEBUG: 2018/09/27 09:02:55 Creating fio pod: fio-pod-high-1
    DEBUG: 2018/09/27 09:02:55 Creating fio pod: fio-pod-high-2
    DEBUG: 2018/09/27 09:02:55 Checking if given pods are in Running state
    DEBUG: 2018/09/27 09:03:04 Getting pods and volumes scheduled on storage nicIds
    DEBUG: 2018/09/27 09:03:04 Checking distribution of storage pods across nicId(s)
    DEBUG: 2018/09/27 09:03:04 Pod scheduled as expected
    DEBUG: 2018/09/27 09:03:04 Deleting all the pods: 
    DEBUG: 2018/09/27 09:03:41 Waitting for volume to move to "Available" state
    DEBUG: 2018/09/27 09:03:41 Deleting the volumes: 
[AfterEach] Network plus remote storage nic & VFs scheduling
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1750
    DEBUG: 2018/09/27 09:04:24 END_TEST NetworkRemoteStorage.NicVFsScheduling Time-taken : 145.79565191

[32m• [SLOW TEST:145.796 seconds][0m
NetworkRemoteStorage.NicVFsScheduling Daily AT_Scheduling-1.2 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1733[0m
  Network plus remote storage nic & VFs scheduling
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1734[0m
    Network plus remote storage nic & VFs scheduling
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1754[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.NicVFsScheduling Daily AT_Scheduling-2.0[0m [90mOccupy 2 VFs on nicID 1 and start traffic for 2 more VFs, they should be scheduled on nicId 3[0m 
  [1mCreate pods and check scheduling on nicID(s)[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3152[0m
[BeforeEach] Occupy 2 VFs on nicID 1 and start traffic for 2 more VFs, they should be scheduled on nicId 3
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3137
    DEBUG: 2018/09/27 09:04:24 START_TEST RemoteStorage.NicVFsScheduling
    DEBUG: 2018/09/27 09:04:24 Login to cluster
    DEBUG: 2018/09/27 09:04:24 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:04:25 Checking basic Vnic usage
    DEBUG: 2018/09/27 09:04:25 Updating inventory struct
[It] Create pods and check scheduling on nicID(s)
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3152
    DEBUG: 2018/09/27 09:04:31 Creating 4 pods and 4 remote volumes with high qos: 
    DEBUG: 2018/09/27 09:04:31 Create 4 remote volumes: 
    DEBUG: 2018/09/27 09:04:36 Create 4 fio pod(s):
    DEBUG: 2018/09/27 09:04:36 Creating fio pod: fio-pod-high-1
    DEBUG: 2018/09/27 09:04:36 Creating fio pod: fio-pod-high-2
    DEBUG: 2018/09/27 09:04:36 Creating fio pod: fio-pod-high-3
    DEBUG: 2018/09/27 09:04:36 Creating fio pod: fio-pod-high-4
    DEBUG: 2018/09/27 09:04:37 Checking if given pods are in Running state
    DEBUG: 2018/09/27 09:04:51 Delete all pods which are scheduled on nicId 3
    DEBUG: 2018/09/27 09:04:51 Deleting pods : 
    DEBUG: 2018/09/27 09:05:07 Waitting for volume to move to "Available" state
    DEBUG: 2018/09/27 09:05:07 Deleting all the volumes which are used by pods which was deleted
    DEBUG: 2018/09/27 09:05:54 Creating 2 pods and 2 remote volumes with high qos: 
    DEBUG: 2018/09/27 09:05:54 Create 2 remote volumes: 
    DEBUG: 2018/09/27 09:05:56 Create 2 fio pod(s):
    DEBUG: 2018/09/27 09:05:56 Creating fio pod: fio-pod-high-new-1
    DEBUG: 2018/09/27 09:05:57 Creating fio pod: fio-pod-high-new-2
    DEBUG: 2018/09/27 09:05:57 Checking if given pods are in Running state
    DEBUG: 2018/09/27 09:06:08 Deleting all the pods: 
    DEBUG: 2018/09/27 09:06:37 Waitting for volume to move to "Available" state
    DEBUG: 2018/09/27 09:06:37 Deleting the volumes: 
[AfterEach] Occupy 2 VFs on nicID 1 and start traffic for 2 more VFs, they should be scheduled on nicId 3
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3147
    DEBUG: 2018/09/27 09:08:24 END_TEST RemoteStorage.NicVFsScheduling Time-taken : 240.469524995

[32m• [SLOW TEST:240.470 seconds][0m
RemoteStorage.NicVFsScheduling Daily AT_Scheduling-2.0
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3128[0m
  Occupy 2 VFs on nicID 1 and start traffic for 2 more VFs, they should be scheduled on nicId 3
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3130[0m
    Create pods and check scheduling on nicID(s)
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3152[0m
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.Basic Sanity RS_Basic-1.1 RS_Basic-1.2 RS_Basic-1.3 RS_Basic-1.5 RS_Verify-1.0 RS_Stress-1.1[0m [90mRemote Storage volume basic test for sanity[0m 
  [1mremote storage volume basic operations[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1045[0m
[BeforeEach] Remote Storage volume basic test for sanity
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1029
    DEBUG: 2018/09/27 09:08:24 START_TEST RemoteStorage.Basic
    DEBUG: 2018/09/27 09:08:24 Login to cluster
    DEBUG: 2018/09/27 09:08:24 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:08:25 Checking basic Vnic usage
    DEBUG: 2018/09/27 09:08:25 Updating inventory struct
[It] remote storage volume basic operations
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1045
    DEBUG: 2018/09/27 09:08:31 Pick up bosserv4 as targetNode and bosserv5 as initiatorNode
    DEBUG: 2018/09/27 09:08:31 Computing total available storage space on targetNode bosserv4
    DEBUG: 2018/09/27 09:08:31 Storage available : 3051037392896, capacity : 3051037392896
    DEBUG: 2018/09/27 09:08:32 Create volumes until vol-size is >  max free space on targetNode or maxvols created
    DEBUG: 2018/09/27 09:08:37 Attach all 5 volumes of bosserv4 on bosserv5
    DEBUG: 2018/09/27 09:09:01 List of devices :  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:09:01 Running WRITE IOs with SHA512 checksum : IO SIZE (4K)
    DEBUG: 2018/09/27 09:09:01 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize=4K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:09:32 output : job1: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [w(5)][12.9%][r=0KiB/s,w=41.3MiB/s][r=0,w=10.6k IOPS][eta 00m:27s]Jobs: 5 (f=5): [w(5)][16.1%][r=0KiB/s,w=40.1MiB/s][r=0,w=10.5k IOPS][eta 00m:26s]Jobs: 5 (f=5): [w(5)][19.4%][r=0KiB/s,w=40.8MiB/s][r=0,w=10.5k IOPS][eta 00m:25s]Jobs: 5 (f=5): [w(5)][22.6%][r=0KiB/s,w=40.8MiB/s][r=0,w=10.5k IOPS][eta 00m:24s]Jobs: 5 (f=5): [w(5)][25.8%][r=0KiB/s,w=41.2MiB/s][r=0,w=10.6k IOPS][eta 00m:23s]Jobs: 5 (f=5): [w(5)][29.0%][r=0KiB/s,w=41.3MiB/s][r=0,w=10.6k IOPS][eta 00m:22s]Jobs: 5 (f=5): [w(5)][32.3%][r=0KiB/s,w=41.5MiB/s][r=0,w=10.7k IOPS][eta 00m:21s]Jobs: 5 (f=5): [w(5)][35.5%][r=0KiB/s,w=41.4MiB/s][r=0,w=10.6k IOPS][eta 00m:20s]Jobs: 5 (f=5): [w(5)][38.7%][r=0KiB/s,w=41.5MiB/s][r=0,w=10.6k IOPS][eta 00m:19s]Jobs: 5 (f=5): [w(5)][41.9%][r=0KiB/s,w=41.4MiB/s][r=0,w=10.6k IOPS][eta 00m:18s]Jobs: 5 (f=5): [w(5)][45.2%][r=0KiB/s,w=40.8MiB/s][r=0,w=10.5k IOPS][eta 00m:17s]Jobs: 5 (f=5): [w(5)][48.4%][r=0KiB/s,w=40.6MiB/s][r=0,w=10.4k IOPS][eta 00m:16s]Jobs: 5 (f=5): [w(5)][51.6%][r=0KiB/s,w=41.4MiB/s][r=0,w=10.6k IOPS][eta 00m:15s]Jobs: 5 (f=5): [w(5)][54.8%][r=0KiB/s,w=41.7MiB/s][r=0,w=10.7k IOPS][eta 00m:14s]Jobs: 5 (f=5): [w(5)][58.1%][r=0KiB/s,w=41.7MiB/s][r=0,w=10.7k IOPS][eta 00m:13s]Jobs: 5 (f=5): [w(5)][61.3%][r=0KiB/s,w=41.6MiB/s][r=0,w=10.6k IOPS][eta 00m:12s]Jobs: 5 (f=5): [w(5)][64.5%][r=0KiB/s,w=41.3MiB/s][r=0,w=10.6k IOPS][eta 00m:11s]Jobs: 5 (f=5): [w(5)][67.7%][r=0KiB/s,w=41.4MiB/s][r=0,w=10.6k IOPS][eta 00m:10s]Jobs: 5 (f=5): [w(5)][71.0%][r=0KiB/s,w=41.6MiB/s][r=0,w=10.7k IOPS][eta 00m:09s]Jobs: 5 (f=5): [w(5)][74.2%][r=0KiB/s,w=41.2MiB/s][r=0,w=10.6k IOPS][eta 00m:08s]Jobs: 5 (f=5): [w(5)][77.4%][r=0KiB/s,w=40.6MiB/s][r=0,w=10.4k IOPS][eta 00m:07s]Jobs: 5 (f=5): [w(5)][80.6%][r=0KiB/s,w=41.4MiB/s][r=0,w=10.6k IOPS][eta 00m:06s]Jobs: 5 (f=5): [w(5)][83.9%][r=0KiB/s,w=41.6MiB/s][r=0,w=10.7k IOPS][eta 00m:05s]Jobs: 5 (f=5): [w(5)][87.1%][r=0KiB/s,w=41.4MiB/s][r=0,w=10.6k IOPS][eta 00m:04s]Jobs: 5 (f=5): [w(5)][90.3%][r=0KiB/s,w=41.3MiB/s][r=0,w=10.6k IOPS][eta 00m:03s]Jobs: 5 (f=5): [w(5)][93.5%][r=0KiB/s,w=41.2MiB/s][r=0,w=10.6k IOPS][eta 00m:02s]Jobs: 5 (f=5): [w(5)][96.8%][r=0KiB/s,w=41.3MiB/s][r=0,w=10.6k IOPS][eta 00m:01s]Jobs: 5 (f=5): [w(5)][100.0%][r=0KiB/s,w=40.2MiB/s][r=0,w=10.5k IOPS][eta 00m:00s]
job1: (groupid=0, jobs=5): err= 0: pid=15307: Thu Sep 27 09:09:32 2018
  write: IOPS=10.6k, BW=41.2MiB/s (43.1MB/s)(1233MiB/30002msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=7.55%, sys=3.10%, ctx=315752, majf=0, minf=584
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,315664,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=41.2MiB/s (43.1MB/s), 41.2MiB/s-41.2MiB/s (43.1MB/s-43.1MB/s), io=1233MiB (1293MB), run=30002-30002msec

Disk stats (read/write):
  nvme1n1: ios=45/62846, merge=0/0, ticks=7/26892, in_queue=26878, util=89.63%
  nvme2n1: ios=45/62731, merge=0/0, ticks=4/26845, in_queue=26831, util=89.54%
  nvme3n1: ios=45/62270, merge=0/0, ticks=3/26631, in_queue=26614, util=88.88%
  nvme4n1: ios=43/62819, merge=0/0, ticks=12/26845, in_queue=26835, util=89.66%
  nvme5n1: ios=43/62988, merge=0/0, ticks=13/26810, in_queue=26810, util=89.65%


    DEBUG: 2018/09/27 09:09:32 Running VERIFY IOs with SHA512 checksum : IO SIZE (4K)
    DEBUG: 2018/09/27 09:09:32 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize=4K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:09:50 output : job1: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [V(5)][0.8%][r=75.8MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 06m:01s]Jobs: 5 (f=5): [V(5)][1.4%][r=75.5MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 05m:54s]Jobs: 5 (f=5): [V(5)][1.7%][r=76.2MiB/s,w=0KiB/s][r=19.5k,w=0 IOPS][eta 05m:48s]Jobs: 5 (f=5): [V(5)][2.0%][r=75.7MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 05m:44s]Jobs: 5 (f=5): [V(5)][2.3%][r=75.9MiB/s,w=0KiB/s][r=19.5k,w=0 IOPS][eta 05m:41s]Jobs: 5 (f=5): [V(5)][2.6%][r=74.4MiB/s,w=0KiB/s][r=19.5k,w=0 IOPS][eta 05m:39s]Jobs: 5 (f=5): [V(5)][2.9%][r=74.3MiB/s,w=0KiB/s][r=19.1k,w=0 IOPS][eta 05m:38s]Jobs: 5 (f=5): [V(5)][3.2%][r=76.2MiB/s,w=0KiB/s][r=19.5k,w=0 IOPS][eta 05m:36s]Jobs: 5 (f=5): [V(5)][3.5%][r=76.9MiB/s,w=0KiB/s][r=19.7k,w=0 IOPS][eta 05m:34s]Jobs: 5 (f=5): [V(5)][3.8%][r=77.2MiB/s,w=0KiB/s][r=19.8k,w=0 IOPS][eta 05m:32s]Jobs: 5 (f=5): [V(5)][4.1%][r=76.4MiB/s,w=0KiB/s][r=19.6k,w=0 IOPS][eta 05m:30s]Jobs: 5 (f=5): [V(5)][4.4%][r=74.5MiB/s,w=0KiB/s][r=19.6k,w=0 IOPS][eta 05m:29s]Jobs: 5 (f=5): [V(5)][4.7%][r=73.1MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 05m:28s]Jobs: 5 (f=5): [V(5)][4.9%][r=74.4MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 05m:28s]
job1: (groupid=0, jobs=5): err= 0: pid=15552: Thu Sep 27 09:09:50 2018
   read: IOPS=19.2k, BW=74.9MiB/s (78.5MB/s)(1233MiB/16473msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=11.52%, sys=3.47%, ctx=315718, majf=0, minf=431
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=315664,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=74.9MiB/s (78.5MB/s), 74.9MiB/s-74.9MiB/s (78.5MB/s-78.5MB/s), io=1233MiB (1293MB), run=16473-16473msec

Disk stats (read/write):
  nvme1n1: ios=63199/0, merge=0/0, ticks=14049/0, in_queue=14035, util=85.14%
  nvme2n1: ios=62557/0, merge=0/0, ticks=13967/0, in_queue=13952, util=84.72%
  nvme3n1: ios=62028/0, merge=0/0, ticks=13849/0, in_queue=13834, util=85.41%
  nvme4n1: ios=62330/0, merge=0/0, ticks=13948/0, in_queue=13938, util=86.17%
  nvme5n1: ios=63072/0, merge=0/0, ticks=13996/0, in_queue=13978, util=85.23%


    DEBUG: 2018/09/27 09:09:50 Running WRITE IOs with SHA512 checksum : IO SIZE (64K)
    DEBUG: 2018/09/27 09:09:50 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize=64K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:10:21 output : job1: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [w(5)][12.9%][r=0KiB/s,w=304MiB/s][r=0,w=4868 IOPS][eta 00m:27s]Jobs: 5 (f=5): [w(5)][16.1%][r=0KiB/s,w=308MiB/s][r=0,w=4925 IOPS][eta 00m:26s]Jobs: 5 (f=5): [w(5)][19.4%][r=0KiB/s,w=304MiB/s][r=0,w=4863 IOPS][eta 00m:25s]Jobs: 5 (f=5): [w(5)][22.6%][r=0KiB/s,w=306MiB/s][r=0,w=4894 IOPS][eta 00m:24s]Jobs: 5 (f=5): [w(5)][25.8%][r=0KiB/s,w=312MiB/s][r=0,w=4985 IOPS][eta 00m:23s]Jobs: 5 (f=5): [w(5)][29.0%][r=0KiB/s,w=300MiB/s][r=0,w=4794 IOPS][eta 00m:22s]Jobs: 5 (f=5): [w(5)][32.3%][r=0KiB/s,w=299MiB/s][r=0,w=4790 IOPS][eta 00m:21s]Jobs: 5 (f=5): [w(5)][35.5%][r=0KiB/s,w=300MiB/s][r=0,w=4800 IOPS][eta 00m:20s]Jobs: 5 (f=5): [w(5)][38.7%][r=0KiB/s,w=302MiB/s][r=0,w=4828 IOPS][eta 00m:19s]Jobs: 5 (f=5): [w(5)][41.9%][r=0KiB/s,w=302MiB/s][r=0,w=4824 IOPS][eta 00m:18s]Jobs: 5 (f=5): [w(5)][45.2%][r=0KiB/s,w=312MiB/s][r=0,w=4994 IOPS][eta 00m:17s]Jobs: 5 (f=5): [w(5)][48.4%][r=0KiB/s,w=315MiB/s][r=0,w=5032 IOPS][eta 00m:16s]Jobs: 5 (f=5): [w(5)][51.6%][r=0KiB/s,w=315MiB/s][r=0,w=5039 IOPS][eta 00m:15s]Jobs: 5 (f=5): [w(5)][54.8%][r=0KiB/s,w=310MiB/s][r=0,w=4963 IOPS][eta 00m:14s]Jobs: 5 (f=5): [w(5)][58.1%][r=0KiB/s,w=300MiB/s][r=0,w=4807 IOPS][eta 00m:13s]Jobs: 5 (f=5): [w(5)][61.3%][r=0KiB/s,w=303MiB/s][r=0,w=4850 IOPS][eta 00m:12s]Jobs: 5 (f=5): [w(5)][64.5%][r=0KiB/s,w=304MiB/s][r=0,w=4859 IOPS][eta 00m:11s]Jobs: 5 (f=5): [w(5)][67.7%][r=0KiB/s,w=300MiB/s][r=0,w=4798 IOPS][eta 00m:10s]Jobs: 5 (f=5): [w(5)][71.0%][r=0KiB/s,w=303MiB/s][r=0,w=4840 IOPS][eta 00m:09s]Jobs: 5 (f=5): [w(5)][74.2%][r=0KiB/s,w=305MiB/s][r=0,w=4880 IOPS][eta 00m:08s]Jobs: 5 (f=5): [w(5)][77.4%][r=0KiB/s,w=310MiB/s][r=0,w=4964 IOPS][eta 00m:07s]Jobs: 5 (f=5): [w(5)][80.6%][r=0KiB/s,w=311MiB/s][r=0,w=4982 IOPS][eta 00m:06s]Jobs: 5 (f=5): [w(5)][83.9%][r=0KiB/s,w=298MiB/s][r=0,w=4768 IOPS][eta 00m:05s]Jobs: 5 (f=5): [w(5)][87.1%][r=0KiB/s,w=293MiB/s][r=0,w=4690 IOPS][eta 00m:04s]Jobs: 5 (f=5): [w(5)][90.3%][r=0KiB/s,w=297MiB/s][r=0,w=4748 IOPS][eta 00m:03s]Jobs: 5 (f=5): [w(5)][93.5%][r=0KiB/s,w=300MiB/s][r=0,w=4797 IOPS][eta 00m:02s]Jobs: 5 (f=5): [w(5)][96.8%][r=0KiB/s,w=310MiB/s][r=0,w=4961 IOPS][eta 00m:01s]Jobs: 5 (f=5): [w(5)][100.0%][r=0KiB/s,w=307MiB/s][r=0,w=4912 IOPS][eta 00m:00s]
job1: (groupid=0, jobs=5): err= 0: pid=15684: Thu Sep 27 09:10:21 2018
  write: IOPS=4873, BW=305MiB/s (319MB/s)(9138MiB/30002msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=42.51%, sys=2.22%, ctx=146397, majf=0, minf=1157
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,146204,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=305MiB/s (319MB/s), 305MiB/s-305MiB/s (319MB/s-319MB/s), io=9138MiB (9582MB), run=30002-30002msec

Disk stats (read/write):
  nvme1n1: ios=45/28971, merge=0/0, ticks=16/16634, in_queue=16642, util=55.46%
  nvme2n1: ios=45/29315, merge=0/0, ticks=10/16728, in_queue=16728, util=55.79%
  nvme3n1: ios=45/28804, merge=0/0, ticks=12/17263, in_queue=17267, util=57.65%
  nvme4n1: ios=43/29178, merge=0/0, ticks=9/16120, in_queue=16119, util=53.85%
  nvme5n1: ios=43/28985, merge=0/0, ticks=12/18801, in_queue=18810, util=62.90%


    DEBUG: 2018/09/27 09:10:21 Running VERIFY IOs with SHA512 checksum : IO SIZE (64K)
    DEBUG: 2018/09/27 09:10:21 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize=64K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:10:48 output : job1: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=64.0KiB-64.0KiB,64.0KiB-64.0KiB,64.0KiB-64.0KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [V(5)][5.4%][r=374MiB/s,w=0KiB/s][r=5987,w=0 IOPS][eta 01m:10s]Jobs: 5 (f=5): [V(5)][6.7%][r=361MiB/s,w=0KiB/s][r=5780,w=0 IOPS][eta 01m:10s]Jobs: 5 (f=5): [V(5)][8.0%][r=348MiB/s,w=0KiB/s][r=5562,w=0 IOPS][eta 01m:09s]Jobs: 5 (f=5): [V(5)][9.3%][r=346MiB/s,w=0KiB/s][r=5535,w=0 IOPS][eta 01m:08s]Jobs: 5 (f=5): [V(5)][10.7%][r=348MiB/s,w=0KiB/s][r=5569,w=0 IOPS][eta 01m:07s]Jobs: 5 (f=5): [V(5)][12.0%][r=352MiB/s,w=0KiB/s][r=5638,w=0 IOPS][eta 01m:06s]Jobs: 5 (f=5): [V(5)][13.5%][r=356MiB/s,w=0KiB/s][r=5693,w=0 IOPS][eta 01m:04s]Jobs: 5 (f=5): [V(5)][14.9%][r=355MiB/s,w=0KiB/s][r=5679,w=0 IOPS][eta 01m:03s]Jobs: 5 (f=5): [V(5)][16.2%][r=358MiB/s,w=0KiB/s][r=5720,w=0 IOPS][eta 01m:02s]Jobs: 5 (f=5): [V(5)][17.6%][r=367MiB/s,w=0KiB/s][r=5878,w=0 IOPS][eta 01m:01s]Jobs: 5 (f=5): [V(5)][18.9%][r=369MiB/s,w=0KiB/s][r=5899,w=0 IOPS][eta 01m:00s]Jobs: 5 (f=5): [V(5)][20.3%][r=357MiB/s,w=0KiB/s][r=5714,w=0 IOPS][eta 00m:59s]Jobs: 4 (f=4): [_(1),V(4)][21.9%][r=355MiB/s,w=0KiB/s][r=5676,w=0 IOPS][eta 00m:57s]Jobs: 4 (f=4): [_(1),V(4)][23.3%][r=285MiB/s,w=0KiB/s][r=4556,w=0 IOPS][eta 00m:56s]Jobs: 4 (f=4): [_(1),V(4)][24.7%][r=284MiB/s,w=0KiB/s][r=4549,w=0 IOPS][eta 00m:55s]Jobs: 4 (f=4): [_(1),V(4)][26.0%][r=281MiB/s,w=0KiB/s][r=4493,w=0 IOPS][eta 00m:54s]Jobs: 4 (f=4): [_(1),V(4)][27.4%][r=281MiB/s,w=0KiB/s][r=4502,w=0 IOPS][eta 00m:53s]Jobs: 4 (f=4): [_(1),V(4)][28.8%][r=282MiB/s,w=0KiB/s][r=4518,w=0 IOPS][eta 00m:52s]Jobs: 4 (f=4): [_(1),V(4)][30.1%][r=286MiB/s,w=0KiB/s][r=4579,w=0 IOPS][eta 00m:51s]Jobs: 4 (f=4): [_(1),V(4)][31.5%][r=292MiB/s,w=0KiB/s][r=4673,w=0 IOPS][eta 00m:50s]Jobs: 4 (f=4): [_(1),V(4)][32.9%][r=285MiB/s,w=0KiB/s][r=4567,w=0 IOPS][eta 00m:49s]Jobs: 4 (f=4): [_(1),V(4)][34.2%][r=277MiB/s,w=0KiB/s][r=4432,w=0 IOPS][eta 00m:48s]Jobs: 4 (f=4): [_(1),V(4)][35.6%][r=281MiB/s,w=0KiB/s][r=4503,w=0 IOPS][eta 00m:47s]Jobs: 1 (f=1): [_(1),V(1),_(3)][90.0%][r=216MiB/s,w=0KiB/s][r=3462,w=0 IOPS][eta 00m:03s]
job1: (groupid=0, jobs=5): err= 0: pid=15920: Thu Sep 27 09:10:48 2018
   read: IOPS=5170, BW=323MiB/s (339MB/s)(8365MiB/25885msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=47.51%, sys=2.25%, ctx=133969, majf=0, minf=1193
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=133841,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=323MiB/s (339MB/s), 323MiB/s-323MiB/s (339MB/s-339MB/s), io=8365MiB (8771MB), run=25885-25885msec

Disk stats (read/write):
  nvme1n1: ios=16586/0, merge=0/0, ticks=6655/0, in_queue=6651, util=45.14%
  nvme2n1: ios=29427/0, merge=0/0, ticks=11586/0, in_queue=11575, util=44.58%
  nvme3n1: ios=28736/0, merge=0/0, ticks=11495/0, in_queue=11486, util=45.14%
  nvme4n1: ios=29194/0, merge=0/0, ticks=11949/0, in_queue=11938, util=46.96%
  nvme5n1: ios=28921/0, merge=0/0, ticks=11767/0, in_queue=11764, util=46.32%


    DEBUG: 2018/09/27 09:10:48 Running WRITE IOs with SHA512 checksum : BS Range (4K to 1M)
    DEBUG: 2018/09/27 09:10:48 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize_range=4K-1024K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:11:19 output : job1: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [w(5)][12.9%][r=0KiB/s,w=687MiB/s][r=0,w=1505 IOPS][eta 00m:27s]Jobs: 5 (f=5): [w(5)][16.1%][r=0KiB/s,w=691MiB/s][r=0,w=1615 IOPS][eta 00m:26s]Jobs: 5 (f=5): [w(5)][19.4%][r=0KiB/s,w=692MiB/s][r=0,w=1648 IOPS][eta 00m:25s]Jobs: 5 (f=5): [w(5)][22.6%][r=0KiB/s,w=688MiB/s][r=0,w=1766 IOPS][eta 00m:24s]Jobs: 5 (f=5): [w(5)][25.8%][r=0KiB/s,w=684MiB/s][r=0,w=1843 IOPS][eta 00m:23s]Jobs: 5 (f=5): [w(5)][29.0%][r=0KiB/s,w=661MiB/s][r=0,w=1828 IOPS][eta 00m:22s]Jobs: 5 (f=5): [w(5)][32.3%][r=0KiB/s,w=652MiB/s][r=0,w=1863 IOPS][eta 00m:21s]Jobs: 5 (f=5): [w(5)][35.5%][r=0KiB/s,w=653MiB/s][r=0,w=1880 IOPS][eta 00m:20s]Jobs: 5 (f=5): [w(5)][38.7%][r=0KiB/s,w=664MiB/s][r=0,w=1795 IOPS][eta 00m:19s]Jobs: 5 (f=5): [w(5)][41.9%][r=0KiB/s,w=664MiB/s][r=0,w=1880 IOPS][eta 00m:18s]Jobs: 5 (f=5): [w(5)][45.2%][r=0KiB/s,w=653MiB/s][r=0,w=1933 IOPS][eta 00m:17s]Jobs: 5 (f=5): [w(5)][48.4%][r=0KiB/s,w=647MiB/s][r=0,w=1975 IOPS][eta 00m:16s]Jobs: 5 (f=5): [w(5)][51.6%][r=0KiB/s,w=643MiB/s][r=0,w=1746 IOPS][eta 00m:15s]Jobs: 5 (f=5): [w(5)][54.8%][r=0KiB/s,w=663MiB/s][r=0,w=1862 IOPS][eta 00m:14s]Jobs: 5 (f=5): [w(5)][58.1%][r=0KiB/s,w=660MiB/s][r=0,w=1927 IOPS][eta 00m:13s]Jobs: 5 (f=5): [w(5)][61.3%][r=0KiB/s,w=640MiB/s][r=0,w=1973 IOPS][eta 00m:12s]Jobs: 5 (f=5): [w(5)][64.5%][r=0KiB/s,w=633MiB/s][r=0,w=2044 IOPS][eta 00m:11s]Jobs: 5 (f=5): [w(5)][67.7%][r=0KiB/s,w=628MiB/s][r=0,w=1984 IOPS][eta 00m:10s]Jobs: 5 (f=5): [w(5)][71.0%][r=0KiB/s,w=633MiB/s][r=0,w=1978 IOPS][eta 00m:09s]Jobs: 5 (f=5): [w(5)][74.2%][r=0KiB/s,w=618MiB/s][r=0,w=1975 IOPS][eta 00m:08s]Jobs: 5 (f=5): [w(5)][77.4%][r=0KiB/s,w=638MiB/s][r=0,w=2066 IOPS][eta 00m:07s]Jobs: 5 (f=5): [w(5)][80.6%][r=0KiB/s,w=611MiB/s][r=0,w=2027 IOPS][eta 00m:06s]Jobs: 5 (f=5): [w(5)][83.9%][r=0KiB/s,w=653MiB/s][r=0,w=2030 IOPS][eta 00m:05s]Jobs: 5 (f=5): [w(5)][87.1%][r=0KiB/s,w=639MiB/s][r=0,w=2126 IOPS][eta 00m:04s]Jobs: 5 (f=5): [w(5)][90.3%][r=0KiB/s,w=608MiB/s][r=0,w=1960 IOPS][eta 00m:03s]Jobs: 5 (f=5): [w(5)][93.5%][r=0KiB/s,w=604MiB/s][r=0,w=1993 IOPS][eta 00m:02s]Jobs: 5 (f=5): [w(5)][96.8%][r=0KiB/s,w=626MiB/s][r=0,w=1928 IOPS][eta 00m:01s]Jobs: 5 (f=5): [w(5)][100.0%][r=0KiB/s,w=607MiB/s][r=0,w=1701 IOPS][eta 00m:00s]
job1: (groupid=0, jobs=5): err= 0: pid=16087: Thu Sep 27 09:11:19 2018
  write: IOPS=1856, BW=649MiB/s (681MB/s)(19.2GiB/30005msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=56.38%, sys=1.22%, ctx=55971, majf=0, minf=7976
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,55709,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=649MiB/s (681MB/s), 649MiB/s-649MiB/s (681MB/s-681MB/s), io=19.2GiB (20.5GB), run=30005-30005msec

Disk stats (read/write):
  nvme1n1: ios=45/31296, merge=0/0, ticks=42/35593, in_queue=35630, util=38.76%
  nvme2n1: ios=45/42591, merge=0/0, ticks=36/45565, in_queue=45594, util=48.07%
  nvme3n1: ios=45/37279, merge=0/0, ticks=22/42604, in_queue=42619, util=45.02%
  nvme4n1: ios=45/32132, merge=0/0, ticks=36/34506, in_queue=34544, util=36.13%
  nvme5n1: ios=43/39296, merge=0/0, ticks=34/45154, in_queue=45181, util=46.82%


    DEBUG: 2018/09/27 09:11:19 Running VERIFY IOs with SHA512 checksum : BS Range (4K to 1M)
    DEBUG: 2018/09/27 09:11:19 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize_range=4K-1024K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:11:56 output : job1: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=4096B-1024KiB,4096B-1024KiB,4096B-1024KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [V(5)][9.1%][r=709MiB/s,w=0KiB/s][r=1604,w=0 IOPS][eta 00m:40s]Jobs: 5 (f=5): [V(5)][12.2%][r=789MiB/s,w=0KiB/s][r=1880,w=0 IOPS][eta 00m:36s]Jobs: 5 (f=5): [V(5)][14.6%][r=711MiB/s,w=0KiB/s][r=1749,w=0 IOPS][eta 00m:35s]Jobs: 5 (f=5): [V(5)][17.1%][r=715MiB/s,w=0KiB/s][r=1890,w=0 IOPS][eta 00m:34s]Jobs: 5 (f=5): [V(5)][19.0%][r=695MiB/s,w=0KiB/s][r=1868,w=0 IOPS][eta 00m:34s]Jobs: 4 (f=4): [_(1),V(4)][21.4%][r=718MiB/s,w=0KiB/s][r=2083,w=0 IOPS][eta 00m:33s]Jobs: 4 (f=4): [_(1),V(4)][23.3%][r=610MiB/s,w=0KiB/s][r=1667,w=0 IOPS][eta 00m:33s]Jobs: 4 (f=4): [_(1),V(4)][25.6%][r=596MiB/s,w=0KiB/s][r=1704,w=0 IOPS][eta 00m:32s]Jobs: 4 (f=4): [_(1),V(4)][27.3%][r=582MiB/s,w=0KiB/s][r=1623,w=0 IOPS][eta 00m:32s]Jobs: 4 (f=4): [_(1),V(4)][29.5%][r=597MiB/s,w=0KiB/s][r=1788,w=0 IOPS][eta 00m:31s]Jobs: 4 (f=4): [_(1),V(4)][31.8%][r=563MiB/s,w=0KiB/s][r=1778,w=0 IOPS][eta 00m:30s]Jobs: 4 (f=4): [_(1),V(4)][34.9%][r=600MiB/s,w=0KiB/s][r=1920,w=0 IOPS][eta 00m:28s]Jobs: 3 (f=3): [_(2),V(3)][37.2%][r=496MiB/s,w=0KiB/s][r=1587,w=0 IOPS][eta 00m:27s]Jobs: 3 (f=3): [_(2),V(3)][39.5%][r=433MiB/s,w=0KiB/s][r=1463,w=0 IOPS][eta 00m:26s]Jobs: 3 (f=3): [_(2),V(3)][41.9%][r=418MiB/s,w=0KiB/s][r=1445,w=0 IOPS][eta 00m:25s]Jobs: 3 (f=3): [_(2),V(3)][43.2%][r=403MiB/s,w=0KiB/s][r=1317,w=0 IOPS][eta 00m:25s]Jobs: 3 (f=3): [_(2),V(3)][45.5%][r=392MiB/s,w=0KiB/s][r=1375,w=0 IOPS][eta 00m:24s]Jobs: 2 (f=2): [_(3),V(2)][47.7%][r=338MiB/s,w=0KiB/s][r=1157,w=0 IOPS][eta 00m:23s]Jobs: 2 (f=2): [_(3),V(2)][50.0%][r=226MiB/s,w=0KiB/s][r=738,w=0 IOPS][eta 00m:22s] Jobs: 2 (f=2): [_(3),V(2)][52.3%][r=228MiB/s,w=0KiB/s][r=781,w=0 IOPS][eta 00m:21s]Jobs: 1 (f=1): [_(4),V(1)][54.5%][r=162MiB/s,w=0KiB/s][r=527,w=0 IOPS][eta 00m:20s]Jobs: 1 (f=1): [_(4),V(1)][56.8%][r=145MiB/s,w=0KiB/s][r=420,w=0 IOPS][eta 00m:19s]Jobs: 1 (f=1): [_(4),V(1)][59.1%][r=141MiB/s,w=0KiB/s][r=418,w=0 IOPS][eta 00m:18s]Jobs: 1 (f=1): [_(4),V(1)][61.4%][r=110MiB/s,w=0KiB/s][r=353,w=0 IOPS][eta 00m:17s]Jobs: 1 (f=1): [_(4),V(1)][63.6%][r=109MiB/s,w=0KiB/s][r=354,w=0 IOPS][eta 00m:16s]Jobs: 1 (f=1): [_(4),V(1)][65.9%][r=110MiB/s,w=0KiB/s][r=338,w=0 IOPS][eta 00m:15s]Jobs: 1 (f=1): [_(4),V(1)][68.2%][r=106MiB/s,w=0KiB/s][r=358,w=0 IOPS][eta 00m:14s]Jobs: 1 (f=1): [_(4),V(1)][70.5%][r=110MiB/s,w=0KiB/s][r=369,w=0 IOPS][eta 00m:13s]Jobs: 1 (f=1): [_(4),V(1)][72.7%][r=107MiB/s,w=0KiB/s][r=373,w=0 IOPS][eta 00m:12s]Jobs: 1 (f=1): [_(4),V(1)][75.0%][r=110MiB/s,w=0KiB/s][r=377,w=0 IOPS][eta 00m:11s]Jobs: 1 (f=1): [_(4),V(1)][75.6%][r=109MiB/s,w=0KiB/s][r=381,w=0 IOPS][eta 00m:11s]Jobs: 1 (f=1): [_(4),V(1)][77.8%][r=107MiB/s,w=0KiB/s][r=409,w=0 IOPS][eta 00m:10s]Jobs: 1 (f=1): [_(4),V(1)][80.0%][r=110MiB/s,w=0KiB/s][r=398,w=0 IOPS][eta 00m:09s]Jobs: 1 (f=1): [_(4),V(1)][82.2%][r=106MiB/s,w=0KiB/s][r=392,w=0 IOPS][eta 00m:08s]
job1: (groupid=0, jobs=5): err= 0: pid=16330: Thu Sep 27 09:11:56 2018
   read: IOPS=1100, BW=382MiB/s (401MB/s)(13.6GiB/36196msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=61.80%, sys=1.84%, ctx=39963, majf=0, minf=7026
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=39819,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=382MiB/s (401MB/s), 382MiB/s-382MiB/s (401MB/s-401MB/s), io=13.6GiB (14.6GB), run=36196-36196msec

Disk stats (read/write):
  nvme1n1: ios=9779/0, merge=0/0, ticks=10187/0, in_queue=10186, util=40.70%
  nvme2n1: ios=19182/0, merge=0/0, ticks=18174/0, in_queue=18172, util=38.65%
  nvme3n1: ios=29141/0, merge=0/0, ticks=28055/0, in_queue=28053, util=43.02%
  nvme4n1: ios=32129/0, merge=0/0, ticks=30206/0, in_queue=30196, util=39.12%
  nvme5n1: ios=39437/0, merge=0/0, ticks=37912/0, in_queue=37901, util=29.87%


    DEBUG: 2018/09/27 09:11:56 Running WRITE IOs with SHA512 checksum : BS Range (32K to 1024K)
    DEBUG: 2018/09/27 09:11:56 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize_range=32K-1024K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:12:27 output : job1: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [w(5)][12.9%][r=0KiB/s,w=652MiB/s][r=0,w=1465 IOPS][eta 00m:27s]Jobs: 5 (f=5): [w(5)][16.1%][r=0KiB/s,w=637MiB/s][r=0,w=1511 IOPS][eta 00m:26s]Jobs: 5 (f=5): [w(5)][19.4%][r=0KiB/s,w=637MiB/s][r=0,w=1558 IOPS][eta 00m:25s]Jobs: 5 (f=5): [w(5)][22.6%][r=0KiB/s,w=637MiB/s][r=0,w=1593 IOPS][eta 00m:24s]Jobs: 5 (f=5): [w(5)][25.8%][r=0KiB/s,w=670MiB/s][r=0,w=1784 IOPS][eta 00m:23s]Jobs: 5 (f=5): [w(5)][29.0%][r=0KiB/s,w=659MiB/s][r=0,w=1756 IOPS][eta 00m:22s]Jobs: 5 (f=5): [w(5)][32.3%][r=0KiB/s,w=680MiB/s][r=0,w=1660 IOPS][eta 00m:21s]Jobs: 5 (f=5): [w(5)][35.5%][r=0KiB/s,w=646MiB/s][r=0,w=1668 IOPS][eta 00m:20s]Jobs: 5 (f=5): [w(5)][38.7%][r=0KiB/s,w=638MiB/s][r=0,w=1688 IOPS][eta 00m:19s]Jobs: 5 (f=5): [w(5)][41.9%][r=0KiB/s,w=619MiB/s][r=0,w=1742 IOPS][eta 00m:18s]Jobs: 5 (f=5): [w(5)][45.2%][r=0KiB/s,w=626MiB/s][r=0,w=1762 IOPS][eta 00m:17s]Jobs: 5 (f=5): [w(5)][48.4%][r=0KiB/s,w=606MiB/s][r=0,w=1803 IOPS][eta 00m:16s]Jobs: 5 (f=5): [w(5)][51.6%][r=0KiB/s,w=610MiB/s][r=0,w=1888 IOPS][eta 00m:15s]Jobs: 5 (f=5): [w(5)][54.8%][r=0KiB/s,w=567MiB/s][r=0,w=1819 IOPS][eta 00m:14s]Jobs: 5 (f=5): [w(5)][58.1%][r=0KiB/s,w=643MiB/s][r=0,w=1840 IOPS][eta 00m:13s]Jobs: 5 (f=5): [w(5)][61.3%][r=0KiB/s,w=644MiB/s][r=0,w=1757 IOPS][eta 00m:12s]Jobs: 5 (f=5): [w(5)][64.5%][r=0KiB/s,w=648MiB/s][r=0,w=1766 IOPS][eta 00m:11s]Jobs: 5 (f=5): [w(5)][67.7%][r=0KiB/s,w=615MiB/s][r=0,w=1786 IOPS][eta 00m:10s]Jobs: 5 (f=5): [w(5)][71.0%][r=0KiB/s,w=591MiB/s][r=0,w=1761 IOPS][eta 00m:09s]Jobs: 5 (f=5): [w(5)][74.2%][r=0KiB/s,w=592MiB/s][r=0,w=1778 IOPS][eta 00m:08s]Jobs: 5 (f=5): [w(5)][77.4%][r=0KiB/s,w=581MiB/s][r=0,w=1831 IOPS][eta 00m:07s]Jobs: 5 (f=5): [w(5)][80.6%][r=0KiB/s,w=569MiB/s][r=0,w=1828 IOPS][eta 00m:06s]Jobs: 5 (f=5): [w(5)][83.9%][r=0KiB/s,w=638MiB/s][r=0,w=1725 IOPS][eta 00m:05s]Jobs: 5 (f=5): [w(5)][87.1%][r=0KiB/s,w=642MiB/s][r=0,w=1721 IOPS][eta 00m:04s]Jobs: 5 (f=5): [w(5)][90.3%][r=0KiB/s,w=660MiB/s][r=0,w=1836 IOPS][eta 00m:03s]Jobs: 5 (f=5): [w(5)][93.5%][r=0KiB/s,w=643MiB/s][r=0,w=1887 IOPS][eta 00m:02s]Jobs: 5 (f=5): [w(5)][96.8%][r=0KiB/s,w=644MiB/s][r=0,w=1908 IOPS][eta 00m:01s]Jobs: 5 (f=5): [w(5)][100.0%][r=0KiB/s,w=609MiB/s][r=0,w=1842 IOPS][eta 00m:00s]
job1: (groupid=0, jobs=5): err= 0: pid=16532: Thu Sep 27 09:12:27 2018
  write: IOPS=1724, BW=629MiB/s (659MB/s)(18.5GiB/30004msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=58.45%, sys=2.47%, ctx=51905, majf=0, minf=1497
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,51753,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=629MiB/s (659MB/s), 629MiB/s-629MiB/s (659MB/s-659MB/s), io=18.5GiB (19.8GB), run=30004-30004msec

Disk stats (read/write):
  nvme1n1: ios=45/36030, merge=0/0, ticks=40/40478, in_queue=40510, util=43.94%
  nvme2n1: ios=45/31844, merge=0/0, ticks=34/32948, in_queue=32981, util=35.39%
  nvme3n1: ios=45/35491, merge=0/0, ticks=38/39989, in_queue=40023, util=42.65%
  nvme4n1: ios=45/32255, merge=0/0, ticks=34/33492, in_queue=33517, util=36.46%
  nvme5n1: ios=43/35432, merge=0/0, ticks=34/40169, in_queue=40200, util=42.17%


    DEBUG: 2018/09/27 09:12:27 Running VERIFY IOs with SHA512 checksum : BS Range (32K to 1024K)
    DEBUG: 2018/09/27 09:12:27 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize_range=32K-1024K --direct=1  --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:12:54 output : job1: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=32.0KiB-1024KiB,32.0KiB-1024KiB,32.0KiB-1024KiB, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [V(5)][11.1%][r=732MiB/s,w=0KiB/s][r=1677,w=0 IOPS][eta 00m:32s]Jobs: 5 (f=5): [V(5)][14.3%][r=739MiB/s,w=0KiB/s][r=1762,w=0 IOPS][eta 00m:30s]Jobs: 5 (f=5): [V(5)][17.1%][r=711MiB/s,w=0KiB/s][r=1806,w=0 IOPS][eta 00m:29s]Jobs: 5 (f=5): [V(5)][20.6%][r=757MiB/s,w=0KiB/s][r=1908,w=0 IOPS][eta 00m:27s]Jobs: 5 (f=5): [V(5)][23.5%][r=756MiB/s,w=0KiB/s][r=1968,w=0 IOPS][eta 00m:26s]Jobs: 4 (f=4): [_(1),V(4)][26.5%][r=596MiB/s,w=0KiB/s][r=1558,w=0 IOPS][eta 00m:25s]Jobs: 4 (f=4): [_(1),V(4)][29.4%][r=575MiB/s,w=0KiB/s][r=1472,w=0 IOPS][eta 00m:24s]Jobs: 4 (f=4): [_(1),V(4)][32.4%][r=579MiB/s,w=0KiB/s][r=1559,w=0 IOPS][eta 00m:23s]Jobs: 4 (f=4): [_(1),V(4)][35.3%][r=568MiB/s,w=0KiB/s][r=1588,w=0 IOPS][eta 00m:22s]Jobs: 4 (f=4): [_(1),V(4)][38.2%][r=566MiB/s,w=0KiB/s][r=1614,w=0 IOPS][eta 00m:21s]Jobs: 4 (f=4): [_(1),V(4)][41.2%][r=566MiB/s,w=0KiB/s][r=1623,w=0 IOPS][eta 00m:20s]Jobs: 4 (f=4): [_(1),V(4)][44.1%][r=554MiB/s,w=0KiB/s][r=1636,w=0 IOPS][eta 00m:19s]Jobs: 4 (f=4): [_(1),V(4)][47.1%][r=536MiB/s,w=0KiB/s][r=1613,w=0 IOPS][eta 00m:18s]Jobs: 4 (f=4): [_(1),V(4)][50.0%][r=616MiB/s,w=0KiB/s][r=1894,w=0 IOPS][eta 00m:17s]Jobs: 4 (f=4): [_(1),V(4)][54.5%][r=612MiB/s,w=0KiB/s][r=2024,w=0 IOPS][eta 00m:15s]Jobs: 4 (f=4): [_(1),V(4)][57.6%][r=601MiB/s,w=0KiB/s][r=1896,w=0 IOPS][eta 00m:14s]Jobs: 3 (f=3): [_(2),V(3)][60.6%][r=525MiB/s,w=0KiB/s][r=1710,w=0 IOPS][eta 00m:13s]Jobs: 3 (f=3): [_(2),V(3)][63.6%][r=399MiB/s,w=0KiB/s][r=1360,w=0 IOPS][eta 00m:12s]Jobs: 2 (f=2): [_(3),V(2)][66.7%][r=406MiB/s,w=0KiB/s][r=1319,w=0 IOPS][eta 00m:11s]Jobs: 2 (f=2): [_(3),V(2)][67.6%][r=243MiB/s,w=0KiB/s][r=770,w=0 IOPS][eta 00m:11s] Jobs: 2 (f=2): [_(3),V(2)][70.6%][r=254MiB/s,w=0KiB/s][r=820,w=0 IOPS][eta 00m:10s]Jobs: 1 (f=1): [_(4),V(1)][73.5%][r=188MiB/s,w=0KiB/s][r=606,w=0 IOPS][eta 00m:09s]Jobs: 1 (f=1): [_(4),V(1)][76.5%][r=130MiB/s,w=0KiB/s][r=436,w=0 IOPS][eta 00m:08s]Jobs: 1 (f=1): [_(4),V(1)][77.1%][r=134MiB/s,w=0KiB/s][r=456,w=0 IOPS][eta 00m:08s]
job1: (groupid=0, jobs=5): err= 0: pid=16789: Thu Sep 27 09:12:54 2018
   read: IOPS=1464, BW=528MiB/s (553MB/s)(13.4GiB/25903msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=60.34%, sys=1.94%, ctx=38063, majf=0, minf=6194
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=37933,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=528MiB/s (553MB/s), 528MiB/s-528MiB/s (553MB/s-553MB/s), io=13.4GiB (14.4GB), run=25903-25903msec

Disk stats (read/write):
  nvme1n1: ios=9427/0, merge=0/0, ticks=10170/0, in_queue=10169, util=44.85%
  nvme2n1: ios=18645/0, merge=0/0, ticks=18147/0, in_queue=18142, util=30.16%
  nvme3n1: ios=27980/0, merge=0/0, ticks=28052/0, in_queue=28047, util=41.61%
  nvme4n1: ios=32380/0, merge=0/0, ticks=30431/0, in_queue=30428, util=38.83%
  nvme5n1: ios=35514/0, merge=0/0, ticks=35765/0, in_queue=35762, util=39.61%


    DEBUG: 2018/09/27 09:12:54 Running WRITE IOs with SHA512 checksum : IO SIZE(4K), bs_unaligned
    DEBUG: 2018/09/27 09:12:54 WRITE FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randwrite --runtime=30 --time_based --do_verify=0 --verify_state_save=1  --blocksize=4K  --blocksize_unaligned=1 --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:13:31 output : job1: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job2: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job3: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job4: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job5: (g=0): rw=randwrite, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [w(5)][12.9%][r=0KiB/s,w=1248MiB/s][r=0,w=320k IOPS][eta 00m:27s]Jobs: 5 (f=5): [w(5)][16.1%][r=0KiB/s,w=1256MiB/s][r=0,w=322k IOPS][eta 00m:26s]Jobs: 5 (f=5): [w(5)][19.4%][r=0KiB/s,w=1248MiB/s][r=0,w=319k IOPS][eta 00m:25s]Jobs: 5 (f=5): [w(5)][22.6%][r=0KiB/s,w=1214MiB/s][r=0,w=311k IOPS][eta 00m:24s]Jobs: 5 (f=5): [w(5)][25.8%][r=0KiB/s,w=1262MiB/s][r=0,w=323k IOPS][eta 00m:23s]Jobs: 5 (f=5): [w(5)][29.0%][r=0KiB/s,w=1266MiB/s][r=0,w=324k IOPS][eta 00m:22s]Jobs: 5 (f=5): [w(5)][32.3%][r=0KiB/s,w=1284MiB/s][r=0,w=329k IOPS][eta 00m:21s]Jobs: 5 (f=5): [w(5)][35.5%][r=0KiB/s,w=1305MiB/s][r=0,w=334k IOPS][eta 00m:20s]Jobs: 5 (f=5): [w(5)][38.7%][r=0KiB/s,w=1210MiB/s][r=0,w=310k IOPS][eta 00m:19s]Jobs: 5 (f=5): [w(5)][41.9%][r=0KiB/s,w=1217MiB/s][r=0,w=311k IOPS][eta 00m:18s]Jobs: 5 (f=5): [w(5)][46.7%][r=0KiB/s,w=1192MiB/s][r=0,w=305k IOPS][eta 00m:16s]Jobs: 5 (f=5): [w(5)][48.4%][r=0KiB/s,w=1216MiB/s][r=0,w=311k IOPS][eta 00m:16s]Jobs: 5 (f=5): [w(5)][51.6%][r=0KiB/s,w=1210MiB/s][r=0,w=310k IOPS][eta 00m:15s]Jobs: 5 (f=5): [w(5)][54.8%][r=0KiB/s,w=1209MiB/s][r=0,w=309k IOPS][eta 00m:14s]Jobs: 5 (f=5): [w(5)][58.1%][r=0KiB/s,w=1201MiB/s][r=0,w=307k IOPS][eta 00m:13s]Jobs: 5 (f=5): [w(5)][61.3%][r=0KiB/s,w=1187MiB/s][r=0,w=304k IOPS][eta 00m:12s]Jobs: 5 (f=5): [w(5)][64.5%][r=0KiB/s,w=1221MiB/s][r=0,w=313k IOPS][eta 00m:11s]Jobs: 5 (f=5): [w(5)][67.7%][r=0KiB/s,w=1217MiB/s][r=0,w=312k IOPS][eta 00m:10s]Jobs: 5 (f=5): [w(5)][71.0%][r=0KiB/s,w=1245MiB/s][r=0,w=319k IOPS][eta 00m:09s]Jobs: 5 (f=5): [w(5)][74.2%][r=0KiB/s,w=1266MiB/s][r=0,w=324k IOPS][eta 00m:08s]Jobs: 5 (f=5): [w(5)][77.4%][r=0KiB/s,w=1231MiB/s][r=0,w=315k IOPS][eta 00m:07s]Jobs: 5 (f=5): [w(5)][80.6%][r=0KiB/s,w=1347MiB/s][r=0,w=345k IOPS][eta 00m:06s]Jobs: 5 (f=5): [w(5)][83.9%][r=0KiB/s,w=1299MiB/s][r=0,w=333k IOPS][eta 00m:05s]Jobs: 5 (f=5): [w(5)][90.0%][r=0KiB/s,w=1303MiB/s][r=0,w=334k IOPS][eta 00m:03s]Jobs: 5 (f=5): [w(5)][90.3%][r=0KiB/s,w=1301MiB/s][r=0,w=333k IOPS][eta 00m:03s]Jobs: 5 (f=5): [w(5)][93.5%][r=0KiB/s,w=1301MiB/s][r=0,w=333k IOPS][eta 00m:02s]Jobs: 5 (f=5): [w(5)][96.8%][r=0KiB/s,w=1240MiB/s][r=0,w=317k IOPS][eta 00m:01s]Jobs: 5 (f=5): [w(5)][100.0%][r=0KiB/s,w=1137MiB/s][r=0,w=291k IOPS][eta 00m:00s]Jobs: 5 (f=5): [f(5)][100.0%][r=0KiB/s,w=237MiB/s][r=0,w=60.8k IOPS][eta 00m:00s]Jobs: 4 (f=4): [f(1),_(1),f(3)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 4 (f=4): [f(1),_(1),f(3)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 3 (f=3): [_(2),f(3)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]     Jobs: 3 (f=3): [_(2),f(3)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]Jobs: 1 (f=1): [_(4),f(1)][100.0%][r=0KiB/s,w=0KiB/s][r=0,w=0 IOPS][eta 00m:00s]
job1: (groupid=0, jobs=5): err= 0: pid=16942: Thu Sep 27 09:13:31 2018
  write: IOPS=316k, BW=1235MiB/s (1295MB/s)(36.2GiB/30001msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=84.33%, sys=15.55%, ctx=435, majf=0, minf=1830
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=0,9486716,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
  WRITE: bw=1235MiB/s (1295MB/s), 1235MiB/s-1235MiB/s (1295MB/s-1295MB/s), io=36.2GiB (38.9GB), run=30001-30001msec

Disk stats (read/write):
  nvme1n1: ios=46/124114, merge=0/649518, ticks=13/1103254, in_queue=1103633, util=17.33%
  nvme2n1: ios=45/248082, merge=0/1159748, ticks=13/1898394, in_queue=1898907, util=32.64%
  nvme3n1: ios=52/269363, merge=0/863314, ticks=17/1883029, in_queue=1883176, util=30.16%
  nvme4n1: ios=45/376227, merge=0/845013, ticks=12/1943076, in_queue=1944513, util=32.36%
  nvme5n1: ios=47/273181, merge=0/1168847, ticks=14/1439836, in_queue=1440632, util=25.57%


    DEBUG: 2018/09/27 09:13:31 Running VERIFY IOs with SHA512 checksum : IO SIZE(4K), bs_unaligned
    DEBUG: 2018/09/27 09:13:31 VERIFY FIO Command : sudo /usr/local/bin/fio --ioengine=sync --iodepth=16 --verify=sha512 --group_reporting --disable_lat=1 --disable_clat=1 --disable_slat=1 --disable_bw_measurement=1 --rw=randread --do_verify=1 --verify_state_load=1 --verify_fatal=1 --verify_dump=1  --blocksize=4K  --blocksize_unaligned=1 --name=job1 --filename=/dev/nvme1n1 --name=job2 --filename=/dev/nvme2n1 --name=job3 --filename=/dev/nvme3n1 --name=job4 --filename=/dev/nvme4n1 --name=job5 --filename=/dev/nvme5n1

    DEBUG: 2018/09/27 09:19:46 output : job1: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job2: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job3: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job4: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
job5: (g=0): rw=randread, bs=4096B-4096B,4096B-4096B,4096B-4096B, ioengine=sync, iodepth=16
fio-2.18
Starting 5 processes
Jobs: 5 (f=5)Jobs: 5 (f=5)Jobs: 5 (f=5): [V(5)][0.8%][r=76.3MiB/s,w=0KiB/s][r=19.6k,w=0 IOPS][eta 05m:50s]Jobs: 5 (f=5): [V(5)][1.1%][r=72.9MiB/s,w=0KiB/s][r=18.7k,w=0 IOPS][eta 05m:49s]Jobs: 5 (f=5): [V(5)][1.7%][r=72.5MiB/s,w=0KiB/s][r=18.6k,w=0 IOPS][eta 05m:47s]Jobs: 5 (f=5): [V(5)][2.0%][r=71.1MiB/s,w=0KiB/s][r=18.5k,w=0 IOPS][eta 05m:47s]Jobs: 5 (f=5): [V(5)][2.3%][r=73.9MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 05m:46s]Jobs: 5 (f=5): [V(5)][2.5%][r=72.4MiB/s,w=0KiB/s][r=18.5k,w=0 IOPS][eta 05m:44s]Jobs: 5 (f=5): [V(5)][2.8%][r=74.3MiB/s,w=0KiB/s][r=19.2k,w=0 IOPS][eta 05m:43s]Jobs: 5 (f=5): [V(5)][3.1%][r=75.8MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 05m:40s]Jobs: 5 (f=5): [V(5)][3.4%][r=75.2MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 05m:38s]Jobs: 5 (f=5): [V(5)][3.7%][r=77.7MiB/s,w=0KiB/s][r=19.9k,w=0 IOPS][eta 05m:36s]Jobs: 5 (f=5): [V(5)][4.0%][r=75.7MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 05m:34s]Jobs: 5 (f=5): [V(5)][4.3%][r=74.7MiB/s,w=0KiB/s][r=19.2k,w=0 IOPS][eta 05m:33s]Jobs: 5 (f=5): [V(5)][4.6%][r=75.2MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 05m:31s]Jobs: 5 (f=5): [V(5)][4.9%][r=75.7MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 05m:30s]Jobs: 5 (f=5): [V(5)][5.2%][r=73.5MiB/s,w=0KiB/s][r=18.8k,w=0 IOPS][eta 05m:29s]Jobs: 5 (f=5): [V(5)][5.5%][r=76.2MiB/s,w=0KiB/s][r=19.6k,w=0 IOPS][eta 05m:27s]Jobs: 5 (f=5): [V(5)][5.8%][r=73.2MiB/s,w=0KiB/s][r=18.8k,w=0 IOPS][eta 05m:27s]Jobs: 5 (f=5): [V(5)][6.1%][r=74.2MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 05m:26s]Jobs: 5 (f=5): [V(5)][6.3%][r=73.9MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 05m:25s]Jobs: 5 (f=5): [V(5)][6.6%][r=75.5MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 05m:24s]Jobs: 5 (f=5): [V(5)][6.9%][r=75.2MiB/s,w=0KiB/s][r=19.5k,w=0 IOPS][eta 05m:23s]Jobs: 5 (f=5): [V(5)][7.2%][r=74.9MiB/s,w=0KiB/s][r=19.2k,w=0 IOPS][eta 05m:22s]Jobs: 5 (f=5): [V(5)][7.5%][r=72.2MiB/s,w=0KiB/s][r=18.7k,w=0 IOPS][eta 05m:21s]Jobs: 5 (f=5): [V(5)][7.8%][r=73.9MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 05m:20s]Jobs: 5 (f=5): [V(5)][8.1%][r=73.1MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 05m:19s]Jobs: 5 (f=5): [V(5)][8.4%][r=73.7MiB/s,w=0KiB/s][r=18.9k,w=0 IOPS][eta 05m:18s]Jobs: 5 (f=5): [V(5)][8.6%][r=73.6MiB/s,w=0KiB/s][r=18.9k,w=0 IOPS][eta 05m:18s]Jobs: 5 (f=5): [V(5)][8.9%][r=73.9MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 05m:17s]Jobs: 5 (f=5): [V(5)][9.2%][r=74.5MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 05m:16s]Jobs: 5 (f=5): [V(5)][9.5%][r=76.3MiB/s,w=0KiB/s][r=19.6k,w=0 IOPS][eta 05m:15s]Jobs: 5 (f=5): [V(5)][9.8%][r=76.2MiB/s,w=0KiB/s][r=19.5k,w=0 IOPS][eta 05m:14s]Jobs: 5 (f=5): [V(5)][10.1%][r=74.4MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 05m:13s]Jobs: 5 (f=5): [V(5)][10.3%][r=73.4MiB/s,w=0KiB/s][r=18.8k,w=0 IOPS][eta 05m:12s]Jobs: 5 (f=5): [V(5)][10.6%][r=74.1MiB/s,w=0KiB/s][r=19.2k,w=0 IOPS][eta 05m:11s]Jobs: 5 (f=5): [V(5)][10.9%][r=73.7MiB/s,w=0KiB/s][r=18.9k,w=0 IOPS][eta 05m:10s]Jobs: 5 (f=5): [V(5)][11.2%][r=73.7MiB/s,w=0KiB/s][r=18.9k,w=0 IOPS][eta 05m:09s]Jobs: 5 (f=5): [V(5)][11.5%][r=75.2MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 05m:08s]Jobs: 5 (f=5): [V(5)][11.8%][r=73.7MiB/s,w=0KiB/s][r=18.9k,w=0 IOPS][eta 05m:07s]Jobs: 5 (f=5): [V(5)][12.1%][r=73.8MiB/s,w=0KiB/s][r=18.9k,w=0 IOPS][eta 05m:06s]Jobs: 5 (f=5): [V(5)][12.4%][r=77.2MiB/s,w=0KiB/s][r=19.8k,w=0 IOPS][eta 05m:04s]Jobs: 5 (f=5): [V(5)][12.7%][r=77.5MiB/s,w=0KiB/s][r=19.9k,w=0 IOPS][eta 05m:03s]Jobs: 5 (f=5): [V(5)][13.0%][r=76.8MiB/s,w=0KiB/s][r=19.7k,w=0 IOPS][eta 05m:02s]Jobs: 5 (f=5): [V(5)][13.3%][r=76.7MiB/s,w=0KiB/s][r=19.7k,w=0 IOPS][eta 05m:01s]Jobs: 5 (f=5): [V(5)][13.5%][r=73.4MiB/s,w=0KiB/s][r=18.8k,w=0 IOPS][eta 05m:00s]Jobs: 5 (f=5): [V(5)][13.8%][r=74.4MiB/s,w=0KiB/s][r=19.5k,w=0 IOPS][eta 04m:59s]Jobs: 5 (f=5): [V(5)][14.1%][r=75.8MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 04m:58s]Jobs: 5 (f=5): [V(5)][14.4%][r=75.2MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 04m:57s]Jobs: 5 (f=5): [V(5)][14.7%][r=73.8MiB/s,w=0KiB/s][r=18.9k,w=0 IOPS][eta 04m:56s]Jobs: 5 (f=5): [V(5)][15.0%][r=74.5MiB/s,w=0KiB/s][r=19.7k,w=0 IOPS][eta 04m:55s]Jobs: 5 (f=5): [V(5)][15.3%][r=76.6MiB/s,w=0KiB/s][r=19.5k,w=0 IOPS][eta 04m:54s]Jobs: 5 (f=5): [V(5)][15.6%][r=75.3MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 04m:52s]Jobs: 5 (f=5): [V(5)][15.9%][r=73.4MiB/s,w=0KiB/s][r=18.8k,w=0 IOPS][eta 04m:52s]Jobs: 5 (f=5): [V(5)][16.1%][r=72.1MiB/s,w=0KiB/s][r=18.7k,w=0 IOPS][eta 04m:51s]Jobs: 5 (f=5): [V(5)][16.4%][r=75.4MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 04m:50s]Jobs: 5 (f=5): [V(5)][16.7%][r=74.4MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 04m:49s]Jobs: 5 (f=5): [V(5)][17.1%][r=75.6MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 04m:47s]Jobs: 5 (f=5): [V(5)][17.3%][r=76.4MiB/s,w=0KiB/s][r=19.6k,w=0 IOPS][eta 04m:46s]Jobs: 5 (f=5): [V(5)][17.6%][r=74.7MiB/s,w=0KiB/s][r=19.2k,w=0 IOPS][eta 04m:45s]Jobs: 5 (f=5): [V(5)][17.9%][r=75.8MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 04m:44s]Jobs: 5 (f=5): [V(5)][18.2%][r=75.4MiB/s,w=0KiB/s][r=19.3k,w=0 IOPS][eta 04m:43s]Jobs: 5 (f=5): [V(5)][18.5%][r=75.8MiB/s,w=0KiB/s][r=19.4k,w=0 IOPS][eta 04m:42s]Jobs: 5 (f=5): [V(5)][18.8%][r=73.1MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 04m:41s]Jobs: 5 (f=5): [V(5)][19.1%][r=73.2MiB/s,w=0KiB/s][r=18.8k,w=0 IOPS][eta 04m:40s]Jobs: 5 (f=5): [V(5)][19.4%][r=73.3MiB/s,w=0KiB/s][r=18.8k,w=0 IOPS][eta 04m:39s]Jobs: 5 (f=5): [V(5)][19.7%][r=73.8MiB/s,w=0KiB/s][r=18.8k,w=0 IOPS][eta 04m:38s]Jobs: 5 (f=5): [V(5)][19.9%][r=73.1MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 04m:37s]Jobs: 5 (f=5): [V(5)][20.2%][r=74.8MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 04m:36s]Jobs: 5 (f=5): [V(5)][20.5%][r=74.2MiB/s,w=0KiB/s][r=18.1k,w=0 IOPS][eta 04m:35s]Jobs: 4 (f=4): [_(1),V(4)][20.8%][r=70.2MiB/s,w=0KiB/s][r=17.1k,w=0 IOPS][eta 04m:34s]Jobs: 4 (f=4): [_(1),V(4)][21.0%][r=58.4MiB/s,w=0KiB/s][r=14.1k,w=0 IOPS][eta 04m:34s]Jobs: 4 (f=4): [_(1),V(4)][21.3%][r=58.9MiB/s,w=0KiB/s][r=15.7k,w=0 IOPS][eta 04m:33s]Jobs: 4 (f=4): [_(1),V(4)][21.6%][r=57.3MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 04m:32s]Jobs: 4 (f=4): [_(1),V(4)][21.9%][r=57.3MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 04m:31s]Jobs: 4 (f=4): [_(1),V(4)][22.2%][r=57.5MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 04m:30s]Jobs: 4 (f=4): [_(1),V(4)][22.4%][r=57.2MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 04m:30s]Jobs: 4 (f=4): [_(1),V(4)][22.7%][r=57.1MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:29s]Jobs: 4 (f=4): [_(1),V(4)][23.0%][r=56.1MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 04m:28s]Jobs: 4 (f=4): [_(1),V(4)][23.3%][r=59.7MiB/s,w=0KiB/s][r=15.2k,w=0 IOPS][eta 04m:27s]Jobs: 4 (f=4): [_(1),V(4)][23.6%][r=58.1MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:26s]Jobs: 4 (f=4): [_(1),V(4)][23.9%][r=61.3MiB/s,w=0KiB/s][r=15.7k,w=0 IOPS][eta 04m:25s]Jobs: 4 (f=4): [_(1),V(4)][24.1%][r=62.2MiB/s,w=0KiB/s][r=15.1k,w=0 IOPS][eta 04m:24s]Jobs: 4 (f=4): [_(1),V(4)][24.4%][r=58.2MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:23s]Jobs: 4 (f=4): [_(1),V(4)][24.7%][r=57.1MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:22s]Jobs: 4 (f=4): [_(1),V(4)][25.0%][r=58.4MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:21s]Jobs: 4 (f=4): [_(1),V(4)][25.3%][r=58.8MiB/s,w=0KiB/s][r=15.3k,w=0 IOPS][eta 04m:20s]Jobs: 4 (f=4): [_(1),V(4)][25.6%][r=58.4MiB/s,w=0KiB/s][r=14.1k,w=0 IOPS][eta 04m:19s]Jobs: 4 (f=4): [_(1),V(4)][25.9%][r=58.3MiB/s,w=0KiB/s][r=14.1k,w=0 IOPS][eta 04m:18s]Jobs: 4 (f=4): [_(1),V(4)][26.1%][r=57.5MiB/s,w=0KiB/s][r=14.8k,w=0 IOPS][eta 04m:17s]Jobs: 4 (f=4): [_(1),V(4)][26.4%][r=56.8MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 04m:17s]Jobs: 4 (f=4): [_(1),V(4)][26.7%][r=60.5MiB/s,w=0KiB/s][r=15.5k,w=0 IOPS][eta 04m:15s]Jobs: 4 (f=4): [_(1),V(4)][27.0%][r=61.4MiB/s,w=0KiB/s][r=15.8k,w=0 IOPS][eta 04m:14s]Jobs: 4 (f=4): [_(1),V(4)][27.3%][r=57.1MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:13s]Jobs: 4 (f=4): [_(1),V(4)][27.6%][r=57.3MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 04m:12s]Jobs: 4 (f=4): [_(1),V(4)][27.8%][r=57.5MiB/s,w=0KiB/s][r=14.8k,w=0 IOPS][eta 04m:12s]Jobs: 4 (f=4): [_(1),V(4)][28.1%][r=57.3MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 04m:11s]Jobs: 4 (f=4): [_(1),V(4)][28.4%][r=57.5MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 04m:10s]Jobs: 4 (f=4): [_(1),V(4)][28.7%][r=57.2MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:09s]Jobs: 4 (f=4): [_(1),V(4)][28.9%][r=57.8MiB/s,w=0KiB/s][r=14.8k,w=0 IOPS][eta 04m:08s]Jobs: 4 (f=4): [_(1),V(4)][29.2%][r=56.6MiB/s,w=0KiB/s][r=14.5k,w=0 IOPS][eta 04m:07s]Jobs: 4 (f=4): [_(1),V(4)][29.5%][r=59.5MiB/s,w=0KiB/s][r=15.3k,w=0 IOPS][eta 04m:06s]Jobs: 4 (f=4): [_(1),V(4)][29.8%][r=59.5MiB/s,w=0KiB/s][r=15.3k,w=0 IOPS][eta 04m:05s]Jobs: 4 (f=4): [_(1),V(4)][30.1%][r=58.5MiB/s,w=0KiB/s][r=14.1k,w=0 IOPS][eta 04m:04s]Jobs: 4 (f=4): [_(1),V(4)][30.4%][r=58.8MiB/s,w=0KiB/s][r=15.5k,w=0 IOPS][eta 04m:03s]Jobs: 4 (f=4): [_(1),V(4)][30.7%][r=57.1MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:02s]Jobs: 4 (f=4): [_(1),V(4)][30.9%][r=58.2MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 04m:01s]Jobs: 4 (f=4): [_(1),V(4)][31.2%][r=58.3MiB/s,w=0KiB/s][r=14.1k,w=0 IOPS][eta 04m:00s]Jobs: 4 (f=4): [_(1),V(4)][31.5%][r=58.9MiB/s,w=0KiB/s][r=15.5k,w=0 IOPS][eta 03m:59s]Jobs: 4 (f=4): [_(1),V(4)][31.8%][r=57.3MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:58s]Jobs: 4 (f=4): [_(1),V(4)][32.0%][r=56.1MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 03m:58s]Jobs: 4 (f=4): [_(1),V(4)][32.3%][r=59.5MiB/s,w=0KiB/s][r=15.3k,w=0 IOPS][eta 03m:57s]Jobs: 4 (f=4): [_(1),V(4)][32.7%][r=61.3MiB/s,w=0KiB/s][r=15.7k,w=0 IOPS][eta 03m:55s]Jobs: 4 (f=4): [_(1),V(4)][33.0%][r=59.3MiB/s,w=0KiB/s][r=15.2k,w=0 IOPS][eta 03m:54s]Jobs: 4 (f=4): [_(1),V(4)][33.2%][r=56.1MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 03m:53s]Jobs: 4 (f=4): [_(1),V(4)][33.4%][r=57.5MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:53s]Jobs: 4 (f=4): [_(1),V(4)][33.7%][r=57.7MiB/s,w=0KiB/s][r=14.8k,w=0 IOPS][eta 03m:52s]Jobs: 4 (f=4): [_(1),V(4)][34.0%][r=57.9MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 03m:51s]Jobs: 4 (f=4): [_(1),V(4)][34.3%][r=56.1MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 03m:50s]Jobs: 4 (f=4): [_(1),V(4)][34.6%][r=57.2MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:49s]Jobs: 4 (f=4): [_(1),V(4)][34.9%][r=57.3MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 03m:48s]Jobs: 4 (f=4): [_(1),V(4)][35.1%][r=58.3MiB/s,w=0KiB/s][r=14.1k,w=0 IOPS][eta 03m:47s]Jobs: 4 (f=4): [_(1),V(4)][35.4%][r=58.9MiB/s,w=0KiB/s][r=15.7k,w=0 IOPS][eta 03m:46s]Jobs: 4 (f=4): [_(1),V(4)][35.7%][r=57.3MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:45s]Jobs: 4 (f=4): [_(1),V(4)][36.0%][r=56.1MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 03m:44s]Jobs: 4 (f=4): [_(1),V(4)][36.3%][r=57.2MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:43s]Jobs: 4 (f=4): [_(1),V(4)][36.6%][r=57.4MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:42s]Jobs: 4 (f=4): [_(1),V(4)][36.9%][r=57.6MiB/s,w=0KiB/s][r=14.8k,w=0 IOPS][eta 03m:41s]Jobs: 4 (f=4): [_(1),V(4)][37.1%][r=57.6MiB/s,w=0KiB/s][r=14.8k,w=0 IOPS][eta 03m:40s]Jobs: 4 (f=4): [_(1),V(4)][37.3%][r=57.1MiB/s,w=0KiB/s][r=14.9k,w=0 IOPS][eta 03m:40s]Jobs: 4 (f=4): [_(1),V(4)][37.6%][r=57.3MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:39s]Jobs: 4 (f=4): [_(1),V(4)][37.9%][r=58.7MiB/s,w=0KiB/s][r=15.8k,w=0 IOPS][eta 03m:38s]Jobs: 4 (f=4): [_(1),V(4)][38.2%][r=58.9MiB/s,w=0KiB/s][r=15.7k,w=0 IOPS][eta 03m:37s]Jobs: 4 (f=4): [_(1),V(4)][38.5%][r=57.0MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 03m:36s]Jobs: 4 (f=4): [_(1),V(4)][38.7%][r=56.1MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 03m:35s]Jobs: 4 (f=4): [_(1),V(4)][39.0%][r=57.4MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:34s]Jobs: 4 (f=4): [_(1),V(4)][39.3%][r=56.1MiB/s,w=0KiB/s][r=14.6k,w=0 IOPS][eta 03m:33s]Jobs: 4 (f=4): [_(1),V(4)][39.6%][r=57.4MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:32s]Jobs: 4 (f=4): [_(1),V(4)][39.9%][r=56.3MiB/s,w=0KiB/s][r=14.5k,w=0 IOPS][eta 03m:31s]Jobs: 4 (f=4): [_(1),V(4)][40.2%][r=57.3MiB/s,w=0KiB/s][r=14.7k,w=0 IOPS][eta 03m:30s]Jobs: 3 (f=3): [_(2),V(3)][40.5%][r=46.5MiB/s,w=0KiB/s][r=11.9k,w=0 IOPS][eta 03m:29s]Jobs: 3 (f=3): [_(2),V(3)][40.7%][r=44.5MiB/s,w=0KiB/s][r=11.4k,w=0 IOPS][eta 03m:28s]Jobs: 3 (f=3): [_(2),V(3)][41.0%][r=44.5MiB/s,w=0KiB/s][r=11.4k,w=0 IOPS][eta 03m:27s]Jobs: 3 (f=3): [_(2),V(3)][41.3%][r=41.4MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:26s]Jobs: 3 (f=3): [_(2),V(3)][41.6%][r=41.5MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 03m:25s]Jobs: 3 (f=3): [_(2),V(3)][41.9%][r=41.5MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 03m:24s]Jobs: 3 (f=3): [_(2),V(3)][42.0%][r=41.2MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:24s]Jobs: 3 (f=3): [_(2),V(3)][42.3%][r=40.9MiB/s,w=0KiB/s][r=10.5k,w=0 IOPS][eta 03m:23s]Jobs: 3 (f=3): [_(2),V(3)][42.6%][r=40.2MiB/s,w=0KiB/s][r=10.5k,w=0 IOPS][eta 03m:22s]Jobs: 3 (f=3): [_(2),V(3)][42.9%][r=41.3MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:21s]Jobs: 3 (f=3): [_(2),V(3)][43.2%][r=41.7MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:20s]Jobs: 3 (f=3): [_(2),V(3)][43.5%][r=42.3MiB/s,w=0KiB/s][r=10.9k,w=0 IOPS][eta 03m:19s]Jobs: 3 (f=3): [_(2),V(3)][43.6%][r=43.3MiB/s,w=0KiB/s][r=11.7k,w=0 IOPS][eta 03m:19s]Jobs: 3 (f=3): [_(2),V(3)][43.9%][r=41.5MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 03m:18s]Jobs: 3 (f=3): [_(2),V(3)][44.2%][r=41.4MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:17s]Jobs: 3 (f=3): [_(2),V(3)][44.5%][r=40.9MiB/s,w=0KiB/s][r=10.5k,w=0 IOPS][eta 03m:16s]Jobs: 3 (f=3): [_(2),V(3)][44.8%][r=41.5MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:15s]Jobs: 3 (f=3): [_(2),V(3)][45.0%][r=40.2MiB/s,w=0KiB/s][r=10.5k,w=0 IOPS][eta 03m:14s]Jobs: 3 (f=3): [_(2),V(3)][45.3%][r=41.2MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:13s]Jobs: 3 (f=3): [_(2),V(3)][45.5%][r=41.8MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 03m:13s]Jobs: 3 (f=3): [_(2),V(3)][45.8%][r=41.4MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:12s]Jobs: 3 (f=3): [_(2),V(3)][46.0%][r=43.5MiB/s,w=0KiB/s][r=11.2k,w=0 IOPS][eta 03m:11s]Jobs: 3 (f=3): [_(2),V(3)][46.3%][r=43.8MiB/s,w=0KiB/s][r=11.2k,w=0 IOPS][eta 03m:10s]Jobs: 3 (f=3): [_(2),V(3)][46.6%][r=40.7MiB/s,w=0KiB/s][r=10.5k,w=0 IOPS][eta 03m:09s]Jobs: 3 (f=3): [_(2),V(3)][46.9%][r=40.1MiB/s,w=0KiB/s][r=10.5k,w=0 IOPS][eta 03m:08s]Jobs: 3 (f=3): [_(2),V(3)][47.0%][r=41.3MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:08s]Jobs: 3 (f=3): [_(2),V(3)][47.3%][r=41.6MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:07s]Jobs: 3 (f=3): [_(2),V(3)][47.6%][r=40.7MiB/s,w=0KiB/s][r=10.5k,w=0 IOPS][eta 03m:06s]Jobs: 3 (f=3): [_(2),V(3)][47.9%][r=41.4MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:05s]Jobs: 3 (f=3): [_(2),V(3)][48.2%][r=41.2MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 03m:04s]Jobs: 3 (f=3): [_(2),V(3)][48.5%][r=42.1MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 03m:03s]Jobs: 3 (f=3): [_(2),V(3)][48.7%][r=42.9MiB/s,w=0KiB/s][r=10.1k,w=0 IOPS][eta 03m:02s]Jobs: 3 (f=3): [_(2),V(3)][49.0%][r=43.6MiB/s,w=0KiB/s][r=11.2k,w=0 IOPS][eta 03m:01s]Jobs: 3 (f=3): [_(2),V(3)][49.3%][r=42.4MiB/s,w=0KiB/s][r=10.9k,w=0 IOPS][eta 03m:00s]Jobs: 3 (f=3): [_(2),V(3)][49.6%][r=42.8MiB/s,w=0KiB/s][r=10.1k,w=0 IOPS][eta 02m:59s]Jobs: 3 (f=3): [_(2),V(3)][49.7%][r=42.7MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 02m:59s]Jobs: 3 (f=3): [_(2),V(3)][50.0%][r=42.2MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 02m:58s]Jobs: 3 (f=3): [_(2),V(3)][50.3%][r=41.1MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 02m:57s]Jobs: 3 (f=3): [_(2),V(3)][50.6%][r=41.8MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 02m:56s]Jobs: 3 (f=3): [_(2),V(3)][50.8%][r=42.4MiB/s,w=0KiB/s][r=10.9k,w=0 IOPS][eta 02m:55s]Jobs: 3 (f=3): [_(2),V(3)][51.1%][r=41.1MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 02m:54s]Jobs: 3 (f=3): [_(2),V(3)][51.4%][r=43.5MiB/s,w=0KiB/s][r=11.2k,w=0 IOPS][eta 02m:53s]Jobs: 3 (f=3): [_(2),V(3)][51.7%][r=45.3MiB/s,w=0KiB/s][r=11.6k,w=0 IOPS][eta 02m:52s]Jobs: 3 (f=3): [_(2),V(3)][52.0%][r=42.8MiB/s,w=0KiB/s][r=10.1k,w=0 IOPS][eta 02m:51s]Jobs: 3 (f=3): [_(2),V(3)][52.2%][r=42.3MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 02m:50s]Jobs: 3 (f=3): [_(2),V(3)][52.5%][r=42.1MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 02m:49s]Jobs: 3 (f=3): [_(2),V(3)][52.8%][r=42.6MiB/s,w=0KiB/s][r=10.9k,w=0 IOPS][eta 02m:48s]Jobs: 3 (f=3): [_(2),V(3)][53.1%][r=41.9MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 02m:47s]Jobs: 3 (f=3): [_(2),V(3)][53.4%][r=41.4MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:46s]Jobs: 3 (f=3): [_(2),V(3)][53.7%][r=41.9MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 02m:45s]Jobs: 3 (f=3): [_(2),V(3)][53.9%][r=41.3MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:44s]Jobs: 3 (f=3): [_(2),V(3)][54.2%][r=42.9MiB/s,w=0KiB/s][r=10.1k,w=0 IOPS][eta 02m:43s]Jobs: 3 (f=3): [_(2),V(3)][54.5%][r=43.3MiB/s,w=0KiB/s][r=11.2k,w=0 IOPS][eta 02m:42s]Jobs: 3 (f=3): [_(2),V(3)][54.6%][r=41.5MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 02m:42s]Jobs: 3 (f=3): [_(2),V(3)][54.9%][r=41.3MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:41s]Jobs: 3 (f=3): [_(2),V(3)][55.2%][r=41.3MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:40s]Jobs: 3 (f=3): [_(2),V(3)][55.5%][r=41.4MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:39s]Jobs: 3 (f=3): [_(2),V(3)][55.7%][r=41.3MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:38s]Jobs: 3 (f=3): [_(2),V(3)][56.0%][r=42.3MiB/s,w=0KiB/s][r=10.9k,w=0 IOPS][eta 02m:37s]Jobs: 3 (f=3): [_(2),V(3)][56.3%][r=40.2MiB/s,w=0KiB/s][r=10.5k,w=0 IOPS][eta 02m:36s]Jobs: 3 (f=3): [_(2),V(3)][56.6%][r=41.6MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 02m:35s]Jobs: 3 (f=3): [_(2),V(3)][56.9%][r=42.1MiB/s,w=0KiB/s][r=10.1k,w=0 IOPS][eta 02m:34s]Jobs: 3 (f=3): [_(2),V(3)][57.1%][r=44.1MiB/s,w=0KiB/s][r=11.3k,w=0 IOPS][eta 02m:33s]Jobs: 3 (f=3): [_(2),V(3)][57.4%][r=41.2MiB/s,w=0KiB/s][r=10.8k,w=0 IOPS][eta 02m:32s]Jobs: 3 (f=3): [_(2),V(3)][57.7%][r=41.2MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:31s]Jobs: 3 (f=3): [_(2),V(3)][57.8%][r=41.6MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 02m:31s]Jobs: 3 (f=3): [_(2),V(3)][58.1%][r=41.4MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:30s]Jobs: 3 (f=3): [_(2),V(3)][58.4%][r=41.3MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:29s]Jobs: 3 (f=3): [_(2),V(3)][58.7%][r=41.3MiB/s,w=0KiB/s][r=10.6k,w=0 IOPS][eta 02m:28s]Jobs: 3 (f=3): [_(2),V(3)][58.9%][r=42.3MiB/s,w=0KiB/s][r=10.9k,w=0 IOPS][eta 02m:27s]Jobs: 3 (f=3): [_(2),V(3)][59.2%][r=41.5MiB/s,w=0KiB/s][r=10.7k,w=0 IOPS][eta 02m:26s]Jobs: 3 (f=3): [_(2),V(3)][59.5%][r=44.2MiB/s,w=0KiB/s][r=11.6k,w=0 IOPS][eta 02m:25s]Jobs: 3 (f=3): [_(2),V(3)][59.8%][r=46.8MiB/s,w=0KiB/s][r=11.8k,w=0 IOPS][eta 02m:24s]Jobs: 3 (f=3): [_(2),V(3)][60.1%][r=35.6MiB/s,w=0KiB/s][r=9086,w=0 IOPS][eta 02m:23s] Jobs: 2 (f=2): [_(3),V(2)][60.3%][r=27.3MiB/s,w=0KiB/s][r=6982,w=0 IOPS][eta 02m:22s]Jobs: 2 (f=2): [_(3),V(2)][60.6%][r=26.3MiB/s,w=0KiB/s][r=6714,w=0 IOPS][eta 02m:21s]Jobs: 2 (f=2): [_(3),V(2)][60.9%][r=26.3MiB/s,w=0KiB/s][r=6720,w=0 IOPS][eta 02m:20s]Jobs: 2 (f=2): [_(3),V(2)][61.2%][r=26.4MiB/s,w=0KiB/s][r=6747,w=0 IOPS][eta 02m:19s]Jobs: 2 (f=2): [_(3),V(2)][61.3%][r=26.3MiB/s,w=0KiB/s][r=6725,w=0 IOPS][eta 02m:19s]Jobs: 2 (f=2): [_(3),V(2)][61.6%][r=26.2MiB/s,w=0KiB/s][r=6694,w=0 IOPS][eta 02m:18s]Jobs: 2 (f=2): [_(3),V(2)][61.8%][r=26.4MiB/s,w=0KiB/s][r=6739,w=0 IOPS][eta 02m:17s]Jobs: 2 (f=2): [_(3),V(2)][62.1%][r=29.2MiB/s,w=0KiB/s][r=7455,w=0 IOPS][eta 02m:16s]Jobs: 2 (f=2): [_(3),V(2)][62.4%][r=29.9MiB/s,w=0KiB/s][r=7637,w=0 IOPS][eta 02m:15s]Jobs: 2 (f=2): [_(3),V(2)][62.7%][r=27.4MiB/s,w=0KiB/s][r=6988,w=0 IOPS][eta 02m:14s]Jobs: 2 (f=2): [_(3),V(2)][63.0%][r=26.4MiB/s,w=0KiB/s][r=6751,w=0 IOPS][eta 02m:13s]Jobs: 2 (f=2): [_(3),V(2)][63.2%][r=26.8MiB/s,w=0KiB/s][r=6847,w=0 IOPS][eta 02m:12s]Jobs: 2 (f=2): [_(3),V(2)][63.5%][r=26.5MiB/s,w=0KiB/s][r=6760,w=0 IOPS][eta 02m:11s]Jobs: 2 (f=2): [_(3),V(2)][63.6%][r=26.7MiB/s,w=0KiB/s][r=6826,w=0 IOPS][eta 02m:11s]Jobs: 2 (f=2): [_(3),V(2)][63.9%][r=26.5MiB/s,w=0KiB/s][r=6758,w=0 IOPS][eta 02m:10s]Jobs: 2 (f=2): [_(3),V(2)][64.2%][r=26.3MiB/s,w=0KiB/s][r=6710,w=0 IOPS][eta 02m:09s]Jobs: 2 (f=2): [_(3),V(2)][64.4%][r=26.4MiB/s,w=0KiB/s][r=6742,w=0 IOPS][eta 02m:08s]Jobs: 2 (f=2): [_(3),V(2)][64.7%][r=30.2MiB/s,w=0KiB/s][r=7707,w=0 IOPS][eta 02m:07s]Jobs: 2 (f=2): [_(3),V(2)][65.0%][r=29.2MiB/s,w=0KiB/s][r=7461,w=0 IOPS][eta 02m:06s]Jobs: 2 (f=2): [_(3),V(2)][65.3%][r=26.6MiB/s,w=0KiB/s][r=6793,w=0 IOPS][eta 02m:05s]Jobs: 2 (f=2): [_(3),V(2)][65.6%][r=26.4MiB/s,w=0KiB/s][r=6749,w=0 IOPS][eta 02m:04s]Jobs: 2 (f=2): [_(3),V(2)][65.7%][r=26.7MiB/s,w=0KiB/s][r=6811,w=0 IOPS][eta 02m:04s]Jobs: 2 (f=2): [_(3),V(2)][65.9%][r=26.3MiB/s,w=0KiB/s][r=6725,w=0 IOPS][eta 02m:03s]Jobs: 2 (f=2): [_(3),V(2)][66.2%][r=26.6MiB/s,w=0KiB/s][r=6803,w=0 IOPS][eta 02m:02s]Jobs: 2 (f=2): [_(3),V(2)][66.5%][r=26.4MiB/s,w=0KiB/s][r=6746,w=0 IOPS][eta 02m:01s]Jobs: 2 (f=2): [_(3),V(2)][66.8%][r=26.6MiB/s,w=0KiB/s][r=6792,w=0 IOPS][eta 02m:00s]Jobs: 2 (f=2): [_(3),V(2)][67.0%][r=26.5MiB/s,w=0KiB/s][r=6764,w=0 IOPS][eta 01m:59s]Jobs: 2 (f=2): [_(3),V(2)][67.3%][r=29.4MiB/s,w=0KiB/s][r=7523,w=0 IOPS][eta 01m:58s]Jobs: 2 (f=2): [_(3),V(2)][67.6%][r=30.2MiB/s,w=0KiB/s][r=7706,w=0 IOPS][eta 01m:57s]Jobs: 2 (f=2): [_(3),V(2)][67.9%][r=26.2MiB/s,w=0KiB/s][r=6702,w=0 IOPS][eta 01m:56s]Jobs: 2 (f=2): [_(3),V(2)][68.1%][r=26.4MiB/s,w=0KiB/s][r=6739,w=0 IOPS][eta 01m:55s]Jobs: 2 (f=2): [_(3),V(2)][68.2%][r=26.6MiB/s,w=0KiB/s][r=6792,w=0 IOPS][eta 01m:55s]Jobs: 2 (f=2): [_(3),V(2)][68.5%][r=26.4MiB/s,w=0KiB/s][r=6745,w=0 IOPS][eta 01m:54s]Jobs: 2 (f=2): [_(3),V(2)][68.8%][r=26.6MiB/s,w=0KiB/s][r=6670,w=0 IOPS][eta 01m:53s]Jobs: 2 (f=2): [_(3),V(2)][69.1%][r=26.3MiB/s,w=0KiB/s][r=6731,w=0 IOPS][eta 01m:52s]Jobs: 2 (f=2): [_(3),V(2)][69.3%][r=26.4MiB/s,w=0KiB/s][r=6756,w=0 IOPS][eta 01m:51s]Jobs: 2 (f=2): [_(3),V(2)][69.6%][r=26.5MiB/s,w=0KiB/s][r=6774,w=0 IOPS][eta 01m:50s]Jobs: 2 (f=2): [_(3),V(2)][69.9%][r=29.1MiB/s,w=0KiB/s][r=7674,w=0 IOPS][eta 01m:49s]Jobs: 2 (f=2): [_(3),V(2)][70.2%][r=29.6MiB/s,w=0KiB/s][r=7551,w=0 IOPS][eta 01m:48s]Jobs: 2 (f=2): [_(3),V(2)][70.4%][r=27.1MiB/s,w=0KiB/s][r=7147,w=0 IOPS][eta 01m:47s]Jobs: 2 (f=2): [_(3),V(2)][70.7%][r=27.4MiB/s,w=0KiB/s][r=7002,w=0 IOPS][eta 01m:46s]Jobs: 2 (f=2): [_(3),V(2)][71.0%][r=26.6MiB/s,w=0KiB/s][r=6805,w=0 IOPS][eta 01m:45s]Jobs: 2 (f=2): [_(3),V(2)][71.3%][r=26.8MiB/s,w=0KiB/s][r=6846,w=0 IOPS][eta 01m:44s]Jobs: 2 (f=2): [_(3),V(2)][71.5%][r=26.5MiB/s,w=0KiB/s][r=6772,w=0 IOPS][eta 01m:43s]Jobs: 2 (f=2): [_(3),V(2)][71.6%][r=26.4MiB/s,w=0KiB/s][r=6747,w=0 IOPS][eta 01m:43s]Jobs: 2 (f=2): [_(3),V(2)][71.9%][r=26.3MiB/s,w=0KiB/s][r=6710,w=0 IOPS][eta 01m:42s]Jobs: 2 (f=2): [_(3),V(2)][72.2%][r=26.2MiB/s,w=0KiB/s][r=6682,w=0 IOPS][eta 01m:41s]Jobs: 2 (f=2): [_(3),V(2)][72.5%][r=29.2MiB/s,w=0KiB/s][r=7678,w=0 IOPS][eta 01m:40s]Jobs: 2 (f=2): [_(3),V(2)][72.7%][r=29.6MiB/s,w=0KiB/s][r=7556,w=0 IOPS][eta 01m:39s]Jobs: 2 (f=2): [_(3),V(2)][73.0%][r=27.1MiB/s,w=0KiB/s][r=7160,w=0 IOPS][eta 01m:38s]Jobs: 2 (f=2): [_(3),V(2)][73.3%][r=26.6MiB/s,w=0KiB/s][r=6785,w=0 IOPS][eta 01m:37s]Jobs: 2 (f=2): [_(3),V(2)][73.6%][r=26.6MiB/s,w=0KiB/s][r=6783,w=0 IOPS][eta 01m:36s]Jobs: 2 (f=2): [_(3),V(2)][73.8%][r=26.4MiB/s,w=0KiB/s][r=6736,w=0 IOPS][eta 01m:35s]Jobs: 2 (f=2): [_(3),V(2)][74.1%][r=26.5MiB/s,w=0KiB/s][r=6764,w=0 IOPS][eta 01m:34s]Jobs: 2 (f=2): [_(3),V(2)][74.4%][r=26.4MiB/s,w=0KiB/s][r=6733,w=0 IOPS][eta 01m:33s]Jobs: 2 (f=2): [_(3),V(2)][74.5%][r=26.5MiB/s,w=0KiB/s][r=6757,w=0 IOPS][eta 01m:33s]Jobs: 2 (f=2): [_(3),V(2)][74.7%][r=26.5MiB/s,w=0KiB/s][r=6772,w=0 IOPS][eta 01m:32s]Jobs: 2 (f=2): [_(3),V(2)][75.0%][r=27.9MiB/s,w=0KiB/s][r=7115,w=0 IOPS][eta 01m:31s]Jobs: 2 (f=2): [_(3),V(2)][75.3%][r=29.3MiB/s,w=0KiB/s][r=7488,w=0 IOPS][eta 01m:30s]Jobs: 2 (f=2): [_(3),V(2)][75.5%][r=26.5MiB/s,w=0KiB/s][r=6776,w=0 IOPS][eta 01m:29s]Jobs: 2 (f=2): [_(3),V(2)][75.8%][r=26.4MiB/s,w=0KiB/s][r=6755,w=0 IOPS][eta 01m:28s]Jobs: 2 (f=2): [_(3),V(2)][76.1%][r=26.2MiB/s,w=0KiB/s][r=6693,w=0 IOPS][eta 01m:27s]Jobs: 2 (f=2): [_(3),V(2)][76.4%][r=26.4MiB/s,w=0KiB/s][r=6740,w=0 IOPS][eta 01m:26s]Jobs: 2 (f=2): [_(3),V(2)][76.4%][r=26.4MiB/s,w=0KiB/s][r=6756,w=0 IOPS][eta 01m:26s]Jobs: 2 (f=2): [_(3),V(2)][76.7%][r=26.7MiB/s,w=0KiB/s][r=6812,w=0 IOPS][eta 01m:25s]Jobs: 2 (f=2): [_(3),V(2)][77.0%][r=26.5MiB/s,w=0KiB/s][r=6771,w=0 IOPS][eta 01m:24s]Jobs: 2 (f=2): [_(3),V(2)][77.3%][r=26.8MiB/s,w=0KiB/s][r=6834,w=0 IOPS][eta 01m:23s]Jobs: 2 (f=2): [_(3),V(2)][77.5%][r=27.2MiB/s,w=0KiB/s][r=6950,w=0 IOPS][eta 01m:22s]Jobs: 2 (f=2): [_(3),V(2)][77.8%][r=27.3MiB/s,w=0KiB/s][r=6973,w=0 IOPS][eta 01m:21s]Jobs: 2 (f=2): [_(3),V(2)][78.1%][r=26.5MiB/s,w=0KiB/s][r=6768,w=0 IOPS][eta 01m:20s]Jobs: 2 (f=2): [_(3),V(2)][78.4%][r=26.4MiB/s,w=0KiB/s][r=6736,w=0 IOPS][eta 01m:19s]Jobs: 2 (f=2): [_(3),V(2)][78.4%][r=26.5MiB/s,w=0KiB/s][r=6778,w=0 IOPS][eta 01m:19s]Jobs: 1 (f=1): [_(4),V(1)][78.7%][r=13.4MiB/s,w=0KiB/s][r=3407,w=0 IOPS][eta 01m:18s]Jobs: 1 (f=1): [_(4),V(1)][79.0%][r=11.1MiB/s,w=0KiB/s][r=3063,w=0 IOPS][eta 01m:17s]Jobs: 1 (f=1): [_(4),V(1)][79.2%][r=12.3MiB/s,w=0KiB/s][r=3079,w=0 IOPS][eta 01m:16s]Jobs: 1 (f=1): [_(4),V(1)][79.5%][r=12.2MiB/s,w=0KiB/s][r=3099,w=0 IOPS][eta 01m:15s]Jobs: 1 (f=1): [_(4),V(1)][79.8%][r=12.2MiB/s,w=0KiB/s][r=3115,w=0 IOPS][eta 01m:14s]Jobs: 1 (f=1): [_(4),V(1)][79.8%][r=12.2MiB/s,w=0KiB/s][r=3122,w=0 IOPS][eta 01m:14s]Jobs: 1 (f=1): [_(4),V(1)][80.1%][r=13.5MiB/s,w=0KiB/s][r=3431,w=0 IOPS][eta 01m:13s]Jobs: 1 (f=1): [_(4),V(1)][80.4%][r=13.3MiB/s,w=0KiB/s][r=3396,w=0 IOPS][eta 01m:12s]Jobs: 1 (f=1): [_(4),V(1)][80.7%][r=13.3MiB/s,w=0KiB/s][r=3402,w=0 IOPS][eta 01m:11s]Jobs: 1 (f=1): [_(4),V(1)][80.9%][r=13.4MiB/s,w=0KiB/s][r=3409,w=0 IOPS][eta 01m:10s]Jobs: 1 (f=1): [_(4),V(1)][81.2%][r=13.4MiB/s,w=0KiB/s][r=3409,w=0 IOPS][eta 01m:09s]Jobs: 1 (f=1): [_(4),V(1)][81.5%][r=13.3MiB/s,w=0KiB/s][r=3395,w=0 IOPS][eta 01m:08s]Jobs: 1 (f=1): [_(4),V(1)][81.7%][r=11.2MiB/s,w=0KiB/s][r=3070,w=0 IOPS][eta 01m:07s]Jobs: 1 (f=1): [_(4),V(1)][82.0%][r=11.1MiB/s,w=0KiB/s][r=3057,w=0 IOPS][eta 01m:06s]Jobs: 1 (f=1): [_(4),V(1)][82.3%][r=12.3MiB/s,w=0KiB/s][r=3079,w=0 IOPS][eta 01m:05s]Jobs: 1 (f=1): [_(4),V(1)][82.6%][r=14.9MiB/s,w=0KiB/s][r=3798,w=0 IOPS][eta 01m:04s]Jobs: 1 (f=1): [_(4),V(1)][82.8%][r=15.7MiB/s,w=0KiB/s][r=3997,w=0 IOPS][eta 01m:03s]Jobs: 1 (f=1): [_(4),V(1)][83.1%][r=12.3MiB/s,w=0KiB/s][r=3078,w=0 IOPS][eta 01m:02s]Jobs: 1 (f=1): [_(4),V(1)][83.2%][r=12.9MiB/s,w=0KiB/s][r=3094,w=0 IOPS][eta 01m:02s]Jobs: 1 (f=1): [_(4),V(1)][83.4%][r=12.2MiB/s,w=0KiB/s][r=3102,w=0 IOPS][eta 01m:01s]Jobs: 1 (f=1): [_(4),V(1)][83.7%][r=12.2MiB/s,w=0KiB/s][r=3118,w=0 IOPS][eta 01m:00s]Jobs: 1 (f=1): [_(4),V(1)][84.0%][r=11.1MiB/s,w=0KiB/s][r=3056,w=0 IOPS][eta 00m:59s]Jobs: 1 (f=1): [_(4),V(1)][84.2%][r=12.3MiB/s,w=0KiB/s][r=3128,w=0 IOPS][eta 00m:58s]Jobs: 1 (f=1): [_(4),V(1)][84.5%][r=12.3MiB/s,w=0KiB/s][r=3131,w=0 IOPS][eta 00m:57s]Jobs: 1 (f=1): [_(4),V(1)][84.6%][r=12.2MiB/s,w=0KiB/s][r=3115,w=0 IOPS][eta 00m:57s]Jobs: 1 (f=1): [_(4),V(1)][85.1%][r=15.5MiB/s,w=0KiB/s][r=3961,w=0 IOPS][eta 00m:55s]Jobs: 1 (f=1): [_(4),V(1)][85.3%][r=15.9MiB/s,w=0KiB/s][r=4044,w=0 IOPS][eta 00m:54s]Jobs: 1 (f=1): [_(4),V(1)][85.6%][r=12.2MiB/s,w=0KiB/s][r=3120,w=0 IOPS][eta 00m:53s]Jobs: 1 (f=1): [_(4),V(1)][85.6%][r=12.2MiB/s,w=0KiB/s][r=3122,w=0 IOPS][eta 00m:53s]Jobs: 1 (f=1): [_(4),V(1)][85.9%][r=12.4MiB/s,w=0KiB/s][r=3082,w=0 IOPS][eta 00m:52s]Jobs: 1 (f=1): [_(4),V(1)][86.2%][r=12.5MiB/s,w=0KiB/s][r=3084,w=0 IOPS][eta 00m:51s]Jobs: 1 (f=1): [_(4),V(1)][86.4%][r=12.2MiB/s,w=0KiB/s][r=3104,w=0 IOPS][eta 00m:50s]Jobs: 1 (f=1): [_(4),V(1)][86.7%][r=11.2MiB/s,w=0KiB/s][r=3070,w=0 IOPS][eta 00m:49s]Jobs: 1 (f=1): [_(4),V(1)][87.0%][r=11.1MiB/s,w=0KiB/s][r=3056,w=0 IOPS][eta 00m:48s]Jobs: 1 (f=1): [_(4),V(1)][87.3%][r=12.2MiB/s,w=0KiB/s][r=3102,w=0 IOPS][eta 00m:47s]Jobs: 1 (f=1): [_(4),V(1)][87.5%][r=15.5MiB/s,w=0KiB/s][r=3948,w=0 IOPS][eta 00m:46s]Jobs: 1 (f=1): [_(4),V(1)][87.8%][r=15.9MiB/s,w=0KiB/s][r=4044,w=0 IOPS][eta 00m:45s]Jobs: 1 (f=1): [_(4),V(1)][88.1%][r=12.5MiB/s,w=0KiB/s][r=3084,w=0 IOPS][eta 00m:44s]Jobs: 1 (f=1): [_(4),V(1)][88.1%][r=12.3MiB/s,w=0KiB/s][r=3139,w=0 IOPS][eta 00m:44s]Jobs: 1 (f=1): [_(4),V(1)][88.4%][r=12.2MiB/s,w=0KiB/s][r=3119,w=0 IOPS][eta 00m:43s]Jobs: 1 (f=1): [_(4),V(1)][88.6%][r=12.2MiB/s,w=0KiB/s][r=3098,w=0 IOPS][eta 00m:42s]Jobs: 1 (f=1): [_(4),V(1)][88.9%][r=11.1MiB/s,w=0KiB/s][r=3060,w=0 IOPS][eta 00m:41s]Jobs: 1 (f=1): [_(4),V(1)][89.2%][r=12.5MiB/s,w=0KiB/s][r=3191,w=0 IOPS][eta 00m:40s]Jobs: 1 (f=1): [_(4),V(1)][89.5%][r=12.8MiB/s,w=0KiB/s][r=3092,w=0 IOPS][eta 00m:39s]Jobs: 1 (f=1): [_(4),V(1)][89.7%][r=12.2MiB/s,w=0KiB/s][r=3114,w=0 IOPS][eta 00m:38s]Jobs: 1 (f=1): [_(4),V(1)][90.0%][r=12.5MiB/s,w=0KiB/s][r=3177,w=0 IOPS][eta 00m:37s]Jobs: 1 (f=1): [_(4),V(1)][90.0%][r=12.7MiB/s,w=0KiB/s][r=3237,w=0 IOPS][eta 00m:37s]Jobs: 1 (f=1): [_(4),V(1)][90.3%][r=12.2MiB/s,w=0KiB/s][r=3111,w=0 IOPS][eta 00m:36s]Jobs: 1 (f=1): [_(4),V(1)][90.6%][r=12.6MiB/s,w=0KiB/s][r=3087,w=0 IOPS][eta 00m:35s]Jobs: 1 (f=1): [_(4),V(1)][90.8%][r=11.1MiB/s,w=0KiB/s][r=3055,w=0 IOPS][eta 00m:34s]Jobs: 1 (f=1): [_(4),V(1)][91.1%][r=11.2MiB/s,w=0KiB/s][r=3069,w=0 IOPS][eta 00m:33s]Jobs: 1 (f=1): [_(4),V(1)][91.4%][r=12.8MiB/s,w=0KiB/s][r=3091,w=0 IOPS][eta 00m:32s]Jobs: 1 (f=1): [_(4),V(1)][91.6%][r=11.2MiB/s,w=0KiB/s][r=3071,w=0 IOPS][eta 00m:31s]Jobs: 1 (f=1): [_(4),V(1)][91.7%][r=12.2MiB/s,w=0KiB/s][r=3075,w=0 IOPS][eta 00m:31s]Jobs: 1 (f=1): [_(4),V(1)][91.9%][r=11.1MiB/s,w=0KiB/s][r=3064,w=0 IOPS][eta 00m:30s]Jobs: 1 (f=1): [_(4),V(1)][92.2%][r=12.4MiB/s,w=0KiB/s][r=3170,w=0 IOPS][eta 00m:29s]Jobs: 1 (f=1): [_(4),V(1)][92.5%][r=13.7MiB/s,w=0KiB/s][r=3345,w=0 IOPS][eta 00m:28s]Jobs: 1 (f=1): [_(4),V(1)][92.7%][r=13.5MiB/s,w=0KiB/s][r=3440,w=0 IOPS][eta 00m:27s]Jobs: 1 (f=1): [_(4),V(1)][93.0%][r=13.2MiB/s,w=0KiB/s][r=3356,w=0 IOPS][eta 00m:26s]Jobs: 1 (f=1): [_(4),V(1)][93.3%][r=13.5MiB/s,w=0KiB/s][r=3433,w=0 IOPS][eta 00m:25s]Jobs: 1 (f=1): [_(4),V(1)][93.5%][r=13.2MiB/s,w=0KiB/s][r=3378,w=0 IOPS][eta 00m:24s]Jobs: 1 (f=1): [_(4),V(1)][93.8%][r=12.5MiB/s,w=0KiB/s][r=3083,w=0 IOPS][eta 00m:23s]Jobs: 1 (f=1): [_(4),V(1)][94.1%][r=12.2MiB/s,w=0KiB/s][r=3100,w=0 IOPS][eta 00m:22s]Jobs: 1 (f=1): [_(4),V(1)][94.4%][r=12.9MiB/s,w=0KiB/s][r=3094,w=0 IOPS][eta 00m:21s]Jobs: 1 (f=1): [_(4),V(1)][94.4%][r=12.2MiB/s,w=0KiB/s][r=3112,w=0 IOPS][eta 00m:21s]Jobs: 1 (f=1): [_(4),V(1)][94.9%][r=15.4MiB/s,w=0KiB/s][r=3927,w=0 IOPS][eta 00m:19s]Jobs: 1 (f=1): [_(4),V(1)][95.2%][r=15.9MiB/s,w=0KiB/s][r=4050,w=0 IOPS][eta 00m:18s]Jobs: 1 (f=1): [_(4),V(1)][95.4%][r=12.4MiB/s,w=0KiB/s][r=3167,w=0 IOPS][eta 00m:17s]Jobs: 1 (f=1): [_(4),V(1)][95.4%][r=12.2MiB/s,w=0KiB/s][r=3101,w=0 IOPS][eta 00m:17s]Jobs: 1 (f=1): [_(4),V(1)][95.7%][r=12.6MiB/s,w=0KiB/s][r=3087,w=0 IOPS][eta 00m:16s]Jobs: 1 (f=1): [_(4),V(1)][96.0%][r=12.2MiB/s,w=0KiB/s][r=3117,w=0 IOPS][eta 00m:15s]Jobs: 1 (f=1): [_(4),V(1)][96.2%][r=12.2MiB/s,w=0KiB/s][r=3120,w=0 IOPS][eta 00m:14s]Jobs: 1 (f=1): [_(4),V(1)][96.5%][r=12.2MiB/s,w=0KiB/s][r=3099,w=0 IOPS][eta 00m:13s]Jobs: 1 (f=1): [_(4),V(1)][96.8%][r=12.4MiB/s,w=0KiB/s][r=3157,w=0 IOPS][eta 00m:12s]Jobs: 1 (f=1): [_(4),V(1)][97.1%][r=12.7MiB/s,w=0KiB/s][r=3088,w=0 IOPS][eta 00m:11s]Jobs: 1 (f=1): [_(4),V(1)][97.3%][r=12.9MiB/s,w=0KiB/s][r=3282,w=0 IOPS][eta 00m:10s]Jobs: 1 (f=1): [_(4),V(1)][97.6%][r=12.5MiB/s,w=0KiB/s][r=3178,w=0 IOPS][eta 00m:09s]Jobs: 1 (f=1): [_(4),V(1)][97.6%][r=12.2MiB/s,w=0KiB/s][r=3076,w=0 IOPS][eta 00m:09s]Jobs: 1 (f=1): [_(4),V(1)][97.9%][r=11.1MiB/s,w=0KiB/s][r=3066,w=0 IOPS][eta 00m:08s]Jobs: 1 (f=1): [_(4),V(1)][98.1%][r=12.2MiB/s,w=0KiB/s][r=3112,w=0 IOPS][eta 00m:07s]Jobs: 1 (f=1): [_(4),V(1)][98.4%][r=12.2MiB/s,w=0KiB/s][r=3120,w=0 IOPS][eta 00m:06s]Jobs: 1 (f=1): [_(4),V(1)][98.7%][r=11.1MiB/s,w=0KiB/s][r=3058,w=0 IOPS][eta 00m:05s]Jobs: 1 (f=1): [_(4),V(1)][98.9%][r=12.2MiB/s,w=0KiB/s][r=3103,w=0 IOPS][eta 00m:04s]Jobs: 1 (f=1): [_(4),V(1)][99.2%][r=12.6MiB/s,w=0KiB/s][r=3087,w=0 IOPS][eta 00m:03s]Jobs: 1 (f=1): [_(4),V(1)][99.5%][r=12.8MiB/s,w=0KiB/s][r=3090,w=0 IOPS][eta 00m:02s]Jobs: 1 (f=1): [_(4),V(1)][99.7%][r=15.7MiB/s,w=0KiB/s][r=3994,w=0 IOPS][eta 00m:01s]Jobs: 1 (f=1): [_(4),V(1)][100.0%][r=15.9MiB/s,w=0KiB/s][r=4051,w=0 IOPS][eta 00m:00s]Jobs: 1 (f=1): [_(4),V(1)][100.0%][r=9968KiB/s,w=0KiB/s][r=2492,w=0 IOPS][eta 00m:00s]
job1: (groupid=0, jobs=5): err= 0: pid=17217: Thu Sep 27 09:19:46 2018
   read: IOPS=10.6k, BW=41.4MiB/s (43.4MB/s)(15.9GiB/373697msec)
    clat percentiles (usec):
     |  1.00th=[    0],  5.00th=[    0], 10.00th=[    0], 20.00th=[    0],
     | 30.00th=[    0], 40.00th=[    0], 50.00th=[    0], 60.00th=[    0],
     | 70.00th=[    0], 80.00th=[    0], 90.00th=[    0], 95.00th=[    0],
     | 99.00th=[    0], 99.50th=[    0], 99.90th=[    0], 99.95th=[    0],
     | 99.99th=[    0]
  cpu          : usr=11.86%, sys=5.50%, ctx=3956164, majf=0, minf=1712
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwt: total=3955200,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=41.4MiB/s (43.4MB/s), 41.4MiB/s-41.4MiB/s (43.4MB/s-43.4MB/s), io=15.9GiB (16.2GB), run=373697-373697msec

Disk stats (read/write):
  nvme1n1: ios=267993/0, merge=0/0, ticks=59985/0, in_queue=59915, util=85.02%
  nvme2n1: ios=527176/0, merge=0/0, ticks=118677/0, in_queue=118537, util=84.72%
  nvme3n1: ios=786405/0, merge=0/0, ticks=178883/0, in_queue=178657, util=83.83%
  nvme4n1: ios=1055797/0, merge=0/0, ticks=243496/0, in_queue=243293, util=85.12%
  nvme5n1: ios=1315038/0, merge=0/0, ticks=306516/0, in_queue=306017, util=81.93%


    DEBUG: 2018/09/27 09:19:46 Create XFS, EXT4 FS and Mount 5 remote volumes
    DEBUG: 2018/09/27 09:19:49 Umount remote volumes and delete mount directories
    DEBUG: 2018/09/27 09:19:50 Detach all 5 remote volumes
    DEBUG: 2018/09/27 09:19:52 Delete all 5 volumes
[AfterEach] Remote Storage volume basic test for sanity
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1040
    DEBUG: 2018/09/27 09:20:54 END_TEST RemoteStorage.Basic Time-taken : 749.987593384

[32m• [SLOW TEST:749.988 seconds][0m
RemoteStorage.Basic Sanity RS_Basic-1.1 RS_Basic-1.2 RS_Basic-1.3 RS_Basic-1.5 RS_Verify-1.0 RS_Stress-1.1
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1022[0m
  Remote Storage volume basic test for sanity
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1024[0m
    remote storage volume basic operations
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:1045[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.MultiplePodsOneRemoteVolumeEach Daily RSP_Basic-1.1 RSP_Basic-1.2 Qos[0m [90mMultiple Pods, One remote volume each.[0m 
  [1mMultiple Pods, One remote volume each.[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3089[0m
[BeforeEach] Multiple Pods, One remote volume each.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3077
    DEBUG: 2018/09/27 09:20:54 START_TEST RemoteStorage.MultiplePodsOneRemoteVolumeEach
    DEBUG: 2018/09/27 09:20:54 Login to cluster
    DEBUG: 2018/09/27 09:20:54 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:20:55 Checking basic Vnic usage
    DEBUG: 2018/09/27 09:20:55 Updating inventory struct
[It] Multiple Pods, One remote volume each.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3089
    DEBUG: 2018/09/27 09:21:02 Creating 10 volumes. Mirror count: 1.
    DEBUG: 2018/09/27 09:21:13 Creating 10 fio pods: 
    DEBUG: 2018/09/27 09:21:16 Checking if given pods are in Running state
    DEBUG: 2018/09/27 09:21:52 Wait for volumes to move into attached state: 
    DEBUG: 2018/09/27 09:24:52 Validating qos associated with each volume: 
    DEBUG: 2018/09/27 09:24:52 Deleting pods : 
    DEBUG: 2018/09/27 09:25:05 Wait for volumes to come in Available state: 
    DEBUG: 2018/09/27 09:25:05 Delete volumes: 
[AfterEach] Multiple Pods, One remote volume each.
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3084
    DEBUG: 2018/09/27 09:27:23 END_TEST RemoteStorage.MultiplePodsOneRemoteVolumeEach Time-taken : 389.001727425

[32m• [SLOW TEST:389.002 seconds][0m
RemoteStorage.MultiplePodsOneRemoteVolumeEach Daily RSP_Basic-1.1 RSP_Basic-1.2 Qos
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3070[0m
  Multiple Pods, One remote volume each.
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3072[0m
    Multiple Pods, One remote volume each.
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3089[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mRemoteStorage.MultiSVDataVerification Weekly RS_Verify-1.6[0m [90mcreate remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs[0m 
  [1mcreates remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3809[0m
[BeforeEach] create remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3791
    DEBUG: 2018/09/27 09:27:23 START_TEST RemoteStorage.MultiSVDataVerification
    DEBUG: 2018/09/27 09:27:23 Login to cluster
    DEBUG: 2018/09/27 09:27:23 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:27:24 Checking basic Vnic usage
    DEBUG: 2018/09/27 09:27:24 Updating inventory struct
[It] creates remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3809
    DEBUG: 2018/09/27 09:27:31 Computing total available storage space on node bosserv6
    DEBUG: 2018/09/27 09:27:31 Available space on the node is less than the maximum size of volume. Hence, creating a volume of size equal to maximum available space on node
Max Volume size allowed : 8796093022208
Available space on node : 3016677654528

    DEBUG: 2018/09/27 09:27:31 Volume size is less than maximum SV size. Can't create multiple SVs.
[AfterEach] create remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3804
    DEBUG: 2018/09/27 09:27:31 END_TEST RemoteStorage.MultiSVDataVerification Time-taken : 7.434330637

[36m[1mS [SKIPPING] [7.434 seconds][0m
RemoteStorage.MultiSVDataVerification Weekly RS_Verify-1.6
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3780[0m
  create remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3786[0m
    [36m[1mcreates remote volume of large size such that it uses multiple SVs, run fio and check for data validation on those SVs [It][0m
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3809[0m

    [36mSkipping since Volume size is less than maximum SV size[0m

    /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/volume.go:3870
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mNetworkRemoteStorage.NicVFsSchedulingTrafficFlowOppositeDirection Daily AT_Scheduling-1.1[0m [90mNetwork plus remote storage nic & VFs scheduling, Traffic flows in opposite direction[0m 
  [1mNetwork plus remote storage nic & VFs scheduling, Traffic flows in opposite direction[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1716[0m
[BeforeEach] Network plus remote storage nic & VFs scheduling, Traffic flows in opposite direction
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1701
    DEBUG: 2018/09/27 09:27:31 START_TEST NetworkRemoteStorage.NicVFsSchedulingTrafficFlowOppositeDirection
    DEBUG: 2018/09/27 09:27:31 Login to cluster
    DEBUG: 2018/09/27 09:27:31 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:27:31 Checking basic Vnic usage
    DEBUG: 2018/09/27 09:27:31 Updating inventory struct
[It] Network plus remote storage nic & VFs scheduling, Traffic flows in opposite direction
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1716
    DEBUG: 2018/09/27 09:27:38 Creating 1 pair of iperf client-server pod
    DEBUG: 2018/09/27 09:27:38 Creating iperf server pod: iperf-serverhigh1
    DEBUG: 2018/09/27 09:27:42 Creating service with name: iperf-serverhigh1
    DEBUG: 2018/09/27 09:28:12 Creating iperf Client pod: iperf-clienthigh1
    DEBUG: 2018/09/27 09:28:16 Getting pods scheduled on network nicIds
    DEBUG: 2018/09/27 09:28:16 Checking distribution of network pods across nicId(s)
    DEBUG: 2018/09/27 09:28:16 Pod scheduled as expected
    DEBUG: 2018/09/27 09:28:16 Creating fio pod and remote volume with high qos: 
    DEBUG: 2018/09/27 09:28:16 Create 1 remote volumes: 
    DEBUG: 2018/09/27 09:28:17 Create 1 fio pod(s):
    DEBUG: 2018/09/27 09:28:17 Creating fio pod: fio-pod-high-1
    DEBUG: 2018/09/27 09:28:17 Checking if given pods are in Running state
    DEBUG: 2018/09/27 09:28:26 Getting pods and volumes scheduled on storage nicIds
    DEBUG: 2018/09/27 09:28:27 Checking distribution of storage pods across nicId(s)
    DEBUG: 2018/09/27 09:28:27 Pod scheduled as expected
    DEBUG: 2018/09/27 09:28:27 Deleting all the pods: 
    DEBUG: 2018/09/27 09:28:58 Waitting for volume to move to "Available" state
    DEBUG: 2018/09/27 09:28:58 Deleting the volumes: 
[AfterEach] Network plus remote storage nic & VFs scheduling, Traffic flows in opposite direction
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1712
    DEBUG: 2018/09/27 09:29:53 END_TEST NetworkRemoteStorage.NicVFsSchedulingTrafficFlowOppositeDirection Time-taken : 142.59653549

[32m• [SLOW TEST:142.597 seconds][0m
NetworkRemoteStorage.NicVFsSchedulingTrafficFlowOppositeDirection Daily AT_Scheduling-1.1
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1695[0m
  Network plus remote storage nic & VFs scheduling, Traffic flows in opposite direction
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1696[0m
    Network plus remote storage nic & VFs scheduling, Traffic flows in opposite direction
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1716[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0mNetworkRemoteStorage.NicVFsSchedulingTrafficFlowSameDirection Daily AT_Scheduling-1.0[0m [90mNetwork plus remote storage nic & VFs scheduling, Traffic flows in same direction[0m 
  [1mNetwork plus remote storage nic & VFs scheduling, Traffic flows in same direction[0m
  [37m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1556[0m
[BeforeEach] Network plus remote storage nic & VFs scheduling, Traffic flows in same direction
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1541
    DEBUG: 2018/09/27 09:29:53 START_TEST NetworkRemoteStorage.NicVFsSchedulingTrafficFlowSameDirection
    DEBUG: 2018/09/27 09:29:53 Login to cluster
    DEBUG: 2018/09/27 09:29:53 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:29:54 Checking basic Vnic usage
    DEBUG: 2018/09/27 09:29:54 Updating inventory struct
[It] Network plus remote storage nic & VFs scheduling, Traffic flows in same direction
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1556
    DEBUG: 2018/09/27 09:30:01 Creating 1 pair of iperf client-server pod
    DEBUG: 2018/09/27 09:30:01 Creating iperf server pod: iperf-serverhigh1
    DEBUG: 2018/09/27 09:30:04 Creating service with name: iperf-serverhigh1
    DEBUG: 2018/09/27 09:30:35 Creating iperf Client pod: iperf-clienthigh1
    DEBUG: 2018/09/27 09:30:38 Getting pods scheduled on network nicIds
    DEBUG: 2018/09/27 09:30:39 Checking distribution of network pods across nicId(s)
    DEBUG: 2018/09/27 09:30:39 Pod scheduled as expected
    DEBUG: 2018/09/27 09:30:39 Creating fio pod and remote volume with high qos: 
    DEBUG: 2018/09/27 09:30:39 Create 1 remote volumes: 
    DEBUG: 2018/09/27 09:30:40 Create 1 fio pod(s):
    DEBUG: 2018/09/27 09:30:40 Creating fio pod: fio-pod-high-1
    DEBUG: 2018/09/27 09:30:40 Checking if given pods are in Running state
    DEBUG: 2018/09/27 09:30:47 Getting pods and volumes scheduled on storage nicIds
    DEBUG: 2018/09/27 09:30:47 Checking distribution of storage pods across nicId(s)
    DEBUG: 2018/09/27 09:30:47 Pod scheduled as expected
    DEBUG: 2018/09/27 09:30:47 Deleting all the pods: 
    DEBUG: 2018/09/27 09:31:10 Waitting for volume to move to "Available" state
    DEBUG: 2018/09/27 09:31:10 Deleting the volumes: 
[AfterEach] Network plus remote storage nic & VFs scheduling, Traffic flows in same direction
  /home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1552
    DEBUG: 2018/09/27 09:31:53 END_TEST NetworkRemoteStorage.NicVFsSchedulingTrafficFlowSameDirection Time-taken : 119.59444308

[32m• [SLOW TEST:119.595 seconds][0m
NetworkRemoteStorage.NicVFsSchedulingTrafficFlowSameDirection Daily AT_Scheduling-1.0
[90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1535[0m
  Network plus remote storage nic & VFs scheduling, Traffic flows in same direction
  [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1536[0m
    Network plus remote storage nic & VFs scheduling, Traffic flows in same direction
    [90m/home/jenkins/workspace/Project13-Master/main/.go/src/dws/test/e2e/tests/network-pod.go:1556[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m    DEBUG: 2018/09/27 09:31:53 Running After suite ...
    DEBUG: 2018/09/27 09:31:53 Checking existance of loopback device(s) on all cluster nodes
    DEBUG: 2018/09/27 09:31:54 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:01 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:02 Login to cluster
    DEBUG: 2018/09/27 09:32:02 Login commands is :  -s 172.16.230.102 login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:03 Destroying the cluster: 1791e929-c239-11e8-be5a-54ab3a2919da, Master node is bosserv6
    DEBUG: 2018/09/27 09:32:03 Checking in a loop for cluster status
    DEBUG: 2018/09/27 09:32:03 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:05 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:06 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:08 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:10 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:11 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:13 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:15 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:17 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:18 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:20 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:22 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:24 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:26 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:27 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:29 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:31 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:33 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:34 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:36 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:38 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:40 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:41 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:43 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:45 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:48 Login using 172.16.230.102 : command is : login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:51 Login command is login -u admin -p Diamanti@111 --proxy --insecure
    DEBUG: 2018/09/27 09:32:51 Error while saving cluster info%!(EXTRA string=failed to run commmand 'dctl -s 172.16.230.102  -o json login -u admin -p Diamanti@111 --proxy --insecure', output:, error:Get https://172.16.230.102:443/api/v1/clusterdiscover: dial tcp 172.16.230.102:443: connect: no route to host
Cannot reach cluster, please check if vip / fqdn is reachable

)
    DEBUG: 2018/09/27 09:33:05 Doing sync all nodes.
    DEBUG: 2018/09/27 09:33:05 Doing sync all nodes.
    DEBUG: 2018/09/27 09:33:06 Doing sync all nodes.
    DEBUG: 2018/09/27 09:33:08 Checking for cluster-info.json on node :172.16.230.8
    DEBUG: 2018/09/27 09:33:09 Checking for cluster-info.json on node :172.16.230.10
    DEBUG: 2018/09/27 09:33:09 Checking for cluster-info.json on node :172.16.230.12
    DEBUG: 2018/09/27 09:33:09 Rebooting all nodes.
    DEBUG: 2018/09/27 09:33:09 Doing sync on 172.16.230.8
PolicyKit daemon disconnected from the bus.
We are no longer a registered authentication agent.
    DEBUG: 2018/09/27 09:33:11 Doing sync on 172.16.230.10
PolicyKit daemon disconnected from the bus.
We are no longer a registered authentication agent.
    DEBUG: 2018/09/27 09:33:12 Doing sync on 172.16.230.12
    DEBUG: 2018/09/27 09:33:13 Waiting for nodes to come up, will wait upto 800 seconds
..................................................    DEBUG: 2018/09/27 09:41:51 Nodes are up, waiting for armada to start
......

[1m[32mRan 22 of 262 Specs in 25778.748 seconds[0m
[1m[32mSUCCESS![0m -- [32m[1m22 Passed[0m | [91m[1m0 Failed[0m | [33m[1m0 Pending[0m | [36m[1m240 Skipped[0m
