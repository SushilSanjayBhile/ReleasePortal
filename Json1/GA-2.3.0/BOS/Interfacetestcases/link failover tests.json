[
    {
        "TC ID": "I_LinkFail-1.0",
        "Scenario / Category": "Networking",
        "Test Description": "\n2 iperf client pods, 2 iperf server pods, Shutdown switch ineterface used by one of client pod.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Only one switch interface must be used by both client pods. And Network bandwidth should drop by 50%.",
        "Notes / Detailed Description": "2 Server pods were running on appserv90\n2 Client pods were running on appserv91 \nTX with all the network ports up : 14760\nshut port 0 on appserv91\nTX with one of the NW ports shut : 9100\nAfter port 0 on appserv91 was turned up, \n+TX was restored back to 14880",
        "": "single link restart : 2 combinations\n1 - shut/no shut with 2-3 second interval\n2-  shut/no shut with 30 second interval"
    },
    {
        "TC ID": "I_LinkFail-1.1",
        "Scenario / Category": "",
        "Test Description": "2 iperf client pods, 2 iperf server pods, Shutdown & restart switch ineterface used by one of client pod.\"\n",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": " One must be able to get expected bandwidth.",
        "Notes / Detailed Description": "2 Server pods were running on appserv90\n2 Client pods were running on appserv91 \nDid a shutdown and no shutdown on port 0 on appserv91 with a 2-3 seconds time gap. No significant change/drop in the bandwith was observed.",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-1.2",
        "Scenario / Category": "",
        "Test Description": "\n2 iperf client pods, 2 iperf server pods, Shutdown switch ineterface used by one of server pod.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Only one switch interface must be used by both server pods.Must see network bandwidth drop by 50%",
        "Notes / Detailed Description": "2 Server pods were running on appserv90\n2 Client pods were running on appserv91 \nRX with all the network ports up : 14890\nshut port 0 on appserv90\nRX with one of the NW ports shut : 9380\nAfter port 0 on appserv91 was turned up, \nRX was restored back to 14350",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-1.3",
        "Scenario / Category": "",
        "Test Description": "\n2 iperf client pods, 2 iperf server pods, Shutdown & restart switch ineterface used by one of server pod.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Must get expected bandwidth as both links are up.",
        "Notes / Detailed Description": "did a shut no shut with a couple of seconds gap on one of the interfaces used by the server pods. No significant Drop or change observed in the bandwidth.",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-1.4",
        "Scenario / Category": "",
        "Test Description": "\n2 iperf client pods, 2 iperf server pods, Shutdown switch ineterfaces used by both of client pods.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Must get 0 bandwidth. ",
        "Notes / Detailed Description": "Bandwidth dropped to 0 and the Node status became Failed.",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-1.5",
        "Scenario / Category": "\n",
        "Test Description": "\n2 iperf client pods, 2 iperf server pods, Shutdown switch ineterfaces used by both of server pods.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Must get 0 bandwidth. ",
        "Notes / Detailed Description": "Bandwidth dropped to 0 and the Node status became Failed.",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-1.6",
        "Scenario / Category": "",
        "Test Description": "Run bi-di traffic and do continues link flap (both network ports)",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (115)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "All the pods were in running after the link flap was stopped. ",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-1.7",
        "Scenario / Category": "",
        "Test Description": "Run bi-di traffic and do continues link flap (one network port)",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (115)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "All the pods were in running after the link flap was stopped. ",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.0",
        "Scenario / Category": "Storage",
        "Test Description": "1 pod, 1 volume, shutdown switch interface used by initiator.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Should get expected IOPS (>= 200k).  ",
        "Notes / Detailed Description": "Got expected IOPS \nMax for RX+TX is: 230658 iops\nWhen both the storage interfaces were shut down on the initiator, the pod went into CrashLoopbackOff state and the IOPS dropped down to 0.",
        "": "Traffic pattern : Read + Write"
    },
    {
        "TC ID": "I_LinkFail-2.1",
        "Scenario / Category": "",
        "Test Description": "1 pod, 1 volume, shutdown switch interface used by target.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Should get expected IOPS (>= 200k). ",
        "Notes / Detailed Description": "Got expected IOPS \nMax for RX+TX is: 230335 iops\nWhen both the storage interfaces were shut down on the target node, the pod went into CrashLoopbackOff state and the IOPS dropped down to 0.",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.2",
        "Scenario / Category": "",
        "Test Description": "2 pods, 2 volumes, Link pull test",
        "Automation TC Name": "",
        "Release": "NA",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "Must see drop in iops by 50%. After making interface up, must get expected iops.",
        "Notes / Detailed Description": "This TC is not applicable for remote testing. Needs to be performed on site.",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.3",
        "Scenario / Category": "",
        "Test Description": "2 pods, 2 volumes, shutdown switch interface used by one of initiator.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Must get 50% less IOPS than whatever we getting before shuting switch interface down.",
        "Notes / Detailed Description": "IOPS before one storage interface was shut on the switch: 461542 iops\nAfter the interface was shut: 286188 iops",
        "": " Note: For all of these test cases, the expected behaviour is seen only for read only or write only pods. In case of RW pods the iops did not drop to 50%. The IOPS we were getting was >=200K."
    },
    {
        "TC ID": "I_LinkFail-2.4",
        "Scenario / Category": "",
        "Test Description": "2 pods, 2 volumes, shutdown & restart switch interface used by one of initiator.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "After shuting down switch interface, must see drop in iops by 50%. After making interface up, must get expected iops.",
        "Notes / Detailed Description": "IOPS before one storage interface was shut on the switch: 461542 iops\nAfter the interface was shut: 286188 iops\nWhen the interface was turned up again: 447840 iops",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.5",
        "Scenario / Category": "",
        "Test Description": "2 pods, 2 volumes, shutdown switch interface used by one of target.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "must see performance drop by 50%.  ",
        "Notes / Detailed Description": "IOPS before one of the storage interface on the target node was shut: 447840 iops\nAfter the interface was shut: 284123 iops",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.6",
        "Scenario / Category": "",
        "Test Description": "2 pods, 2 volumes, shutdown & restart switch interface used by one of target.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "After shuting down switch interface, must see drop in iops by 50%. After making interface up, must get expected iops.",
        "Notes / Detailed Description": "IOPS before one of the storage interface on the target node was shut: 447840 iops\nAfter the interface was shut: 284123 iops\nWhen the interface was turned up again: 413538 iops",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.7",
        "Scenario / Category": "",
        "Test Description": "2 pods, 2 volumes, shutdown switch inetrfaces used by both initiator.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Fail",
        "Bug no ": "DWS-4945\nComment by Naveen: This is expected behavior today. When both the links are brought down, the Remote Storage Pods (single plex) will start failing. And we don't have an auto-recovery mechanism in this case.",
        "Expected Behaviour": "Must get 0 IOPs. Intiator and target side cleanup is done correctly.",
        "Notes / Detailed Description": "tested with read. After blocking both links pods went into crashloopbackOff state and the IOPS dropped down to 0. When the ports were opened again, the pod status didnt change back to Running. So had to delete and re-create the pods",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.8",
        "Scenario / Category": "",
        "Test Description": "2 pods, 2 volumes, shutdown switch inetrfaces used by both targets.",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (113)",
        "Results": "Fail",
        "Bug no ": "DWS-4945\nComment by Naveen: This is expected behavior today. When both the links are brought down, the Remote Storage Pods (single plex) will start failing. And we don't have an auto-recovery mechanism in this case.",
        "Expected Behaviour": "Must get 0 IOPs. Intiator and target side cleanup is done correctly.",
        "Notes / Detailed Description": "tested with read. After blocking both links pods went into crashloopbackOff state and the IOPS dropped down to 0. When the ports were opened again, the pod status didnt change back to Running. So had to delete and re-create the pods",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.9",
        "Scenario / Category": "",
        "Test Description": "Stress test with continues link flap",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (125)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "Check node status, volume status.",
        "Notes / Detailed Description": "started a stress test with the specfile \"cfg-stress-storage-only.json\" and the link flap has been started for a single storage port on each of the nodes. (if both the storage ports are shut, the pod goes into CrashLoopbckOff state). 7 iterations passed.",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-2.10",
        "Scenario / Category": "",
        "Test Description": "Stress test (bi-di fio traffic) with continues link flap (flap both storage ports)",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (128)",
        "Results": "Fail",
        "Bug no ": "DWS-4945",
        "Expected Behaviour": "Check pods status, io failure message",
        "Notes / Detailed Description": "Ran 24 fio bi-di pods. When both the storage ports are flapped, some of the pods were stuck in crashoopback of state and some got stuck in container create,",
        "": "Use fio-verify image. "
    },
    {
        "TC ID": "I_LinkFail-2.11",
        "Scenario / Category": "",
        "Test Description": "Stress test (bi-di fio traffic) with continues link flap (flap single storage ports)",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (125)",
        "Results": "Fail",
        "Bug no ": "Updated DWS-5379",
        "Expected Behaviour": "Check pods status, io failure message",
        "Notes / Detailed Description": "Ran 24 fio bi-di pods. The podauto got stuck in the 3rd iteration while deleting one of the pods.\nThe pod was stuck in terminating state. However the cluster status was good. The rest of the pods were in Running state and the respective volumes were attached. ",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-3.0",
        "Scenario / Category": "Mirroring",
        "Test Description": "Stress test (bi-di fio traffic) with continues link flap (flap both storage ports)",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (136)",
        "Results": "Fail",
        "Bug no ": "Updated DWS-5876",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "The core failed on one of the nodes and it was in failed state (Bosserv7). All the pods and volumes were stuck in pending state. All the volumes from the previous iteration were stuck in PendingDelete state. Exactly same bug was observed on NYNJ",
        "": ""
    },
    {
        "TC ID": "I_LinkFail-3.1",
        "Scenario / Category": "",
        "Test Description": "Stress test (bi-di fio traffic) with continues link flap (flap single storage port)",
        "Automation TC Name": "",
        "Release": "GA 2.3.0",
        "Build No": "9.9.1 (128)",
        "Results": "Pass",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "Flap only one storage link of initiator node.",
        "Automation TC Name": "",
        "Release": "",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "Flap only one storage link of target node.",
        "Automation TC Name": "",
        "Release": "",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "",
        "Build No": "",
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "Total",
        "Build No": 21.0,
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "Ran",
        "Build No": 21.0,
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "%",
        "Build No": 100.0,
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "Passed",
        "Build No": 16.0,
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "%",
        "Build No": 76.19,
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "Automated",
        "Build No": 0.0,
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    },
    {
        "TC ID": "",
        "Scenario / Category": "",
        "Test Description": "",
        "Automation TC Name": "",
        "Release": "%",
        "Build No": 0.0,
        "Results": "",
        "Bug no ": "",
        "Expected Behaviour": "",
        "Notes / Detailed Description": "",
        "": ""
    }
]